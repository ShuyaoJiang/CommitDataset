[+++ b/modules/elasticsearch/src/main/java/org/apache/lucene/store/bytebuffer/ByteBufferDirectory.java, +    protected final Map<String, ByteBufferFile> files = new ConcurrentHashMap<String, ByteBufferFile>();, +++ b/modules/elasticsearch/src/main/java/org/apache/lucene/store/bytebuffer/ByteBufferDirectory.java, +    protected final Map<String, ByteBufferFile> files = new ConcurrentHashMap<String, ByteBufferFile>();, +++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryStatus.java, +    ConcurrentMap<String, String> checksums = ConcurrentCollections.newConcurrentMap();, +++ b/modules/elasticsearch/src/main/java/org/apache/lucene/store/bytebuffer/ByteBufferDirectory.java, +    protected final Map<String, ByteBufferFile> files = new ConcurrentHashMap<String, ByteBufferFile>();, +++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryStatus.java, +    ConcurrentMap<String, String> checksums = ConcurrentCollections.newConcurrentMap();, +++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryTarget.java, +import org.elasticsearch.common.collect.Sets;, +import org.elasticsearch.index.shard.IllegalIndexShardStateException;, +import org.elasticsearch.index.shard.IndexShardClosedException;, +import org.elasticsearch.index.shard.IndexShardNotStartedException;, +import org.elasticsearch.index.shard.IndexShardState;, +import org.elasticsearch.index.shard.ShardId;, +import org.elasticsearch.transport.BaseTransportRequestHandler;, +import org.elasticsearch.transport.ConnectTransportException;, +import org.elasticsearch.transport.FutureTransportResponseHandler;, +import org.elasticsearch.transport.TransportChannel;, +import org.elasticsearch.transport.TransportService;, +import java.util.Set;, +            peerRecoveryStatus.checksums = null;, +            RecoveryStatus onGoingRecovery = onGoingRecoveries.get(shard.shardId());, +            if (onGoingRecovery == null) {, +                // shard is getting closed on us, +                throw new IndexShardClosedException(shard.shardId());, +            }, +, +            // first, we go and move files that were created with the recovery id suffix to, +            // the actual names, its ok if we have a corrupted index here, since we have replicas, +            // to recover from in case of a full cluster shutdown just when this code executes..., +            String suffix = "." + onGoingRecovery.startTime;, +            Set<String> filesToRename = Sets.newHashSet();, +            for (String existingFile : shard.store().directory().listAll()) {, +                if (existingFile.endsWith(suffix)) {, +                    filesToRename.add(existingFile.substring(0, existingFile.length() - suffix.length()));, +                }, +            }, +            Exception failureToRename = null;, +            if (!filesToRename.isEmpty()) {, +                // first, go and delete the existing ones, +                for (String fileToRename : filesToRename) {, +                    shard.store().directory().deleteFile(fileToRename);, +                }, +                for (String fileToRename : filesToRename) {, +                    // now, rename the files..., +                    try {, +                        shard.store().renameFile(fileToRename + suffix, fileToRename);, +                    } catch (Exception e) {, +                        failureToRename = e;, +                        break;, +                    }, +                }, +            }, +            if (failureToRename != null) {, +                throw failureToRename;, +            }, +            // now write checksums, +            shard.store().writeChecksums(onGoingRecovery.checksums);, +, +                onGoingRecovery.checksums.remove(request.name());, +, +                // also, we check if the file already exists, if it does, we create a file name based, +                // on the current recovery "id" and later we make the switch, the reason for that is that, +                // we only want to overwrite the index files once we copied all over, and not create a, +                // case where the index is half moved, +, +                String name = request.name();, +                if (shard.store().directory().fileExists(name)) {, +                    name = name + "." + onGoingRecovery.startTime;, +                }, +, +                indexOutput = shard.store().createOutputWithNoChecksum(name);, +, +                            onGoingRecovery.checksums.put(request.name(), request.checksum());, +++ b/modules/elasticsearch/src/main/java/org/apache/lucene/store/bytebuffer/ByteBufferDirectory.java, +    protected final Map<String, ByteBufferFile> files = new ConcurrentHashMap<String, ByteBufferFile>();, +++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryStatus.java, +    ConcurrentMap<String, String> checksums = ConcurrentCollections.newConcurrentMap();, +++ b/modules/elasticsearch/src/main/java/org/elasticsearch/index/shard/recovery/RecoveryTarget.java, +import org.elasticsearch.common.collect.Sets;, +import org.elasticsearch.index.shard.IllegalIndexShardStateException;, +import org.elasticsearch.index.shard.IndexShardClosedException;, +import org.elasticsearch.index.shard.IndexShardNotStartedException;, +import org.elasticsearch.index.shard.IndexShardState;, +import org.elasticsearch.index.shard.ShardId;, +import org.elasticsearch.transport.BaseTransportRequestHandler;, +import org.elasticsearch.transport.ConnectTransportException;, +import org.elasticsearch.transport.FutureTransportResponseHandler;, +import org.elasticsearch.transport.TransportChannel;, +import org.elasticsearch.transport.TransportService;, +import java.util.Set;, +            peerRecoveryStatus.checksums = null;, +            RecoveryStatus onGoingRecovery = onGoingRecoveries.get(shard.shardId());, +            if (onGoingRecovery == null) {, +                // shard is getting closed on us, +                throw new IndexShardClosedException(shard.shardId());, +            }]