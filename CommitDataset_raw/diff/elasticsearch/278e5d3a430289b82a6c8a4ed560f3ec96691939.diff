[+++ b/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java, +        // HttpMessageDecoder#content variable gets freshly created for each request and not reused across, +++ b/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java, +        // HttpMessageDecoder#content variable gets freshly created for each request and not reused across, +++ b/src/main/java/org/elasticsearch/transport/netty/MessageChannelHandler.java, +    // to guess the size of the cumulation buffer to allocate, and because we make a fresh copy of the cumulation, +    // buffer so we can readBytesReference from it without other request writing into the same one in case, +    // two one message and a partial next message exists within the same input, +    // we can readBytesReference because NioWorker always copies the input buffer into a fresh buffer, and we, +    // don't reuse cumumlation buffer, +            callDecode(ctx, e.getChannel(), cumulation, true);, +            int actualSize = callDecode(ctx, e.getChannel(), input, false);, +    private int callDecode(ChannelHandlerContext ctx, Channel channel, ChannelBuffer buffer, boolean cumulationBuffer) throws Exception {, +        int actualSize = 0;, +        while (buffer.readable()) {, +            actualSize = 0;, +            if (buffer.readableBytes() < 4) {, +            int dataLen = buffer.getInt(buffer.readerIndex());, +            actualSize = dataLen + 4;, +            if (buffer.readableBytes() < actualSize) {, +                break;, +            buffer.skipBytes(4);, +            process(ctx, channel, buffer, dataLen);, +        if (cumulationBuffer) {, +            assert buffer == this.cumulation;, +            if (!buffer.readable()) {, +            } else if (buffer.readerIndex() > 0) {, +                // make a fresh copy of the cumalation buffer, so we, +                // can readBytesReference from it, and also, don't keep it around, +, +                // its not that big of an overhead since discardReadBytes in the next round messageReceived will, +                // copy over the bytes to the start again, +                if (actualSize > 0) {, +                    this.cumulation = ChannelBuffers.dynamicBuffer(actualSize, ctx.getChannel().getConfig().getBufferFactory());, +                } else {, +                    this.cumulation = ChannelBuffers.dynamicBuffer(ctx.getChannel().getConfig().getBufferFactory());, +                }, +                this.cumulation.writeBytes(buffer);, +            }, +        return actualSize;, +                callDecode(ctx, ctx.getChannel(), cumulation, true);, +++ b/src/main/java/org/elasticsearch/http/netty/NettyHttpRequest.java, +        // HttpMessageDecoder#content variable gets freshly created for each request and not reused across, +++ b/src/main/java/org/elasticsearch/transport/netty/MessageChannelHandler.java, +    // to guess the size of the cumulation buffer to allocate, and because we make a fresh copy of the cumulation, +    // buffer so we can readBytesReference from it without other request writing into the same one in case, +    // two one message and a partial next message exists within the same input, +    // we can readBytesReference because NioWorker always copies the input buffer into a fresh buffer, and we, +    // don't reuse cumumlation buffer, +            callDecode(ctx, e.getChannel(), cumulation, true);, +            int actualSize = callDecode(ctx, e.getChannel(), input, false);, +    private int callDecode(ChannelHandlerContext ctx, Channel channel, ChannelBuffer buffer, boolean cumulationBuffer) throws Exception {, +        int actualSize = 0;, +        while (buffer.readable()) {, +            actualSize = 0;, +            if (buffer.readableBytes() < 4) {, +            int dataLen = buffer.getInt(buffer.readerIndex());, +            actualSize = dataLen + 4;, +            if (buffer.readableBytes() < actualSize) {, +                break;, +            buffer.skipBytes(4);, +            process(ctx, channel, buffer, dataLen);, +        if (cumulationBuffer) {, +            assert buffer == this.cumulation;, +            if (!buffer.readable()) {, +            } else if (buffer.readerIndex() > 0) {, +                // make a fresh copy of the cumalation buffer, so we, +                // can readBytesReference from it, and also, don't keep it around, +, +                // its not that big of an overhead since discardReadBytes in the next round messageReceived will, +                // copy over the bytes to the start again, +                if (actualSize > 0) {, +                    this.cumulation = ChannelBuffers.dynamicBuffer(actualSize, ctx.getChannel().getConfig().getBufferFactory());, +                } else {, +                    this.cumulation = ChannelBuffers.dynamicBuffer(ctx.getChannel().getConfig().getBufferFactory());, +                }, +                this.cumulation.writeBytes(buffer);, +            }, +        return actualSize;, +                callDecode(ctx, ctx.getChannel(), cumulation, true);, +++ b/src/test/java/org/elasticsearch/test/stress/search1/ConcurrentSearchSerializationTests.java, +package org.elasticsearch.test.stress.search1;, +, +import org.elasticsearch.action.ActionListener;, +import org.elasticsearch.action.index.IndexResponse;, +import org.elasticsearch.action.search.SearchResponse;, +import org.elasticsearch.client.Client;, +import org.elasticsearch.common.RandomStringGenerator;, +import org.elasticsearch.common.settings.ImmutableSettings;, +import org.elasticsearch.common.settings.Settings;, +import org.elasticsearch.index.query.QueryBuilders;, +import org.elasticsearch.node.Node;, +import org.elasticsearch.node.NodeBuilder;, +import org.elasticsearch.search.SearchHit;, +, +import java.util.concurrent.CountDownLatch;, +, +/**, + * Tests that data don't get corrupted while reading it over the streams., + * <p/>]