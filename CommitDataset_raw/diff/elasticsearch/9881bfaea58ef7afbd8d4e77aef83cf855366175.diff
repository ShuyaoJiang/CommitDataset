[+++ b/docs/reference/analysis/analyzers/fingerprint-analyzer.asciidoc, +, +[float], +=== Definition, +, +The `fingerprint` tokenizer consists of:, +, +Tokenizer::, +* <<analysis-standard-tokenizer,Standard Tokenizer>>, +, +Token Filters (in order)::, +* <<analysis-lowercase-tokenfilter,Lower Case Token Filter>>, +* <<analysis-asciifolding-tokenfilter>>, +* <<analysis-stop-tokenfilter,Stop Token Filter>> (disabled by default), +* <<analysis-fingerprint-tokenfilter>>, +, +If you need to customize the `fingerprint` analyzer beyond the configuration, +parameters then you need to recreate it as a `custom` analyzer and modify, +it, usually by adding token filters. This would recreate the built-in, +`fingerprint` analyzer and you can use it as a starting point for further, +customization:, +, +[source,js], +----------------------------------------------------, +PUT /fingerprint_example, +{, +  "settings": {, +    "analysis": {, +      "analyzer": {, +        "rebuilt_fingerprint": {, +          "tokenizer": "standard",, +          "filter": [, +            "lowercase",, +            "asciifolding",, +            "fingerprint", +          ], +        }, +      }, +    }, +  }, +}, +----------------------------------------------------, +// CONSOLE, +// TEST[s/\n$/\nstartyaml\n  - compare_analyzers: {index: fingerprint_example, first: fingerprint, second: rebuilt_fingerprint}\nendyaml\n/], +++ b/docs/reference/analysis/analyzers/fingerprint-analyzer.asciidoc, +, +[float], +=== Definition, +, +The `fingerprint` tokenizer consists of:, +, +Tokenizer::, +* <<analysis-standard-tokenizer,Standard Tokenizer>>, +, +Token Filters (in order)::, +* <<analysis-lowercase-tokenfilter,Lower Case Token Filter>>, +* <<analysis-asciifolding-tokenfilter>>, +* <<analysis-stop-tokenfilter,Stop Token Filter>> (disabled by default), +* <<analysis-fingerprint-tokenfilter>>, +, +If you need to customize the `fingerprint` analyzer beyond the configuration, +parameters then you need to recreate it as a `custom` analyzer and modify, +it, usually by adding token filters. This would recreate the built-in, +`fingerprint` analyzer and you can use it as a starting point for further, +customization:, +, +[source,js], +----------------------------------------------------, +PUT /fingerprint_example, +{, +  "settings": {, +    "analysis": {, +      "analyzer": {, +        "rebuilt_fingerprint": {, +          "tokenizer": "standard",, +          "filter": [, +            "lowercase",, +            "asciifolding",, +            "fingerprint", +          ], +        }, +      }, +    }, +  }, +}, +----------------------------------------------------, +// CONSOLE, +// TEST[s/\n$/\nstartyaml\n  - compare_analyzers: {index: fingerprint_example, first: fingerprint, second: rebuilt_fingerprint}\nendyaml\n/], +++ b/docs/reference/analysis/analyzers/keyword-analyzer.asciidoc, +, +[float], +=== Definition, +, +The `keyword` analyzer consists of:, +, +Tokenizer::, +* <<analysis-keyword-tokenizer,Keyword Tokenizer>>, +, +If you need to customize the `keyword` analyzer then you need to, +recreate it as a `custom` analyzer and modify it, usually by adding]