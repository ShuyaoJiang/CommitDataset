[+++ b/src/test/java/org/elasticsearch/recovery/RecoveryWhileUnderLoadTests.java, +    public class BackgroundIndexer implements AutoCloseable {, +        final Thread[] writers;, +        final CountDownLatch stopLatch;, +        final CopyOnWriteArrayList<Throwable> failures;, +        final AtomicBoolean stop = new AtomicBoolean(false);, +, +        public BackgroundIndexer() {, +            this(scaledRandomIntBetween(3, 10));, +        }, +, +        public BackgroundIndexer(int writerCount) {, +            this(writerCount, true);, +        }, +, +        public BackgroundIndexer(int writerCount, boolean autoStart) {, +, +            failures = new CopyOnWriteArrayList<>();, +            writers = new Thread[writerCount];, +            stopLatch = new CountDownLatch(writers.length);, +            logger.info("--> starting {} indexing threads", writerCount);, +, +            if (autoStart) {, +                startLatch.countDown();, +            }, +        }, +, +        public void start() {, +            startLatch.countDown();, +        }, +, +        public void stop() throws InterruptedException {, +            if (stop.get()) {, +                return;, +            }, +            stop.set(true);, +, +            assertThat("timeout while waiting for indexing threads to stop", stopLatch.await(6, TimeUnit.MINUTES), equalTo(true));, +            assertNoFailures();, +        }, +, +        public long totalIndexedDocs() {, +            return indexCounter.get();, +        }, +, +        public Throwable[] getFailures() {, +            return failures.toArray(new Throwable[failures.size()]);, +        }, +, +        public void assertNoFailures() {, +            assertThat(failures, emptyIterable());, +        }, +, +        @Override, +        public void close() throws Exception {, +            stop();, +        }, +    }, +, +    @Test, +    @TestLogging("action.search.type:TRACE,action.admin.indices.refresh:TRACE"), +    @Slow, +    public void recoverWhileUnderLoadAllocateBackupsTest() throws Exception {, +        logger.info("--> creating test index ...");, +        int numberOfShards = numberOfShards();, +        assertAcked(prepareCreate("test", 1, settingsBuilder().put(SETTING_NUMBER_OF_SHARDS, numberOfShards).put(SETTING_NUMBER_OF_REPLICAS, 1)));, +, +        final int totalNumDocs = scaledRandomIntBetween(200, 20000);, +        try (BackgroundIndexer indexer = new BackgroundIndexer()) {, +            int waitFor = totalNumDocs / 10;, +            logger.info("--> waiting for {} docs to be indexed ...", waitFor);, +            waitForDocs(waitFor);, +            indexer.assertNoFailures();, +            logger.info("--> {} docs indexed",  waitFor);, +, +            logger.info("--> flushing the index ....");, +            // now flush, just to make sure we have some data in the index, not just translog, +            client().admin().indices().prepareFlush().execute().actionGet();, +, +            waitFor += totalNumDocs / 10;, +            logger.info("--> waiting for {} docs to be indexed ...", waitFor);, +            waitForDocs(waitFor);, +            indexer.assertNoFailures();, +            logger.info("--> {} docs indexed",  waitFor);, +, +            logger.info("--> allow 2 nodes for index [test] ...");, +            // now start another node, while we index, +            allowNodes("test", 2);, +, +            logger.info("--> waiting for GREEN health status ...");, +            // make sure the cluster state is green, and all has been recovered, +            assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout("1m").setWaitForGreenStatus().setWaitForNodes(">=2").execute().actionGet().isTimedOut(), equalTo(false));, +, +            logger.info("--> waiting for {} docs to be indexed ...", totalNumDocs);, +            waitForDocs(totalNumDocs);, +            indexer.assertNoFailures();, +            logger.info("--> {} docs indexed", totalNumDocs);, +, +            logger.info("--> marking and waiting for indexing threads to stop ...");, +            indexer.stop();]