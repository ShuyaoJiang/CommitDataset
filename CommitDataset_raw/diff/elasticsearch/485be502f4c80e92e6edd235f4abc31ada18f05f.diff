[+++ b/docs/en/ml/introduction.asciidoc, +Data is pulled from {es} for analysis and anomaly results are displayed in {kib}, +  Jobs can analyze either a one-off batch of data or continuously in real time., +  <<ml-post-data,POST data>> from any source directly to an API., +++ b/docs/en/ml/introduction.asciidoc, +Data is pulled from {es} for analysis and anomaly results are displayed in {kib}, +  Jobs can analyze either a one-off batch of data or continuously in real time., +  <<ml-post-data,POST data>> from any source directly to an API., +++ b/docs/en/rest-api/ml/datafeedresource.asciidoc, +  low cardinality data., +//TBD link to a Working with aggregations page, +  (object) The {es} query domain-specific language (DSL). This value, +  corresponds to the query object in an {es} search POST body. All the, +  options that are supported by {es} can be used, as this object is, +  passed verbatim to {es}. By default, this property has the following, +  (time units) The number of seconds behind real time that data is queried. For, +  example, if data from 10:04 a.m. might not be searchable in {es} until, +  10:06 a.m., set this property to 120 seconds. The default value is `60s`., +  (unsigned integer) The `size` parameter that is used in {es} searches., +Data feeds might be required to search over long time periods, for several months, +  (string) For started data feeds only, contains messages relating to the, +  selection of a node., +  (object) The node upon which the data feed is started. The data feed and, +  job will be on the same node., +  `id`::: The unique identifier of the node. For example,, +  "0-o0tOoRTwKFZifatTWKNw"., +  `ephemeral_id`::: The node ephemeral ID., +  `transport_address`::: The host and port where transport HTTP connections are, +  accepted. For example, "127.0.0.1:9300"., +  `stopped`::: The data feed is stopped and will not receive data until it is, +  re-started., +++ b/docs/en/ml/introduction.asciidoc, +Data is pulled from {es} for analysis and anomaly results are displayed in {kib}, +  Jobs can analyze either a one-off batch of data or continuously in real time., +  <<ml-post-data,POST data>> from any source directly to an API., +++ b/docs/en/rest-api/ml/datafeedresource.asciidoc, +  low cardinality data., +//TBD link to a Working with aggregations page, +  (object) The {es} query domain-specific language (DSL). This value, +  corresponds to the query object in an {es} search POST body. All the, +  options that are supported by {es} can be used, as this object is, +  passed verbatim to {es}. By default, this property has the following, +  (time units) The number of seconds behind real time that data is queried. For, +  example, if data from 10:04 a.m. might not be searchable in {es} until, +  10:06 a.m., set this property to 120 seconds. The default value is `60s`., +  (unsigned integer) The `size` parameter that is used in {es} searches., +Data feeds might be required to search over long time periods, for several months, +  (string) For started data feeds only, contains messages relating to the, +  selection of a node., +  (object) The node upon which the data feed is started. The data feed and, +  job will be on the same node., +  `id`::: The unique identifier of the node. For example,, +  "0-o0tOoRTwKFZifatTWKNw"., +  `ephemeral_id`::: The node ephemeral ID., +  `transport_address`::: The host and port where transport HTTP connections are, +  accepted. For example, "127.0.0.1:9300"., +  `stopped`::: The data feed is stopped and will not receive data until it is, +  re-started., +++ b/docs/en/rest-api/ml/post-data.asciidoc, +File sizes are limited to 100 Mb, so if your file is larger, then split it into, +multiple files and upload each one separately in sequential time order. When, +running in real time, it is generally recommended to perform many small uploads,, +rather than queueing data to upload larger files., +IMPORTANT:  Data can only be accepted from a single connection. Use a single, +connection synchronously to send data, close, flush, or delete a single job., +or a comma-separated list., +++ b/docs/en/ml/introduction.asciidoc, +Data is pulled from {es} for analysis and anomaly results are displayed in {kib}, +  Jobs can analyze either a one-off batch of data or continuously in real time., +  <<ml-post-data,POST data>> from any source directly to an API., +++ b/docs/en/rest-api/ml/datafeedresource.asciidoc, +  low cardinality data., +//TBD link to a Working with aggregations page, +  (object) The {es} query domain-specific language (DSL). This value, +  corresponds to the query object in an {es} search POST body. All the, +  options that are supported by {es} can be used, as this object is, +  passed verbatim to {es}. By default, this property has the following, +  (time units) The number of seconds behind real time that data is queried. For, +  example, if data from 10:04 a.m. might not be searchable in {es} until, +  10:06 a.m., set this property to 120 seconds. The default value is `60s`., +  (unsigned integer) The `size` parameter that is used in {es} searches., +Data feeds might be required to search over long time periods, for several months, +  (string) For started data feeds only, contains messages relating to the, +  selection of a node., +  (object) The node upon which the data feed is started. The data feed and, +  job will be on the same node., +  `id`::: The unique identifier of the node. For example,, +  "0-o0tOoRTwKFZifatTWKNw"., +  `ephemeral_id`::: The node ephemeral ID., +  `transport_address`::: The host and port where transport HTTP connections are, +  accepted. For example, "127.0.0.1:9300"., +  `stopped`::: The data feed is stopped and will not receive data until it is, +  re-started., +++ b/docs/en/rest-api/ml/post-data.asciidoc, +File sizes are limited to 100 Mb, so if your file is larger, then split it into, +multiple files and upload each one separately in sequential time order. When, +running in real time, it is generally recommended to perform many small uploads,, +rather than queueing data to upload larger files., +IMPORTANT:  Data can only be accepted from a single connection. Use a single, +connection synchronously to send data, close, flush, or delete a single job.]