[+++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java, +                        logger.debug("Cluster is blocked ({}), scheduling a retry", blockException.getMessage());, +                        logger.debug("Cluster is blocked ({}), scheduling a retry", blockException.getMessage());, +                logger.debug("No shard instances known for index [{}]. Scheduling a retry", shardIt.shardId());, +, +                    logger.debug("primary shard [{}] is not yet active or we do not know that node it is assigned to [{}]. Scheduling a retry.", shard.shardId(), shard.currentNodeId());, +                        logger.debug("Not enough active copies of shard [{}] to meet write consistency of [{}] (have {}, needed {}). Scheduling a retry.",, +                                shard.shardId(), consistencyLevel, shardIt.sizeActive(), requiredNumber);, +                                logger.debug("received an error from node the primary was assigned to ({}). Scheduling a retry", exp.getMessage());, +                logger.debug("Couldn't find a eligible primary shard. Scheduling for retry.");, +, +                        logger.debug("ShardRepOp: listener to cluster state added. Trying again");, +                        logger.debug("ShardRepOp: cluster changed (version {}). Trying again", event.state().version());, +            } else {, +                logger.debug("ShardRepOp: retry scheduling ignored as it was executed from an active cluster state listener");, +                    logger.debug("Had an error while performing operation on primary ({}). Scheduling a retry.", e.getMessage());, +++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java, +                        logger.debug("Cluster is blocked ({}), scheduling a retry", blockException.getMessage());, +                        logger.debug("Cluster is blocked ({}), scheduling a retry", blockException.getMessage());, +                logger.debug("No shard instances known for index [{}]. Scheduling a retry", shardIt.shardId());, +, +                    logger.debug("primary shard [{}] is not yet active or we do not know that node it is assigned to [{}]. Scheduling a retry.", shard.shardId(), shard.currentNodeId());, +                        logger.debug("Not enough active copies of shard [{}] to meet write consistency of [{}] (have {}, needed {}). Scheduling a retry.",, +                                shard.shardId(), consistencyLevel, shardIt.sizeActive(), requiredNumber);, +                                logger.debug("received an error from node the primary was assigned to ({}). Scheduling a retry", exp.getMessage());, +                logger.debug("Couldn't find a eligible primary shard. Scheduling for retry.");, +, +                        logger.debug("ShardRepOp: listener to cluster state added. Trying again");, +                        logger.debug("ShardRepOp: cluster changed (version {}). Trying again", event.state().version());, +            } else {, +                logger.debug("ShardRepOp: retry scheduling ignored as it was executed from an active cluster state listener");, +                    logger.debug("Had an error while performing operation on primary ({}). Scheduling a retry.", e.getMessage());, +++ b/src/test/java/org/elasticsearch/test/integration/TestCluster.java, +import java.util.concurrent.atomic.AtomicInteger;, +import static org.elasticsearch.common.settings.ImmutableSettings.settingsBuilder;, +    private AtomicInteger nextNodeId = new AtomicInteger(0);, +, +            logger.info("increasing cluster size from {} to {}", size, num);, +        logger.info("reducing cluster size from {} to {}", nodes.size() - num, num);, +        String name = "node_" + nextNodeId.getAndIncrement();, +++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java, +                        logger.debug("Cluster is blocked ({}), scheduling a retry", blockException.getMessage());, +                        logger.debug("Cluster is blocked ({}), scheduling a retry", blockException.getMessage());, +                logger.debug("No shard instances known for index [{}]. Scheduling a retry", shardIt.shardId());, +, +                    logger.debug("primary shard [{}] is not yet active or we do not know that node it is assigned to [{}]. Scheduling a retry.", shard.shardId(), shard.currentNodeId());, +                        logger.debug("Not enough active copies of shard [{}] to meet write consistency of [{}] (have {}, needed {}). Scheduling a retry.",, +                                shard.shardId(), consistencyLevel, shardIt.sizeActive(), requiredNumber);, +                                logger.debug("received an error from node the primary was assigned to ({}). Scheduling a retry", exp.getMessage());, +                logger.debug("Couldn't find a eligible primary shard. Scheduling for retry.");, +, +                        logger.debug("ShardRepOp: listener to cluster state added. Trying again");, +                        logger.debug("ShardRepOp: cluster changed (version {}). Trying again", event.state().version());, +            } else {, +                logger.debug("ShardRepOp: retry scheduling ignored as it was executed from an active cluster state listener");, +                    logger.debug("Had an error while performing operation on primary ({}). Scheduling a retry.", e.getMessage());, +++ b/src/test/java/org/elasticsearch/test/integration/TestCluster.java, +import java.util.concurrent.atomic.AtomicInteger;, +import static org.elasticsearch.common.settings.ImmutableSettings.settingsBuilder;, +    private AtomicInteger nextNodeId = new AtomicInteger(0);, +, +            logger.info("increasing cluster size from {} to {}", size, num);, +        logger.info("reducing cluster size from {} to {}", nodes.size() - num, num);, +        String name = "node_" + nextNodeId.getAndIncrement();, +++ b/src/test/java/org/elasticsearch/test/integration/search/basic/SearchWhileCreatingIndexTests.java, +, +        // make sure we have enough nodes to guaranty default QUORUM consistency., +        // TODO: add a smarter choice based on actual consistency (when that is randomized), +        int shardsNo = numberOfReplicas + 1;, +        int neededNodes = shardsNo <= 2 ? 1 : shardsNo / 2 + 1;, +        cluster().ensureAtLeastNumNodes(randomIntBetween(neededNodes, shardsNo));]