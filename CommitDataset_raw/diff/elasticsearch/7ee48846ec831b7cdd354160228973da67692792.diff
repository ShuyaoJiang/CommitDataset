[+++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/action/CloseJobAction.java, +        private String[] resolvedJobIds;, +, +        private boolean local;, +        public void setLocal(boolean local) {, +            this.local = local;, +        }, +, +            local = in.readBoolean();, +            out.writeBoolean(local);, +            if (request.local == false && nodes.isLocalNodeElectedMaster() == false) {, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/action/CloseJobAction.java, +        private String[] resolvedJobIds;, +, +        private boolean local;, +        public void setLocal(boolean local) {, +            this.local = local;, +        }, +, +            local = in.readBoolean();, +            out.writeBoolean(local);, +            if (request.local == false && nodes.isLocalNodeElectedMaster() == false) {, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/DatafeedManager.java, +                    /*, +                        Enforces that for the close job api call the current node is the coordinating node., +                        If we are in this callback then the local node's cluster state doesn't contain a persistent task, +                        for the datafeed and therefor the datafeed is stopped, so there is no need for the master node to, +                        be to coordinating node., +, +                        Normally close job and stop datafeed are both executed via master node and both apis use master, +                        node's local cluster state for validation purposes. In case of auto close this isn't the case and, +                        if the job runs on a regular node then it may see the update before the close job api does in, +                        the master node's local cluster state. This can cause the close job api the fail with a validation, +                        error that the datafeed isn't stopped. To avoid this we use the current node as coordinating node, +                        for the close job api call., +                    */, +                    closeJobRequest.setLocal(true);, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/action/CloseJobAction.java, +        private String[] resolvedJobIds;, +, +        private boolean local;, +        public void setLocal(boolean local) {, +            this.local = local;, +        }, +, +            local = in.readBoolean();, +            out.writeBoolean(local);, +            if (request.local == false && nodes.isLocalNodeElectedMaster() == false) {, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/DatafeedManager.java, +                    /*, +                        Enforces that for the close job api call the current node is the coordinating node., +                        If we are in this callback then the local node's cluster state doesn't contain a persistent task, +                        for the datafeed and therefor the datafeed is stopped, so there is no need for the master node to, +                        be to coordinating node., +, +                        Normally close job and stop datafeed are both executed via master node and both apis use master, +                        node's local cluster state for validation purposes. In case of auto close this isn't the case and, +                        if the job runs on a regular node then it may see the update before the close job api does in, +                        the master node's local cluster state. This can cause the close job api the fail with a validation, +                        error that the datafeed isn't stopped. To avoid this we use the current node as coordinating node, +                        for the close job api call., +                    */, +                    closeJobRequest.setLocal(true);, +++ b/plugin/src/test/java/org/elasticsearch/xpack/ml/integration/BasicDistributedJobsIT.java, +import org.elasticsearch.action.index.IndexRequest;, +    public void testJobAutoClose() throws Exception {, +        internalCluster().ensureAtMostNumDataNodes(0);, +        internalCluster().startNode(Settings.builder().put(MachineLearning.ML_ENABLED.getKey(), false));, +        internalCluster().startNode(Settings.builder().put(MachineLearning.ML_ENABLED.getKey(), true));, +, +        client().admin().indices().prepareCreate("data"), +                .addMapping("type", "time", "type=date"), +                .get();, +, +        IndexRequest indexRequest = new IndexRequest("data", "type");, +        indexRequest.source("time", 1407081600L);, +        client().index(indexRequest).get();, +        indexRequest = new IndexRequest("data", "type");, +        indexRequest.source("time", 1407082600L);, +        client().index(indexRequest).get();, +        indexRequest = new IndexRequest("data", "type");, +        indexRequest.source("time", 1407083600L);, +        client().index(indexRequest).get();, +        refresh();, +, +        Job.Builder job = createScheduledJob("job_id");, +        PutJobAction.Request putJobRequest = new PutJobAction.Request(job);, +        PutJobAction.Response putJobResponse = client().execute(PutJobAction.INSTANCE, putJobRequest).actionGet();, +        assertTrue(putJobResponse.isAcknowledged());, +, +        DatafeedConfig config = createDatafeed("data_feed_id", job.getId(), Collections.singletonList("data"));, +        PutDatafeedAction.Request putDatafeedRequest = new PutDatafeedAction.Request(config);, +        PutDatafeedAction.Response putDatadeedResponse = client().execute(PutDatafeedAction.INSTANCE, putDatafeedRequest), +                .actionGet();, +        assertTrue(putDatadeedResponse.isAcknowledged());, +, +        client().execute(OpenJobAction.INSTANCE, new OpenJobAction.Request(job.getId())).get();, +, +        StartDatafeedAction.Request startDatafeedRequest = new StartDatafeedAction.Request(config.getId(), 0L);, +        startDatafeedRequest.getParams().setEndTime(1492616844L);]