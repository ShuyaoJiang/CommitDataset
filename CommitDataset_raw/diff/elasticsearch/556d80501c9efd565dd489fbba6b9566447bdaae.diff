[+++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/InternalSignificantTerms.java, +                List<Bucket> existingBuckets = buckets.get(bucket.getKeyAsString());, +++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/InternalSignificantTerms.java, +                List<Bucket> existingBuckets = buckets.get(bucket.getKeyAsString());, +++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsBackwardCompatibilityIT.java, +     * Test for streaming significant terms buckets to old es versions., +        StringTerms classes = response.getAggregations().get("class");, +++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/InternalSignificantTerms.java, +                List<Bucket> existingBuckets = buckets.get(bucket.getKeyAsString());, +++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsBackwardCompatibilityIT.java, +     * Test for streaming significant terms buckets to old es versions., +        StringTerms classes = response.getAggregations().get("class");, +++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/significant/SignificanceHeuristicTests.java, +import org.elasticsearch.search.aggregations.InternalAggregation;, +import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;, +import org.elasticsearch.search.aggregations.support.format.ValueFormatter;, +import java.nio.charset.StandardCharsets;, +import java.util.*;, +import static org.hamcrest.Matchers.*;, +        InternalSignificantTerms.Bucket originalBucket = (InternalSignificantTerms.Bucket) sigTerms[0].buckets.get(0);, +        InternalSignificantTerms.Bucket streamedBucket = (InternalSignificantTerms.Bucket) sigTerms[1].buckets.get(0);, +        assertThat(originalBucket.getKeyAsString(), equalTo(streamedBucket.getKeyAsString()));, +        assertThat(originalBucket.getSupersetDf(), equalTo(streamedBucket.getSupersetDf()));, +        assertThat(originalBucket.getSubsetDf(), equalTo(streamedBucket.getSubsetDf()));, +        assertThat(streamedBucket.getSubsetSize(), equalTo(10l));, +        assertThat(streamedBucket.getSupersetSize(), equalTo(20l));, +    public void testReduce() {, +        List<InternalAggregation> aggs = createInternalAggregations();, +        SignificantTerms reducedAgg = (SignificantTerms) aggs.get(0).doReduce(aggs, null);, +        assertThat(reducedAgg.getBuckets().size(), equalTo(2));, +        assertThat(reducedAgg.getBuckets().get(0).getSubsetDf(), equalTo(8l));, +        assertThat(reducedAgg.getBuckets().get(0).getSubsetSize(), equalTo(16l));, +        assertThat(reducedAgg.getBuckets().get(0).getSupersetDf(), equalTo(10l));, +        assertThat(reducedAgg.getBuckets().get(0).getSupersetSize(), equalTo(30l));, +        assertThat(reducedAgg.getBuckets().get(1).getSubsetDf(), equalTo(8l));, +        assertThat(reducedAgg.getBuckets().get(1).getSubsetSize(), equalTo(16l));, +        assertThat(reducedAgg.getBuckets().get(1).getSupersetDf(), equalTo(10l));, +        assertThat(reducedAgg.getBuckets().get(1).getSupersetSize(), equalTo(30l));, +    }, +, +    // Create aggregations as they might come from three different shards and return as list., +    private List<InternalAggregation> createInternalAggregations() {, +, +        String type = randomBoolean() ? "long" : "string";, +        SignificanceHeuristic significanceHeuristic = getRandomSignificanceheuristic();, +, +        List<InternalAggregation> aggs = new ArrayList<>();, +        List<InternalSignificantTerms.Bucket> terms0Buckets = new ArrayList<>();, +        terms0Buckets.add(createBucket(type, 4, 4, 5, 10, 0));, +        aggs.add(createAggregation(type, significanceHeuristic, terms0Buckets, 4, 10));, +        List<InternalSignificantTerms.Bucket> terms1Buckets = new ArrayList<>();, +        terms0Buckets.add(createBucket(type, 4, 4, 5, 10, 1));, +        aggs.add(createAggregation(type, significanceHeuristic, terms1Buckets, 4, 10));, +        List<InternalSignificantTerms.Bucket> terms01Buckets = new ArrayList<>();, +        terms0Buckets.add(createBucket(type, 4, 8, 5, 10, 0));, +        terms0Buckets.add(createBucket(type, 4, 8, 5, 10, 1));, +        aggs.add(createAggregation(type, significanceHeuristic, terms01Buckets, 8, 10));, +        return aggs;, +    }, +, +    private InternalSignificantTerms createAggregation(String type, SignificanceHeuristic significanceHeuristic, List<InternalSignificantTerms.Bucket> buckets, long subsetSize, long supersetSize) {, +        if (type.equals("string")) {, +            return new SignificantStringTerms(subsetSize, supersetSize, "sig_terms", 2, -1, significanceHeuristic, buckets, new ArrayList<PipelineAggregator>(), new HashMap<String, Object>());, +        } else {, +            return new SignificantLongTerms(subsetSize, supersetSize, "sig_terms", ValueFormatter.RAW, 2, -1, significanceHeuristic, buckets, new ArrayList<PipelineAggregator>(), new HashMap<String, Object>());, +        }, +    }, +, +    private InternalSignificantTerms.Bucket createBucket(String type, long subsetDF, long subsetSize, long supersetDF, long supersetSize, long label) {, +        if (type.equals("string")) {, +            return new SignificantStringTerms.Bucket(new BytesRef(Long.toString(label).getBytes(StandardCharsets.UTF_8)), subsetDF, subsetSize, supersetDF, supersetSize, InternalAggregations.EMPTY);, +        } else {, +            return new SignificantLongTerms.Bucket(subsetDF, subsetSize, supersetDF, supersetSize, label, InternalAggregations.EMPTY, ValueFormatter.RAW);, +        }, +    }, +, +++ b/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/InternalSignificantTerms.java, +                List<Bucket> existingBuckets = buckets.get(bucket.getKeyAsString());, +++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsBackwardCompatibilityIT.java, +     * Test for streaming significant terms buckets to old es versions., +        StringTerms classes = response.getAggregations().get("class");, +++ b/core/src/test/java/org/elasticsearch/search/aggregations/bucket/significant/SignificanceHeuristicTests.java, +import org.elasticsearch.search.aggregations.InternalAggregation;, +import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator;, +import org.elasticsearch.search.aggregations.support.format.ValueFormatter;, +import java.nio.charset.StandardCharsets;, +import java.util.*;, +import static org.hamcrest.Matchers.*;, +        InternalSignificantTerms.Bucket originalBucket = (InternalSignificantTerms.Bucket) sigTerms[0].buckets.get(0);, +        InternalSignificantTerms.Bucket streamedBucket = (InternalSignificantTerms.Bucket) sigTerms[1].buckets.get(0);, +        assertThat(originalBucket.getKeyAsString(), equalTo(streamedBucket.getKeyAsString()));, +        assertThat(originalBucket.getSupersetDf(), equalTo(streamedBucket.getSupersetDf()));, +        assertThat(originalBucket.getSubsetDf(), equalTo(streamedBucket.getSubsetDf()));, +        assertThat(streamedBucket.getSubsetSize(), equalTo(10l));, +        assertThat(streamedBucket.getSupersetSize(), equalTo(20l));, +    public void testReduce() {, +        List<InternalAggregation> aggs = createInternalAggregations();, +        SignificantTerms reducedAgg = (SignificantTerms) aggs.get(0).doReduce(aggs, null);, +        assertThat(reducedAgg.getBuckets().size(), equalTo(2));, +        assertThat(reducedAgg.getBuckets().get(0).getSubsetDf(), equalTo(8l));]