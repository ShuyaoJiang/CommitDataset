[+++ b/src/main/java/org/elasticsearch/alerts/AlertManager.java, +import org.elasticsearch.cluster.ClusterState;, +import java.util.concurrent.atomic.AtomicReference;, +    private final ClusterService clusterService;, +    private final AtomicReference<State> state = new AtomicReference<>(State.STOPPED);, +        this.clusterService = clusterService;, +        return state.get() == State.STARTED;, +    // This is synchronized, because this may first be called from the cluster changed event and then from before close, +    // when a node closes. The stop also stops the scheduler which has several background threads. If this method is, +    // invoked in that order that node closes and the test framework complains then about the fact that there are still, +    // threads alive., +    public synchronized void stop() {, +        if (state.compareAndSet(State.LOADING, State.STOPPED) || state.compareAndSet(State.STARTED, State.STOPPED)) {, +            scheduler.stop();, +        if (state.get() != State.STARTED) {, +        public void clusterChanged(ClusterChangedEvent event) {, +                // We're no longer the master so we need to stop alerting., +                // Stopping alerting may take a while since it will wait on the scheduler to complete shutdown,, +                // so we fork here so that we don't wait too long. Other events may need to be processed and, +                // other cluster state listeners may need to be executed as well for this event., +                threadPool.executor(ThreadPool.Names.GENERIC).execute(new Runnable() {, +                    @Override, +                    public void run() {, +                    }, +                });, +                    // wait until the gateway has recovered from disk, otherwise we think may not have .alerts and, +                    // a .alertshistory index, but they may not have been restored from the cluster state on disk, +                    return;, +                }, +                if (state.compareAndSet(State.STOPPED, State.LOADING)) {, +                    initialize(event.state());, +                }, +            }, +        private void initialize(final ClusterState state) {, +            threadPool.executor(ThreadPool.Names.GENERIC).execute(new Runnable() {, +                public void run() {, +                    if (alertsStore.start(state)) {, +                    } else {, +                        retry();, +            threadPool.executor(ThreadPool.Names.GENERIC).execute(new Runnable() {, +                public void run() {, +                    if (actionManager.start(state)) {, +                    } else {, +                        retry();, +                if (state.compareAndSet(State.LOADING, State.STARTED)) {, +                } else {, +                    logger.info("Didn't start alert manager, because it state was [{}] while [{}] was expected", state.get(), State.LOADING);, +        private void retry() {, +            // Only retry if our state is loading, +            if (state.get() == State.LOADING) {, +                final ClusterState newState = clusterService.state();, +                        initialize(newState);, +            } else {, +                logger.info("Didn't retry to initialize the alert manager, because it state was [{}] while [{}] was expected", state.get(), State.LOADING);, +        }, +, +    }, +, +    private enum State {, +, +        STOPPED,, +        LOADING,, +        STARTED, +++ b/src/main/java/org/elasticsearch/alerts/AlertManager.java, +import org.elasticsearch.cluster.ClusterState;, +import java.util.concurrent.atomic.AtomicReference;, +    private final ClusterService clusterService;, +    private final AtomicReference<State> state = new AtomicReference<>(State.STOPPED);, +        this.clusterService = clusterService;, +        return state.get() == State.STARTED;, +    // This is synchronized, because this may first be called from the cluster changed event and then from before close, +    // when a node closes. The stop also stops the scheduler which has several background threads. If this method is, +    // invoked in that order that node closes and the test framework complains then about the fact that there are still, +    // threads alive., +    public synchronized void stop() {, +        if (state.compareAndSet(State.LOADING, State.STOPPED) || state.compareAndSet(State.STARTED, State.STOPPED)) {, +            scheduler.stop();, +        if (state.get() != State.STARTED) {, +        public void clusterChanged(ClusterChangedEvent event) {, +                // We're no longer the master so we need to stop alerting., +                // Stopping alerting may take a while since it will wait on the scheduler to complete shutdown,, +                // so we fork here so that we don't wait too long. Other events may need to be processed and, +                // other cluster state listeners may need to be executed as well for this event., +                threadPool.executor(ThreadPool.Names.GENERIC).execute(new Runnable() {, +                    @Override, +                    public void run() {, +                    }, +                });, +                    // wait until the gateway has recovered from disk, otherwise we think may not have .alerts and, +                    // a .alertshistory index, but they may not have been restored from the cluster state on disk, +                    return;, +                }, +                if (state.compareAndSet(State.STOPPED, State.LOADING)) {, +                    initialize(event.state());, +                }, +            }, +        private void initialize(final ClusterState state) {, +            threadPool.executor(ThreadPool.Names.GENERIC).execute(new Runnable() {, +                public void run() {, +                    if (alertsStore.start(state)) {]