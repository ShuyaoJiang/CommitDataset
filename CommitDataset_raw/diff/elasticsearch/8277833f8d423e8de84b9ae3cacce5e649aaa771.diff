[+++ b/src/main/java/org/elasticsearch/index/analysis/WordDelimiterTokenFilterFactory.java, +        flags |= getFlag(GENERATE_NUMBER_PARTS, settings, "generate_number_parts", true);, +        if (settings.getAsBoolean(key, defaultValue)) {, +        return 0;, +    }, +++ b/src/main/java/org/elasticsearch/index/analysis/WordDelimiterTokenFilterFactory.java, +        flags |= getFlag(GENERATE_NUMBER_PARTS, settings, "generate_number_parts", true);, +        if (settings.getAsBoolean(key, defaultValue)) {, +        return 0;, +    }, +++ b/src/test/java/org/elasticsearch/test/unit/index/analysis/WordDelimiterTokenFilterFactoryTests.java, +/*, + * Licensed to ElasticSearch and Shay Banon under one, + * or more contributor license agreements.  See the NOTICE file, + * distributed with this work for additional information, + * regarding copyright ownership. ElasticSearch licenses this, + * file to you under the Apache License, Version 2.0 (the, + * "License"); you may not use this file except in compliance, + * with the License.  You may obtain a copy of the License at, + *, + *    http://www.apache.org/licenses/LICENSE-2.0, + *, + * Unless required by applicable law or agreed to in writing,, + * software distributed under the License is distributed on an, + * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY, + * KIND, either express or implied.  See the License for the, + * specific language governing permissions and limitations, + * under the License., + */, +package org.elasticsearch.test.unit.index.analysis;, +, +, +import org.apache.lucene.analysis.Tokenizer;, +import org.apache.lucene.analysis.core.WhitespaceTokenizer;, +import org.apache.lucene.util.Version;, +import org.elasticsearch.index.analysis.AnalysisService;, +import org.elasticsearch.index.analysis.TokenFilterFactory;, +import org.testng.annotations.Test;, +, +import java.io.IOException;, +import java.io.StringReader;, +, +import static org.elasticsearch.common.settings.ImmutableSettings.settingsBuilder;, +, +public class WordDelimiterTokenFilterFactoryTests {, +, +    @Test, +    public void testDefault() throws IOException {, +        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settingsBuilder(), +                .put("index.analysis.filter.my_word_delimiter.type", "word_delimiter"), +                .build());, +        TokenFilterFactory tokenFilter = analysisService.tokenFilter("my_word_delimiter");, +        String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's";, +        String[] expected = new String[]{"Power", "Shot", "500", "42", "wi", "fi", "wi", "fi", "4000", "j", "2", "se", "O", "Neil"};, +        Tokenizer tokenizer = new WhitespaceTokenizer(Version.LUCENE_41, new StringReader(source));, +        AnalysisTestsHelper.assertSimpleTSOutput(tokenFilter.create(tokenizer), expected);, +    }, +, +    @Test, +    public void testCatenateWords() throws IOException {, +        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settingsBuilder(), +                .put("index.analysis.filter.my_word_delimiter.type", "word_delimiter"), +                .put("index.analysis.filter.my_word_delimiter.catenate_words", "true"), +                .put("index.analysis.filter.my_word_delimiter.generate_word_parts", "false"), +                .build());, +        TokenFilterFactory tokenFilter = analysisService.tokenFilter("my_word_delimiter");, +        String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's";, +        String[] expected = new String[]{"PowerShot", "500", "42", "wifi", "wifi", "4000", "j", "2", "se", "ONeil"};, +        Tokenizer tokenizer = new WhitespaceTokenizer(Version.LUCENE_41, new StringReader(source));, +        AnalysisTestsHelper.assertSimpleTSOutput(tokenFilter.create(tokenizer), expected);, +    }, +, +    @Test, +    public void testCatenateNumbers() throws IOException {, +        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settingsBuilder(), +                .put("index.analysis.filter.my_word_delimiter.type", "word_delimiter"), +                .put("index.analysis.filter.my_word_delimiter.generate_number_parts", "false"), +                .put("index.analysis.filter.my_word_delimiter.catenate_numbers", "true"), +                .build());, +        TokenFilterFactory tokenFilter = analysisService.tokenFilter("my_word_delimiter");, +        String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's";, +        String[] expected = new String[]{"Power", "Shot", "50042", "wi", "fi", "wi", "fi", "4000", "j", "2", "se", "O", "Neil"};, +        Tokenizer tokenizer = new WhitespaceTokenizer(Version.LUCENE_41, new StringReader(source));, +        AnalysisTestsHelper.assertSimpleTSOutput(tokenFilter.create(tokenizer), expected);, +    }, +, +    @Test, +    public void testCatenateAll() throws IOException {, +        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settingsBuilder(), +                .put("index.analysis.filter.my_word_delimiter.type", "word_delimiter"), +                .put("index.analysis.filter.my_word_delimiter.generate_word_parts", "false"), +                .put("index.analysis.filter.my_word_delimiter.generate_number_parts", "false"), +                .put("index.analysis.filter.my_word_delimiter.catenate_all", "true"), +                .build());, +        TokenFilterFactory tokenFilter = analysisService.tokenFilter("my_word_delimiter");, +        String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's";, +        String[] expected = new String[]{"PowerShot", "50042", "wifi", "wifi4000", "j2se", "ONeil"};, +        Tokenizer tokenizer = new WhitespaceTokenizer(Version.LUCENE_41, new StringReader(source));, +        AnalysisTestsHelper.assertSimpleTSOutput(tokenFilter.create(tokenizer), expected);, +    }]