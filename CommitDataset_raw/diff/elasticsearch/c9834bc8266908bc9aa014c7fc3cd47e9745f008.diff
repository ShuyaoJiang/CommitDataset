[+++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/extractor/aggregation/AggregationDataExtractor.java, +        try (AggregationToJsonProcessor processor = new AggregationToJsonProcessor(, +                context.timeField, context.includeDocCount, outputStream)) {, +                processor.process(histogramBuckets.removeFirst());, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/extractor/aggregation/AggregationDataExtractor.java, +        try (AggregationToJsonProcessor processor = new AggregationToJsonProcessor(, +                context.timeField, context.includeDocCount, outputStream)) {, +                processor.process(histogramBuckets.removeFirst());, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/extractor/aggregation/AggregationToJsonProcessor.java, +import org.elasticsearch.common.Nullable;, +import org.elasticsearch.search.aggregations.metrics.max.Max;, +import java.util.Objects;, + * In order to ensure that datafeeds can restart without duplicating data, we require that, + * each histogram bucket has a nested max aggregation matching the time_field., +    private final String timeField;, +    AggregationToJsonProcessor(String timeField, boolean includeDocCount, OutputStream outputStream), +            throws IOException {, +        this.timeField = Objects.requireNonNull(timeField);, +    public void process(Histogram.Bucket bucket) throws IOException {, +        if (bucket.getDocCount() == 0) {, +            return;, +        Aggregations aggs = bucket.getAggregations();, +        Aggregation timeAgg = aggs == null ? null : aggs.get(timeField);, +        if (timeAgg instanceof Max == false) {, +            throw new IllegalArgumentException("Missing max aggregation for time_field [" + timeField + "]");, +        }, +, +        // We want to handle the max time aggregation only at the bucket level., +        // So, we add the value here and then remove the aggregation before, +        // processing the rest of the sub aggs., +        long timestamp = (long) ((Max) timeAgg).value();, +        keyValuePairs.put(timeField, timestamp);, +        List<Aggregation> subAggs = new ArrayList<>(aggs.asList());, +        subAggs.remove(timeAgg);, +        processNestedAggs(bucket.getDocCount(), subAggs);, +    }, +, +    private void processNestedAggs(long docCount, List<Aggregation> aggs) throws IOException {, +            processNestedAggs(bucket.getDocCount(), asList(bucket.getAggregations()));, +, +    private static List<Aggregation> asList(@Nullable Aggregations aggs) {, +        return aggs == null ? Collections.emptyList() : aggs.asList();, +    }, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/extractor/aggregation/AggregationDataExtractor.java, +        try (AggregationToJsonProcessor processor = new AggregationToJsonProcessor(, +                context.timeField, context.includeDocCount, outputStream)) {, +                processor.process(histogramBuckets.removeFirst());, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/extractor/aggregation/AggregationToJsonProcessor.java, +import org.elasticsearch.common.Nullable;, +import org.elasticsearch.search.aggregations.metrics.max.Max;, +import java.util.Objects;, + * In order to ensure that datafeeds can restart without duplicating data, we require that, + * each histogram bucket has a nested max aggregation matching the time_field., +    private final String timeField;, +    AggregationToJsonProcessor(String timeField, boolean includeDocCount, OutputStream outputStream), +            throws IOException {, +        this.timeField = Objects.requireNonNull(timeField);, +    public void process(Histogram.Bucket bucket) throws IOException {, +        if (bucket.getDocCount() == 0) {, +            return;, +        Aggregations aggs = bucket.getAggregations();, +        Aggregation timeAgg = aggs == null ? null : aggs.get(timeField);, +        if (timeAgg instanceof Max == false) {, +            throw new IllegalArgumentException("Missing max aggregation for time_field [" + timeField + "]");, +        }, +, +        // We want to handle the max time aggregation only at the bucket level., +        // So, we add the value here and then remove the aggregation before, +        // processing the rest of the sub aggs., +        long timestamp = (long) ((Max) timeAgg).value();, +        keyValuePairs.put(timeField, timestamp);, +        List<Aggregation> subAggs = new ArrayList<>(aggs.asList());, +        subAggs.remove(timeAgg);, +        processNestedAggs(bucket.getDocCount(), subAggs);, +    }, +, +    private void processNestedAggs(long docCount, List<Aggregation> aggs) throws IOException {, +            processNestedAggs(bucket.getDocCount(), asList(bucket.getAggregations()));, +, +    private static List<Aggregation> asList(@Nullable Aggregations aggs) {, +        return aggs == null ? Collections.emptyList() : aggs.asList();, +    }, +++ b/plugin/src/test/java/org/elasticsearch/xpack/ml/datafeed/extractor/aggregation/AggregationDataExtractorTests.java, +import static org.elasticsearch.xpack.ml.datafeed.extractor.aggregation.AggregationTestUtils.createMax;, +                    createMax("time", 1999),, +                    createMax("time", 3999),, +        String expectedStream = "{\"time\":1999,\"airline\":\"a\",\"responsetime\":11.0,\"doc_count\":1} ", +                + "{\"time\":1999,\"airline\":\"b\",\"responsetime\":12.0,\"doc_count\":2} ", +                + "{\"time\":3999,\"airline\":\"c\",\"responsetime\":31.0,\"doc_count\":4} ", +                + "{\"time\":3999,\"airline\":\"b\",\"responsetime\":32.0,\"doc_count\":3}";, +            histogramBuckets.add(createHistogramBucket(timestamp, 3, Arrays.asList(createMax("time", timestamp))));, +            histogramBuckets.add(createHistogramBucket(timestamp, 3, Arrays.asList(createMax("time", timestamp))));, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/extractor/aggregation/AggregationDataExtractor.java, +        try (AggregationToJsonProcessor processor = new AggregationToJsonProcessor(, +                context.timeField, context.includeDocCount, outputStream)) {, +                processor.process(histogramBuckets.removeFirst());, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/extractor/aggregation/AggregationToJsonProcessor.java, +import org.elasticsearch.common.Nullable;, +import org.elasticsearch.search.aggregations.metrics.max.Max;, +import java.util.Objects;]