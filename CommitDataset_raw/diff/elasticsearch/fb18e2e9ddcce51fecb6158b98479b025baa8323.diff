[+++ b/docs/resiliency/index.asciidoc, += Resiliency Status, +, +:JIRA: https://issues.apache.org/jira/browse/LUCENE-, +:GIT:  https://github.com/elasticsearch/elasticsearch/issues/, +, +== Overview, +, +The team at Elasticsearch is committed to continuously improving both, +Elasticsearch and Apache Lucene to protect your data.  As with any distributed, +system, Elasticsearch is complex and has many moving parts, each of which can, +encounter edge cases that require proper handling.  Our resiliency project is, +an ongoing effort to find and fix these edge cases. If you want to keep up, +with all this project on GitHub, see our issues list under the tag, +https://github.com/elasticsearch/elasticsearch/issues?q=label%3Aresiliency[resiliency]., +, +While GitHub is great for sharing our work, it can be difficult to get an, +overview of the current state of affairs and the previous work that has been, +done from an issues list. This page provides an overview of all the, +resiliency-related issues that we are aware of, improvements that have already, +been made and current in-progress work. We’ve also listed some historical, +improvements throughout this page to provide the full context., +, +If you’re interested in more on how we approach ensuring resiliency in, +Elasticsearch, you may be interested in Igor Motov’s recent talk, +http://www.elasticsearch.org/videos/improving-elasticsearch-resiliency/[Improving Elasticsearch Resiliency]., +, +You may also be interested in our blog post, +http://www.elasticsearch.org/blog/resiliency-elasticsearch/[Resiliency in Elasticsearch],, +which details our thought processes when addressing resiliency in both, +Elasticsearch and the work our developers do upstream in Apache Lucene., +, +== Data Store Recommendations, +, +Some customers use Elasticsearch as a primary datastore, some set-up, +comprehensive back-up solutions using features such as our Snapshot and, +Restore, while others use Elasticsearch in conjunction with a data storage, +system like Hadoop or even flat files. Elasticsearch can be used for so many, +different use cases which is why we have created this page to make sure you, +are fully informed when you are architecting your system., +, +== Work in Progress, +, +[float], +=== Known Unknowns (STATUS: ONGOING), +, +We consider this topic to be the most important in our quest for, +resiliency. We put a tremendous amount of effort into testing, +Elasticsearch to simulate failures and randomize configuration to, +produce extreme conditions. In addition, our users are an important, +source of information on unexpected edge cases and your bug reports, +help us make fixes that ensure that our system continues to be, +resilient., +, +If you encounter an issue, https://github.com/elasticsearch/elasticsearch/issues[please report it]!, +, +We are committed to tracking down and fixing all the issues that are posted., +, +[float], +=== Loss of documents during network partition (STATUS: ONGOING), +, +If a network partition separates a node from the master, there is some window of time before the node detects it. The length of the window is dependent on the type of the partition. This window is extremely small if a socket is broken. More adversarial partitions, for example, silently dropping requests without breaking the socket can take longer (up to 3x30s using current defaults)., +, +If the node hosts a primary shard at the moment of partition, and ends up being isolated from the cluster (which could have resulted in {GIT}2488[split-brain] before), some documents that are being indexed into the primary may be lost if they fail to reach one of the allocated replicas (due to the partition) and that replica is later promoted to primary by the master. {GIT}7572[#7572], +, +A test to replicate this condition was added in {GIT}7493[#7493]., +, +[float], +=== Prevent use of known-bad Java versions (STATUS: ONGOING), +, +Certain versions of the JVM are known to have bugs which can cause index corruption.  {GIT}7580[#7580] prevents Elasticsearch startup if known bad versions are in use., +, +[float], +=== Lucene checksums phase 2 (STATUS:ONGOING), +, +When Lucene opens a segment for reading, it validates the checksum on the smaller segment files -- those which it reads entirely into memory -- but not the large files like term frequencies and positions, as this would be very expensive. During merges, term vectors and stored fields are validated, as long the segments being merged come from the same version of Lucene. Checksumming for term vectors and stored fields is important because merging consists of performing optimized byte copies. Term frequencies, term positions, payloads, doc values, and norms are currently not checked during merges, although Lucene provides the option to do so.  These files are less prone to silent corruption as they are actively decoded during merge, and so are more likely to throw exceptions if there is any corruption., +, +There are a few ongoing efforts to improve coverage:, +, +* {GIT}7360[#7360] validates checksums on all segment files during merges. (STATUS: ONGOING, fixed in 1.4.0.Beta), +* {JIRA}5842[LUCENE-5842] validates the structure of the checksum footer of the postings lists, doc values, stored fields and term vectors when opening a new segment, to ensure that these files have not been truncated. (STATUS: ONGOING, Fixed in Lucene 4.10 and 1.4.0.Beta), +* {JIRA}5894[LUCENE-5894] lays the groundwork for extending more efficient checksum validation to all files during optimized bulk merges, if possible. (STATUS: ONGOING, Fixed in Lucene 5.0), +* {GIT}7586[#7586] adds checksums for cluster and index state files. (STATUS: NOT STARTED), +, +[float], +=== Add per-segment and per-commit ID to help replication (STATUS: ONGOING), +, +{JIRA}5895[LUCENE-5895] adds a unique ID for each segment and each commit point. File-based replication (as performed by snapshot/restore) can use this ID to know whether the segment/commit on the source and destination machines are the same.  Fixed in Lucene 4.11., +, +[float], +=== Improving Zen Discovery (STATUS: ONGOING), +, +Recovery from failure is a complicated process, especially in an asychronous distributed system like Elasticsearch. With several processes happening in parallel, it is important to ensure that recovery proceeds swiftly and safely. While fixing the {GIT}2488[split-brain issue] we have been hunting down corner cases that were not handled optimally, adding tests to demonstrate the issues, and working on fixes:, +, +* Faster & better detection of master & node failures, including not trying to reconnect upon disconnect, fail on disconnect error on ping, verify cluster names in pings. Previously, Elasticsearch had to wait a bit for the node to complete the process required to join the cluster. Recent changes guarantee that a node has fully joined the cluster before we start the fault detection process. Therefore we can do an immediate check causing faster detection of errors and validation of cluster state after a minimum master node breach. {GIT}6706[#6706], {GIT}7399[#7399] (STATUS: DONE, v1.4.0.Beta), +* Broaden Unicast pinging when master fails: When a node loses it’s current master it will start pinging to find a new one. Previously, when using unicast based pinging, the node would ping a set of predefined nodes asking them whether the master had really disappeared or whether there was a network hiccup. Now, we ping all nodes in the cluster to increase coverage. In the case that all unicast hosts are disconnected from the current master during a network failure, this improvement is essential to allow the cluster to reform once the partition is healed. {GIT}7336[#7336] (STATUS: DONE, v1.4.0.Beta), +* After joining a cluster, validate that the join was successful and that the master has been set in the local cluster state. {GIT}6969[#6969]. (STATUS: DONE, v1.4.0.Beta), +* Write additional tests that use the test infrastructure to verify proper behavior during network disconnections and garbage collections. {GIT}7082[#7082] (STATUS: ONGOING), +* Make write calls return the number of total/successful/missing shards in the same way that we do in search, which ensures transparency in the consistency of write operations. (STATUS: NOT STARTED), +]