[+++ b/src/main/java/org/elasticsearch/common/bytes/PagedBytesReference.java, +        private final BytesRef ref;, +            this.ref = new BytesRef();, +        public int read(final byte[] b, final int bOffset, final int len) throws IOException {, +            int todo = Math.min(len, length);, +            // current offset into the underlying ByteArray, +            long bytearrayOffset = offset + pos;, +, +            // bytes already copied, +, +            while (written < todo) {, +                long pagefragment = PAGE_SIZE - (bytearrayOffset % PAGE_SIZE); // how much can we read until hitting N*PAGE_SIZE?, +                int bulksize = (int)Math.min(pagefragment, todo - written); // we cannot copy more than a page fragment, +                boolean copied = bytearray.get(bytearrayOffset, bulksize, ref); // get the fragment, +                assert (copied == false); // we should never ever get back a materialized byte[], +                System.arraycopy(ref.bytes, ref.offset, b, bOffset + written, bulksize); // copy fragment contents, +                written += bulksize; // count how much we copied, +                bytearrayOffset += bulksize; // advance ByteArray index, +            pos += written; // finally advance our stream position, +++ b/src/main/java/org/elasticsearch/common/bytes/PagedBytesReference.java, +        private final BytesRef ref;, +            this.ref = new BytesRef();, +        public int read(final byte[] b, final int bOffset, final int len) throws IOException {, +            int todo = Math.min(len, length);, +            // current offset into the underlying ByteArray, +            long bytearrayOffset = offset + pos;, +, +            // bytes already copied, +, +            while (written < todo) {, +                long pagefragment = PAGE_SIZE - (bytearrayOffset % PAGE_SIZE); // how much can we read until hitting N*PAGE_SIZE?, +                int bulksize = (int)Math.min(pagefragment, todo - written); // we cannot copy more than a page fragment, +                boolean copied = bytearray.get(bytearrayOffset, bulksize, ref); // get the fragment, +                assert (copied == false); // we should never ever get back a materialized byte[], +                System.arraycopy(ref.bytes, ref.offset, b, bOffset + written, bulksize); // copy fragment contents, +                written += bulksize; // count how much we copied, +                bytearrayOffset += bulksize; // advance ByteArray index, +            pos += written; // finally advance our stream position, +++ b/src/test/java/org/elasticsearch/common/bytes/PagedBytesReferenceTest.java, +        int length = randomIntBetween(10, scaledRandomIntBetween(PAGE_SIZE * 2, PAGE_SIZE * 20));, +, +        // reset the stream for bulk reading, +    public void testStreamInputBulkReadWithOffset() throws IOException {, +        int length = randomIntBetween(10, scaledRandomIntBetween(PAGE_SIZE * 2, PAGE_SIZE * 20));, +        assertNotNull(si);, +, +        // read a bunch of single bytes one by one, +        int offset = randomIntBetween(1, length / 2);, +        for (int i = 0; i < offset ; i++) {, +            assertEquals(pbr.get(i), si.readByte());, +        }, +, +        // now do NOT reset the stream - keep the stream's offset!, +, +        // buffer to compare remaining bytes against bulk read, +        byte[] pbrBytesWithOffset = Arrays.copyOfRange(pbr.toBytes(), offset, length);, +        // randomized target buffer to ensure no stale slots, +        byte[] targetBytes = new byte[pbrBytesWithOffset.length];, +        getRandom().nextBytes(targetBytes);, +, +        // bulk-read all, +        si.readFully(targetBytes);, +        assertArrayEquals(pbrBytesWithOffset, targetBytes);, +    }, +, +    public void testSliceStreamInput() throws IOException {, +        int length = randomIntBetween(10, scaledRandomIntBetween(PAGE_SIZE * 2, PAGE_SIZE * 20));, +        BytesReference pbr = getRandomizedPagedBytesReference(length);, +, +        // reset the slice stream for bulk reading, +        sliceInput.reset();]