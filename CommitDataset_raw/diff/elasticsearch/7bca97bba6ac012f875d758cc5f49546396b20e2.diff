[+++ b/build.gradle, +      javadoc.options.encoding='UTF8', +++ b/build.gradle, +      javadoc.options.encoding='UTF8', +++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java, +            "repository-hdfs",, +++ b/build.gradle, +      javadoc.options.encoding='UTF8', +++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java, +            "repository-hdfs",, +++ b/core/src/main/resources/org/elasticsearch/plugins/plugin-install.help, +    - repository-hdfs, +++ b/build.gradle, +      javadoc.options.encoding='UTF8', +++ b/core/src/main/java/org/elasticsearch/plugins/PluginManager.java, +            "repository-hdfs",, +++ b/core/src/main/resources/org/elasticsearch/plugins/plugin-install.help, +    - repository-hdfs, +++ b/docs/plugins/repository-hdfs.asciidoc, +[[repository-hdfs]], +=== Hadoop HDFS Repository Plugin, +, +The HDFS repository plugin adds support for using HDFS File System as a repository for, +{ref}/modules-snapshots.html[Snapshot/Restore]., +, +[[repository-hdfs-install]], +[float], +==== Installation, +, +This plugin can be installed using the plugin manager:, +, +[source,sh], +----------------------------------------------------------------, +sudo bin/plugin install repository-hdfs, +sudo bin/plugin install repository-hdfs-hadoop2, +sudo bin/plugin install repository-hdfs-lite, +----------------------------------------------------------------, +, +The plugin must be installed on every node in the cluster, and each node must, +be restarted after installation., +, +[[repository-hdfs-remove]], +[float], +==== Removal, +, +The plugin can be removed with the following command:, +, +[source,sh], +----------------------------------------------------------------, +sudo bin/plugin remove repository-hdfs, +sudo bin/plugin remove repository-hdfs-hadoop2, +sudo bin/plugin remove repository-hdfs-lite, +----------------------------------------------------------------, +, +The node must be stopped before removing the plugin., +, +[[repository-hdfs-usage]], +==== Getting started with HDFS, +, +The HDFS snapshot/restore plugin comes in three _flavors_:, +, +* Default / Hadoop 1.x::, +The default version contains the plugin jar alongside Apache Hadoop 1.x (stable) dependencies., +* YARN / Hadoop 2.x::, +The `hadoop2` version contains the plugin jar plus the Apache Hadoop 2.x (also known as YARN) dependencies., +* Lite::, +The `lite` version contains just the plugin jar, without any Hadoop dependencies. The user should provide these (read below)., +, +[[repository-hdfs-flavor]], +===== What version to use?, +, +It depends on whether Hadoop is locally installed or not and if not, whether it is compatible with Apache Hadoop clients., +, +* Are you using Apache Hadoop (or a _compatible_ distro) and do not have installed on the Elasticsearch nodes?::, ++, +If the answer is yes, for Apache Hadoop 1 use the default `repository-hdfs` or `repository-hdfs-hadoop2` for Apache Hadoop 2., ++, +* If you are have Hadoop installed locally on the Elasticsearch nodes or are using a certain distro::, ++, +Use the `lite` version and place your Hadoop _client_ jars and their dependencies in the plugin folder under `hadoop-libs`., +For large deployments, it is recommended to package the libraries in the plugin zip and deploy it manually across nodes , +(and thus avoiding having to do the libraries setup on each node)., +, +[[repository-hdfs-security]], +==== Handling JVM Security and Permissions, +, +Out of the box, Elasticsearch runs in a JVM with the security manager turned _on_ to make sure that unsafe or sensitive actions, +are allowed only from trusted code. Hadoop however is not really designed to run under one; it does not rely on privileged blocks, +to execute sensitive code, of which it uses plenty., +, +The `repository-hdfs` plugin provides the necessary permissions for both Apache Hadoop 1.x and 2.x (latest versions) to successfully, +run in a secured JVM as one can tell from the number of permissions required when installing the plugin., +However using a certain Hadoop File-System (outside DFS), a certain distro or operating system (in particular Windows), might require , +additional permissions which are not provided by the plugin., +, +In this case there are several workarounds:, +* add the permission into `plugin-security.policy` (available in the plugin folder), +* disable the security manager through `es.security.manager.enabled=false` configurations setting - NOT RECOMMENDED, +, +If you find yourself in such a situation, please let us know what Hadoop distro version and OS you are using and what permission is missing]