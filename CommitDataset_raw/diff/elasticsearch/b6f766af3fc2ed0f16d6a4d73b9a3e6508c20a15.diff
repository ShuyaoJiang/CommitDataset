[+++ b/src/main/java/org/apache/lucene/search/vectorhighlight/CustomFieldQuery.java, +import org.elasticsearch.common.lucene.search.MultiPhrasePrefixQuery;, +import org.elasticsearch.common.lucene.search.TermFilter;, +import org.elasticsearch.common.lucene.search.XBooleanFilter;, +import org.elasticsearch.common.lucene.search.XFilteredQuery;, +++ b/src/main/java/org/apache/lucene/search/vectorhighlight/CustomFieldQuery.java, +import org.elasticsearch.common.lucene.search.MultiPhrasePrefixQuery;, +import org.elasticsearch.common.lucene.search.TermFilter;, +import org.elasticsearch.common.lucene.search.XBooleanFilter;, +import org.elasticsearch.common.lucene.search.XFilteredQuery;, +++ b/src/main/java/org/elasticsearch/common/lucene/search/XTermsFilter.java, +import org.apache.lucene.util.ArrayUtil;, +import java.util.*;, + * Constructs a filter for docs matching any of the terms added to this class., + * Unlike a RangeFilter this can be used for filtering on multiple terms that are not necessarily in, + * a sequence. An example might be a collection of primary keys from a database query result or perhaps, + * a choice of "category" labels picked by the end user. As a filter, this is much faster than the, + * equivalent query (a BooleanQuery with many "should" TermQueries), +// LUCENE 4.1 UPGRADE: Just use TermsFilter once upgrading to 4.1, its a copy, +public final class XTermsFilter extends Filter {, +    /*, +     * this class is often used for large number of terms in a single field., +     * to optimize for this case and to be filter-cache friendly we, +     * serialize all terms into a single byte array and store offsets, +     * in a parallel array to keep the # of object constant and speed up, +     * equals / hashcode., +     *, +     * This adds quite a bit of complexity but allows large term filters to, +     * be efficient for GC and cache-lookups, +     */, +    private final int[] offsets;, +    private final byte[] termsBytes;, +    private final TermsAndField[] termsAndFields;, +    private final int hashCode; // cached hashcode for fast cache lookups, +    private static final int PRIME = 31;, +     * Creates a new {@link XTermsFilter} from the given list. The list, +    public XTermsFilter(final List<Term> terms) {, +        this(new FieldAndTermEnum() {, +            // we need to sort for deduplication and to have a common cache key, +            final Iterator<Term> iter = sort(terms).iterator();, +, +            @Override, +            public BytesRef next() {, +                if (iter.hasNext()) {, +                    Term next = iter.next();, +                    field = next.field();, +                    return next.bytes();, +                }, +                return null;, +            }, +        }, terms.size());, +    }, +, +    /**, +     * Creates a new {@link XTermsFilter} from the given {@link BytesRef} list for, +     * a single field., +     */, +    public XTermsFilter(final String field, final List<BytesRef> terms) {, +        this(new FieldAndTermEnum(field) {, +            // we need to sort for deduplication and to have a common cache key, +            final Iterator<BytesRef> iter = sort(terms).iterator();, +, +            @Override, +            public BytesRef next() {, +                if (iter.hasNext()) {, +                    return iter.next();, +                }, +                return null;, +            }, +        }, terms.size());, +    }, +, +    /**, +     * Creates a new {@link XTermsFilter} from the given {@link BytesRef} array for, +     * a single field., +     */, +    public XTermsFilter(final String field, final BytesRef... terms) {, +        // this ctor prevents unnecessary Term creations, +        this(field, Arrays.asList(terms));, +    public XTermsFilter(final Term... terms) {, +        this(Arrays.asList(terms));, +, +, +    private XTermsFilter(FieldAndTermEnum iter, int length) {, +        // TODO: maybe use oal.index.PrefixCodedTerms instead?, +        // If number of terms is more than a few hundred it, +        // should be a win, +, +        // TODO: we also pack terms in FieldCache/DocValues, +        // ... maybe we can refactor to share that code, +, +        // TODO: yet another option is to build the union of the terms in, +        // an automaton an call intersect on the termsenum if the density is high, +, +        int hash = 9;, +        byte[] serializedTerms = new byte[0];, +        this.offsets = new int[length + 1];, +        int lastEndOffset = 0;, +        ArrayList<TermsAndField> termsAndFields = new ArrayList<TermsAndField>();, +        TermsAndField lastTermsAndField = null;]