[+++ b/docs/reference/mapping/types/keyword.asciidoc, +`split_queries_on_whitespace`::, +, +    Whether <<full-text-queries,full text queries>> should split the input on whitespace, +    when building a query for this field., +    Accepts `true` or `false` (default)., +, +++ b/docs/reference/mapping/types/keyword.asciidoc, +`split_queries_on_whitespace`::, +, +    Whether <<full-text-queries,full text queries>> should split the input on whitespace, +    when building a query for this field., +    Accepts `true` or `false` (default)., +, +++ b/server/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java, +            try (IndexAnalyzers fakeIndexAnalzyers = new IndexAnalyzers(indexSettings, fakeDefault, fakeDefault, fakeDefault, analyzerMap, analyzerMap, analyzerMap)) {, +++ b/docs/reference/mapping/types/keyword.asciidoc, +`split_queries_on_whitespace`::, +, +    Whether <<full-text-queries,full text queries>> should split the input on whitespace, +    when building a query for this field., +    Accepts `true` or `false` (default)., +, +++ b/server/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java, +            try (IndexAnalyzers fakeIndexAnalzyers = new IndexAnalyzers(indexSettings, fakeDefault, fakeDefault, fakeDefault, analyzerMap, analyzerMap, analyzerMap)) {, +++ b/server/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java, +import org.apache.lucene.analysis.core.WhitespaceTokenizer;, +        Map<String, NamedAnalyzer> whitespaceNormalizers = new HashMap<>();, +                    "keyword", tokenizerFactoryFactories.get("keyword"), tokenFilterFactoryFactories, charFilterFactoryFactories);, +            processNormalizerFactory(entry.getKey(), entry.getValue(), whitespaceNormalizers,, +                    "whitespace", () -> new WhitespaceTokenizer(), tokenFilterFactoryFactories, charFilterFactoryFactories);, +            unmodifiableMap(analyzers), unmodifiableMap(normalizers), unmodifiableMap(whitespaceNormalizers));, +            String tokenizerName,, +            TokenizerFactory tokenizerFactory,, +        if (tokenizerFactory == null) {, +            ((CustomNormalizerProvider) normalizerFactory).build(tokenizerName, tokenizerFactory, charFilters, tokenFilters);, +++ b/docs/reference/mapping/types/keyword.asciidoc, +`split_queries_on_whitespace`::, +, +    Whether <<full-text-queries,full text queries>> should split the input on whitespace, +    when building a query for this field., +    Accepts `true` or `false` (default)., +, +++ b/server/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java, +            try (IndexAnalyzers fakeIndexAnalzyers = new IndexAnalyzers(indexSettings, fakeDefault, fakeDefault, fakeDefault, analyzerMap, analyzerMap, analyzerMap)) {, +++ b/server/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java, +import org.apache.lucene.analysis.core.WhitespaceTokenizer;, +        Map<String, NamedAnalyzer> whitespaceNormalizers = new HashMap<>();, +                    "keyword", tokenizerFactoryFactories.get("keyword"), tokenFilterFactoryFactories, charFilterFactoryFactories);, +            processNormalizerFactory(entry.getKey(), entry.getValue(), whitespaceNormalizers,, +                    "whitespace", () -> new WhitespaceTokenizer(), tokenFilterFactoryFactories, charFilterFactoryFactories);, +            unmodifiableMap(analyzers), unmodifiableMap(normalizers), unmodifiableMap(whitespaceNormalizers));, +            String tokenizerName,, +            TokenizerFactory tokenizerFactory,, +        if (tokenizerFactory == null) {, +            ((CustomNormalizerProvider) normalizerFactory).build(tokenizerName, tokenizerFactory, charFilters, tokenFilters);, +++ b/server/src/main/java/org/elasticsearch/index/analysis/CustomNormalizerProvider.java, +    public void build(final String tokenizerName, final TokenizerFactory tokenizerFactory, final Map<String, CharFilterFactory> charFilters,, +        if (analyzerSettings.get("tokenizer") != null) {, +                tokenizerName,, +                tokenizerFactory,, +++ b/docs/reference/mapping/types/keyword.asciidoc, +`split_queries_on_whitespace`::, +, +    Whether <<full-text-queries,full text queries>> should split the input on whitespace, +    when building a query for this field., +    Accepts `true` or `false` (default)., +, +++ b/server/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java, +            try (IndexAnalyzers fakeIndexAnalzyers = new IndexAnalyzers(indexSettings, fakeDefault, fakeDefault, fakeDefault, analyzerMap, analyzerMap, analyzerMap)) {, +++ b/server/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java, +import org.apache.lucene.analysis.core.WhitespaceTokenizer;, +        Map<String, NamedAnalyzer> whitespaceNormalizers = new HashMap<>();, +                    "keyword", tokenizerFactoryFactories.get("keyword"), tokenFilterFactoryFactories, charFilterFactoryFactories);, +            processNormalizerFactory(entry.getKey(), entry.getValue(), whitespaceNormalizers,, +                    "whitespace", () -> new WhitespaceTokenizer(), tokenFilterFactoryFactories, charFilterFactoryFactories);, +            unmodifiableMap(analyzers), unmodifiableMap(normalizers), unmodifiableMap(whitespaceNormalizers));, +            String tokenizerName,, +            TokenizerFactory tokenizerFactory,, +        if (tokenizerFactory == null) {, +            ((CustomNormalizerProvider) normalizerFactory).build(tokenizerName, tokenizerFactory, charFilters, tokenFilters);, +++ b/server/src/main/java/org/elasticsearch/index/analysis/CustomNormalizerProvider.java, +    public void build(final String tokenizerName, final TokenizerFactory tokenizerFactory, final Map<String, CharFilterFactory> charFilters,, +        if (analyzerSettings.get("tokenizer") != null) {, +                tokenizerName,, +                tokenizerFactory,, +++ b/server/src/main/java/org/elasticsearch/index/analysis/IndexAnalyzers.java, +    private final Map<String, NamedAnalyzer> whitespaceNormalizers;, +                          Map<String, NamedAnalyzer> normalizers, Map<String, NamedAnalyzer> whitespaceNormalizers) {, +        this.whitespaceNormalizers = whitespaceNormalizers;, +     * Returns a normalizer that splits on whitespace mapped to the given name or <code>null</code> if not present, +     */, +    public NamedAnalyzer getWhitespaceNormalizer(String name) {, +        return whitespaceNormalizers.get(name);, +    }, +, +    /**, +++ b/docs/reference/mapping/types/keyword.asciidoc, +`split_queries_on_whitespace`::, +]