[+++ b/src/main/java/org/elasticsearch/cluster/routing/operation/hash/djb/DjbHashFunction.java, +    public static int DJB_HASH(byte[] value, int offset, int length) {, +        long hash = 5381;, +, +        final int end = offset + length;, +        for (int i = offset; i < end; i++) {, +            hash = ((hash << 5) + hash) + value[i];, +        }, +, +        return (int) hash;, +    }, +, +++ b/src/main/java/org/elasticsearch/cluster/routing/operation/hash/djb/DjbHashFunction.java, +    public static int DJB_HASH(byte[] value, int offset, int length) {, +        long hash = 5381;, +, +        final int end = offset + length;, +        for (int i = offset; i < end; i++) {, +            hash = ((hash << 5) + hash) + value[i];, +        }, +, +        return (int) hash;, +    }, +, +++ b/src/main/java/org/elasticsearch/common/lucene/uid/UidField.java, +++ b/src/main/java/org/elasticsearch/cluster/routing/operation/hash/djb/DjbHashFunction.java, +    public static int DJB_HASH(byte[] value, int offset, int length) {, +        long hash = 5381;, +, +        final int end = offset + length;, +        for (int i = offset; i < end; i++) {, +            hash = ((hash << 5) + hash) + value[i];, +        }, +, +        return (int) hash;, +    }, +, +++ b/src/main/java/org/elasticsearch/common/lucene/uid/UidField.java, +++ b/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java, +import org.apache.lucene.util.BytesRef;, +import org.elasticsearch.common.lucene.HashedBytesRef;, +    // A uid (in the form of BytesRef) to the version map, +    // we use the hashed variant since we iterate over it and check removal and additions on existing keys, +    private final ConcurrentMap<HashedBytesRef, VersionValue> versionMap;, +                VersionValue versionValue = versionMap.get(versionKey(get.uid()));, +            VersionValue versionValue = versionMap.get(versionKey(create.uid()));, +            versionMap.put(versionKey(create.uid()), new VersionValue(updatedVersion, false, threadPool.estimatedTimeInMillis(), translogLocation));, +            VersionValue versionValue = versionMap.get(versionKey(index.uid()));, +            versionMap.put(versionKey(index.uid()), new VersionValue(updatedVersion, false, threadPool.estimatedTimeInMillis(), translogLocation));, +            VersionValue versionValue = versionMap.get(versionKey(delete.uid()));, +                versionMap.put(versionKey(delete.uid()), new VersionValue(updatedVersion, true, threadPool.estimatedTimeInMillis(), translogLocation));, +                versionMap.put(versionKey(delete.uid()), new VersionValue(updatedVersion, true, threadPool.estimatedTimeInMillis(), translogLocation));, +                versionMap.put(versionKey(delete.uid()), new VersionValue(updatedVersion, true, threadPool.estimatedTimeInMillis(), translogLocation));, +        for (Map.Entry<HashedBytesRef, VersionValue> entry : versionMap.entrySet()) {, +            HashedBytesRef uid = entry.getKey();, +            synchronized (dirtyLock(uid.bytes)) { // can we do it without this lock on each value? maybe batch to a set and get the lock once per set?, +                VersionValue versionValue = versionMap.get(uid);, +                        versionMap.remove(uid);, +                    versionMap.remove(uid);, +    private HashedBytesRef versionKey(Term uid) {, +        return new HashedBytesRef(uid.bytes());, +    }, +, +    private Object dirtyLock(BytesRef uid) {, +        int hash = DjbHashFunction.DJB_HASH(uid.bytes, uid.offset, uid.length);, +        return dirtyLock(uid.bytes());]