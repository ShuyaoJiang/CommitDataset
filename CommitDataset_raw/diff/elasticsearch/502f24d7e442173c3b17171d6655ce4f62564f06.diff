[+++ b/src/main/java/org/elasticsearch/percolator/MultiDocumentPercolatorIndex.java, +import org.apache.lucene.util.CloseableThreadLocal;, +import java.util.List;, +/**, + * Implementation of {@link PercolatorIndex} that can hold multiple Lucene documents by, + * opening multiple {@link MemoryIndex} based IndexReaders and wrapping them via a single top level reader., + */, +    private final CloseableThreadLocal<MemoryIndex> cache;, +, +    MultiDocumentPercolatorIndex(CloseableThreadLocal<MemoryIndex> cache) {, +        this.cache = cache;, +        List<ParseContext.Document> docs = parsedDocument.docs();, +        int rootDocIndex = docs.size() - 1;, +        assert rootDocIndex > 0;, +        MemoryIndex rootDocMemoryIndex = null;, +        for (int i = 0; i < docs.size(); i++) {, +            ParseContext.Document d = docs.get(i);, +            MemoryIndex memoryIndex;, +            if (rootDocIndex == i) {, +                // the last doc is always the rootDoc, since that is usually the biggest document it make sense, +                // to reuse the MemoryIndex it uses, +                memoryIndex = rootDocMemoryIndex = cache.get();, +            } else {, +                memoryIndex = new MemoryIndex(true);, +            }, +            memoryIndices[i] = indexDoc(d, parsedDocument.analyzer(), memoryIndex).createSearcher().getIndexReader();, +            DocSearcher docSearcher = new DocSearcher(new IndexSearcher(slowReader), rootDocMemoryIndex);, +    MemoryIndex indexDoc(ParseContext.Document d, Analyzer analyzer, MemoryIndex memoryIndex) {, +        private final MemoryIndex rootDocMemoryIndex;, +        private DocSearcher(IndexSearcher searcher, MemoryIndex rootDocMemoryIndex) {, +            this.rootDocMemoryIndex = rootDocMemoryIndex;, +                rootDocMemoryIndex.reset();, +++ b/src/main/java/org/elasticsearch/percolator/MultiDocumentPercolatorIndex.java, +import org.apache.lucene.util.CloseableThreadLocal;, +import java.util.List;, +/**, + * Implementation of {@link PercolatorIndex} that can hold multiple Lucene documents by, + * opening multiple {@link MemoryIndex} based IndexReaders and wrapping them via a single top level reader., + */, +    private final CloseableThreadLocal<MemoryIndex> cache;, +, +    MultiDocumentPercolatorIndex(CloseableThreadLocal<MemoryIndex> cache) {, +        this.cache = cache;, +        List<ParseContext.Document> docs = parsedDocument.docs();, +        int rootDocIndex = docs.size() - 1;, +        assert rootDocIndex > 0;, +        MemoryIndex rootDocMemoryIndex = null;, +        for (int i = 0; i < docs.size(); i++) {, +            ParseContext.Document d = docs.get(i);, +            MemoryIndex memoryIndex;, +            if (rootDocIndex == i) {, +                // the last doc is always the rootDoc, since that is usually the biggest document it make sense, +                // to reuse the MemoryIndex it uses, +                memoryIndex = rootDocMemoryIndex = cache.get();, +            } else {, +                memoryIndex = new MemoryIndex(true);, +            }, +            memoryIndices[i] = indexDoc(d, parsedDocument.analyzer(), memoryIndex).createSearcher().getIndexReader();, +            DocSearcher docSearcher = new DocSearcher(new IndexSearcher(slowReader), rootDocMemoryIndex);, +    MemoryIndex indexDoc(ParseContext.Document d, Analyzer analyzer, MemoryIndex memoryIndex) {, +        private final MemoryIndex rootDocMemoryIndex;, +        private DocSearcher(IndexSearcher searcher, MemoryIndex rootDocMemoryIndex) {, +            this.rootDocMemoryIndex = rootDocMemoryIndex;, +                rootDocMemoryIndex.reset();, +++ b/src/main/java/org/elasticsearch/percolator/PercolatorIndex.java, +/**, + * Abstraction on how to index the percolator document., + */, +++ b/src/main/java/org/elasticsearch/percolator/MultiDocumentPercolatorIndex.java, +import org.apache.lucene.util.CloseableThreadLocal;, +import java.util.List;, +/**, + * Implementation of {@link PercolatorIndex} that can hold multiple Lucene documents by, + * opening multiple {@link MemoryIndex} based IndexReaders and wrapping them via a single top level reader., + */, +    private final CloseableThreadLocal<MemoryIndex> cache;, +, +    MultiDocumentPercolatorIndex(CloseableThreadLocal<MemoryIndex> cache) {, +        this.cache = cache;, +        List<ParseContext.Document> docs = parsedDocument.docs();, +        int rootDocIndex = docs.size() - 1;, +        assert rootDocIndex > 0;, +        MemoryIndex rootDocMemoryIndex = null;, +        for (int i = 0; i < docs.size(); i++) {, +            ParseContext.Document d = docs.get(i);, +            MemoryIndex memoryIndex;, +            if (rootDocIndex == i) {, +                // the last doc is always the rootDoc, since that is usually the biggest document it make sense, +                // to reuse the MemoryIndex it uses, +                memoryIndex = rootDocMemoryIndex = cache.get();, +            } else {, +                memoryIndex = new MemoryIndex(true);, +            }, +            memoryIndices[i] = indexDoc(d, parsedDocument.analyzer(), memoryIndex).createSearcher().getIndexReader();, +            DocSearcher docSearcher = new DocSearcher(new IndexSearcher(slowReader), rootDocMemoryIndex);, +    MemoryIndex indexDoc(ParseContext.Document d, Analyzer analyzer, MemoryIndex memoryIndex) {, +        private final MemoryIndex rootDocMemoryIndex;, +        private DocSearcher(IndexSearcher searcher, MemoryIndex rootDocMemoryIndex) {, +            this.rootDocMemoryIndex = rootDocMemoryIndex;, +                rootDocMemoryIndex.reset();]