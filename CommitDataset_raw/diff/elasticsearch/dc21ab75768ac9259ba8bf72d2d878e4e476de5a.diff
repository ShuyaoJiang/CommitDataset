[+++ b/docs/reference/analysis/tokenizers/standard-tokenizer.asciidoc, +exceeds this length then it is split at `max_token_length` intervals. Defaults to `255`.]