[+++ b/docs/community/integrations.asciidoc, +  Thin asynchronous scala client for storehaus., +++ b/docs/community/integrations.asciidoc, +  Thin asynchronous scala client for storehaus., +++ b/docs/groovy-api/anatomy.asciidoc, +    pritnln "Indexed $response.id into $response.index/$response.type", +++ b/docs/community/integrations.asciidoc, +  Thin asynchronous scala client for storehaus., +++ b/docs/groovy-api/anatomy.asciidoc, +    pritnln "Indexed $response.id into $response.index/$response.type", +++ b/docs/java-api/query-dsl-filters.asciidoc, +elasticsearch provides a full Java query dsl in a similar manner to the, +<8> distance computation mode: `GeoDistance.SLOPPY_ARC` (default), `GeoDistance.ARC` (slighly more precise but, +++ b/docs/community/integrations.asciidoc, +  Thin asynchronous scala client for storehaus., +++ b/docs/groovy-api/anatomy.asciidoc, +    pritnln "Indexed $response.id into $response.index/$response.type", +++ b/docs/java-api/query-dsl-filters.asciidoc, +elasticsearch provides a full Java query dsl in a similar manner to the, +<8> distance computation mode: `GeoDistance.SLOPPY_ARC` (default), `GeoDistance.ARC` (slighly more precise but, +++ b/docs/reference/docs/delete.asciidoc, +no routing value is specified, the delete will be broadcasted, +++ b/docs/community/integrations.asciidoc, +  Thin asynchronous scala client for storehaus., +++ b/docs/groovy-api/anatomy.asciidoc, +    pritnln "Indexed $response.id into $response.index/$response.type", +++ b/docs/java-api/query-dsl-filters.asciidoc, +elasticsearch provides a full Java query dsl in a similar manner to the, +<8> distance computation mode: `GeoDistance.SLOPPY_ARC` (default), `GeoDistance.ARC` (slighly more precise but, +++ b/docs/reference/docs/delete.asciidoc, +no routing value is specified, the delete will be broadcasted, +++ b/docs/reference/indices.asciidoc, +++ b/docs/community/integrations.asciidoc, +  Thin asynchronous scala client for storehaus., +++ b/docs/groovy-api/anatomy.asciidoc, +    pritnln "Indexed $response.id into $response.index/$response.type", +++ b/docs/java-api/query-dsl-filters.asciidoc, +elasticsearch provides a full Java query dsl in a similar manner to the, +<8> distance computation mode: `GeoDistance.SLOPPY_ARC` (default), `GeoDistance.ARC` (slighly more precise but, +++ b/docs/reference/docs/delete.asciidoc, +no routing value is specified, the delete will be broadcasted, +++ b/docs/reference/indices.asciidoc, +++ b/docs/reference/indices/flush.asciidoc, +POST /twitter/_flush, +// AUTOSENSE, +POST /kimchy,elasticsearch/_flush, +POST /_flush, +// AUTOSENSE, +, +[[indices-synced-flush]], +=== Synced Flush, +, +Elasticsearch tracks the indexing activity of each shards. Shards that have not, +received any indexing operations for, by default, 30m are automatically marked as inactive. This presents, +an opportunity for Elasticsearch to reduce shard resources and also perform, +a special kind of flush, called `synced flush`. A synced flush performs normal, +flushing and adds a special uniquely generated marker (`sync_id`) to all shards., +, +Since the sync id marker was added when there were no ongoing indexing operations, it can, +be used as a quick way to check if two shards indices are identical. This quick sync id, +comparison (if present) is used during recovery or restarts to skip the first and, +most costly phase of the process. In that case, no segment files need to be copied and, +the transaction log replay phase of the recovery can start immediately. Note that since the sync id, +marker was applied together with a flush, it is highly likely that the transaction log will be empty,, +speeding up recoveries even more., +, +This is particularly useful for use cases having lots of indices which are, +never or very rarely updated, such as time based data. This use case typically generates lots of indices whose, +recovery without the synced flush marker would take a long time., +, +To check whether a shard has a marker or not, one can use the `commit` section of shard stats returned by, +the <<indices-stats,indices stats>> API:, +, +[source,bash], +--------------------------------------------------, +GET /twitter/_stats/commit?level=shards, +--------------------------------------------------, +// AUTOSENSE, +, +[float], +=== Synced Flush API, +, +The Synced Flush API allows an administrator to initiate a synced flush manually. This can particularly useful for, +a planned (rolling) cluster restart where one can stop indexing and doesn't want to wait for the default 30m to pass, +when the synced flush will be performed automatically., +, +While handy, there are a couple of caveats for this API:, +, +1. Synced flush is a best effort operation. Any ongoing indexing operations will cause, +the synced flush to fail. This means that some shards may be synced flushed while others aren't. See below for more., +2. The `sync_id` marker is removed as soon as the shard is flushed again. Uncommitted, +operations in the transaction log do not remove the marker. That is because the marker is store as part, +of a low level lucene commit, representing a point in time snapshot of the segments. In practice, one should consider, +any indexing operation on an index  as removing the marker., +, +, +[source,bash], +--------------------------------------------------, +POST /twitter/_flush/synced, +--------------------------------------------------]