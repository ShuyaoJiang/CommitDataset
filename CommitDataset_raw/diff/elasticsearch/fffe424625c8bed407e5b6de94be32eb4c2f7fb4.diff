[+++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/MachineLearningTemplateRegistry.java, +        try (XContentBuilder stateMapping = ElasticsearchMappings.stateMapping()) {, +            templateRequest.mapping(ElasticsearchMappings.DOC_TYPE, stateMapping);, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/MachineLearningTemplateRegistry.java, +        try (XContentBuilder stateMapping = ElasticsearchMappings.stateMapping()) {, +            templateRequest.mapping(ElasticsearchMappings.DOC_TYPE, stateMapping);, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/persistence/ElasticsearchMappings.java, +     * Create the Elasticsearch mapping for state.  State could potentially be, +     * huge (target document size is 16MB and there can be many documents) so all, +     * analysis by Elasticsearch is disabled.  The only way to retrieve state is, +     * by knowing the ID of a particular document., +    public static XContentBuilder stateMapping() throws IOException {, +                    .startObject(DOC_TYPE), +        builder.startObject(ModelSnapshot.QUANTILES.getPreferredName()), +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/MachineLearningTemplateRegistry.java, +        try (XContentBuilder stateMapping = ElasticsearchMappings.stateMapping()) {, +            templateRequest.mapping(ElasticsearchMappings.DOC_TYPE, stateMapping);, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/persistence/ElasticsearchMappings.java, +     * Create the Elasticsearch mapping for state.  State could potentially be, +     * huge (target document size is 16MB and there can be many documents) so all, +     * analysis by Elasticsearch is disabled.  The only way to retrieve state is, +     * by knowing the ID of a particular document., +    public static XContentBuilder stateMapping() throws IOException {, +                    .startObject(DOC_TYPE), +        builder.startObject(ModelSnapshot.QUANTILES.getPreferredName()), +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobDataDeleter.java, +                bulkRequestBuilder.add(client.prepareDelete(stateIndexName, ElasticsearchMappings.DOC_TYPE, stateDocId));, +            }, +            // TODO: remove in 7.0, +            for (String stateDocId : modelSnapshot.legacyStateDocumentIds()) {, +                bulkRequestBuilder.add(client.prepareDelete(stateIndexName, ModelState.TYPE, stateDocId));, +            // TODO: remove in 7.0, +            bulkRequestBuilder.add(client.prepareDelete(AnomalyDetectorsIndex.jobResultsAliasedName(modelSnapshot.getJobId()),, +                    ModelSnapshot.TYPE.getPreferredName(), ModelSnapshot.legacyDocumentId(modelSnapshot)));, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/MachineLearningTemplateRegistry.java, +        try (XContentBuilder stateMapping = ElasticsearchMappings.stateMapping()) {, +            templateRequest.mapping(ElasticsearchMappings.DOC_TYPE, stateMapping);, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/persistence/ElasticsearchMappings.java, +     * Create the Elasticsearch mapping for state.  State could potentially be, +     * huge (target document size is 16MB and there can be many documents) so all, +     * analysis by Elasticsearch is disabled.  The only way to retrieve state is, +     * by knowing the ID of a particular document., +    public static XContentBuilder stateMapping() throws IOException {, +                    .startObject(DOC_TYPE), +        builder.startObject(ModelSnapshot.QUANTILES.getPreferredName()), +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobDataDeleter.java, +                bulkRequestBuilder.add(client.prepareDelete(stateIndexName, ElasticsearchMappings.DOC_TYPE, stateDocId));, +            }, +            // TODO: remove in 7.0, +            for (String stateDocId : modelSnapshot.legacyStateDocumentIds()) {, +                bulkRequestBuilder.add(client.prepareDelete(stateIndexName, ModelState.TYPE, stateDocId));, +            // TODO: remove in 7.0, +            bulkRequestBuilder.add(client.prepareDelete(AnomalyDetectorsIndex.jobResultsAliasedName(modelSnapshot.getJobId()),, +                    ModelSnapshot.TYPE.getPreferredName(), ModelSnapshot.legacyDocumentId(modelSnapshot)));, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobProvider.java, +                // These next two document IDs never need to be the legacy ones due to the rule, +                // that you cannot open a 5.4 job in a subsequent version of the product, +        LOGGER.trace("ES API CALL: search all of category definitions from index {} sort ascending {} from {} size {}",, +                indexName, CategoryDefinition.CATEGORY_ID.getPreferredName(), from, size);, +        LOGGER.trace("ES API CALL: search all of records from index {}{}{} with filter after sort from {} size {}",, +                indexName, (sb != null) ? " with sort" : "",, +        LOGGER.trace("ES API CALL: search all of influencers from index {}{}  with filter from {} size {}", () -> indexName,, +        LOGGER.trace("ES API CALL: search all model snapshots from index {} sort ascending {} with filter after sort from {} size {}",, +                indexName, sortField, from, size);, +     * Because we have a rule that we will not open a legacy job in the current product version, +     * we don't have to worry about legacy document IDs here., +     *, +            LOGGER.trace("ES API CALL: get ID {} from index {}", stateDocId, indexName);, +            GetResponse stateResponse = client.prepareGet(indexName, ElasticsearchMappings.DOC_TYPE, stateDocId).get();, +        // the order the C++ process expects.  There are no snapshots for this, so the IDs simply, +            String docId = CategorizerState.documentId(jobId, ++docNum);, +            LOGGER.trace("ES API CALL: get ID {} from index {}", docId, indexName);, +            GetResponse stateResponse = client.prepareGet(indexName, ElasticsearchMappings.DOC_TYPE, docId).get();, +        LOGGER.trace("ES API CALL: search model plots from index {} from {} size {}", indexName, from, size);, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/MachineLearningTemplateRegistry.java, +        try (XContentBuilder stateMapping = ElasticsearchMappings.stateMapping()) {, +            templateRequest.mapping(ElasticsearchMappings.DOC_TYPE, stateMapping);, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/persistence/ElasticsearchMappings.java, +     * Create the Elasticsearch mapping for state.  State could potentially be, +     * huge (target document size is 16MB and there can be many documents) so all, +     * analysis by Elasticsearch is disabled.  The only way to retrieve state is, +     * by knowing the ID of a particular document., +    public static XContentBuilder stateMapping() throws IOException {, +                    .startObject(DOC_TYPE), +        builder.startObject(ModelSnapshot.QUANTILES.getPreferredName()), +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobDataDeleter.java, +                bulkRequestBuilder.add(client.prepareDelete(stateIndexName, ElasticsearchMappings.DOC_TYPE, stateDocId));, +            }, +            // TODO: remove in 7.0, +            for (String stateDocId : modelSnapshot.legacyStateDocumentIds()) {, +                bulkRequestBuilder.add(client.prepareDelete(stateIndexName, ModelState.TYPE, stateDocId));, +            // TODO: remove in 7.0, +            bulkRequestBuilder.add(client.prepareDelete(AnomalyDetectorsIndex.jobResultsAliasedName(modelSnapshot.getJobId()),, +                    ModelSnapshot.TYPE.getPreferredName(), ModelSnapshot.legacyDocumentId(modelSnapshot)));, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobProvider.java, +                // These next two document IDs never need to be the legacy ones due to the rule, +                // that you cannot open a 5.4 job in a subsequent version of the product, +        LOGGER.trace("ES API CALL: search all of category definitions from index {} sort ascending {} from {} size {}",, +                indexName, CategoryDefinition.CATEGORY_ID.getPreferredName(), from, size);, +        LOGGER.trace("ES API CALL: search all of records from index {}{}{} with filter after sort from {} size {}",]