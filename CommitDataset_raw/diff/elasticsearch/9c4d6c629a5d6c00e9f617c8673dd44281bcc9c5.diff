[+++ b/docs/plugins/repository-s3.asciidoc, +    size lower than `5mb` is not allowed since it will prevent the use of the, +    Multipart API and may result in upload errors. It is also not possible to, +    set a buffer size greater than `5gb` as it is the maximum upload size, +    allowed by S3. Defaults to the minimum between `100mb` and `5%` of the heap size., +++ b/docs/plugins/repository-s3.asciidoc, +    size lower than `5mb` is not allowed since it will prevent the use of the, +    Multipart API and may result in upload errors. It is also not possible to, +    set a buffer size greater than `5gb` as it is the maximum upload size, +    allowed by S3. Defaults to the minimum between `100mb` and `5%` of the heap size., +++ /dev/null, +++ b/docs/plugins/repository-s3.asciidoc, +    size lower than `5mb` is not allowed since it will prevent the use of the, +    Multipart API and may result in upload errors. It is also not possible to, +    set a buffer size greater than `5gb` as it is the maximum upload size, +    allowed by S3. Defaults to the minimum between `100mb` and `5%` of the heap size., +++ /dev/null, +++ b/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobContainer.java, +import com.amazonaws.services.s3.model.AbortMultipartUploadRequest;, +import com.amazonaws.services.s3.model.CompleteMultipartUploadRequest;, +import com.amazonaws.services.s3.model.InitiateMultipartUploadRequest;, +import com.amazonaws.services.s3.model.PartETag;, +import com.amazonaws.services.s3.model.PutObjectRequest;, +import com.amazonaws.services.s3.model.UploadPartRequest;, +import com.amazonaws.services.s3.model.UploadPartResult;, +import org.apache.lucene.util.SetOnce;, +import org.elasticsearch.common.Strings;, +import org.elasticsearch.common.collect.Tuple;, +import java.util.ArrayList;, +import java.util.List;, +import static org.elasticsearch.repositories.s3.S3Repository.MAX_FILE_SIZE;, +import static org.elasticsearch.repositories.s3.S3Repository.MAX_FILE_SIZE_USING_MULTIPART;, +import static org.elasticsearch.repositories.s3.S3Repository.MIN_PART_SIZE_USING_MULTIPART;, +, +    private final S3BlobStore blobStore;, +    private final String keyPath;, +, +        SocketAccess.doPrivilegedIOException(() -> {, +            if (blobSize <= blobStore.bufferSizeInBytes()) {, +                executeSingleUpload(blobStore, buildKey(blobName), inputStream, blobSize);, +            } else {, +                executeMultipartUpload(blobStore, buildKey(blobName), inputStream, blobSize);, +            return null;, +        });, +    private String buildKey(String blobName) {, +, +    /**, +     * Uploads a blob using a single upload request, +     */, +    void executeSingleUpload(final S3BlobStore blobStore,, +                             final String blobName,, +                             final InputStream input,, +                             final long blobSize) throws IOException {, +, +        // Extra safety checks, +        if (blobSize > MAX_FILE_SIZE.getBytes()) {, +            throw new IllegalArgumentException("Upload request size [" + blobSize + "] can't be larger than " + MAX_FILE_SIZE);, +        }, +        if (blobSize > blobStore.bufferSizeInBytes()) {, +            throw new IllegalArgumentException("Upload request size [" + blobSize + "] can't be larger than buffer size");, +        }, +, +        try {, +            final ObjectMetadata md = new ObjectMetadata();, +            md.setContentLength(blobSize);, +            if (blobStore.serverSideEncryption()) {, +                md.setSSEAlgorithm(ObjectMetadata.AES_256_SERVER_SIDE_ENCRYPTION);, +            }, +, +            final PutObjectRequest putRequest = new PutObjectRequest(blobStore.bucket(), blobName, input, md);, +            putRequest.setStorageClass(blobStore.getStorageClass());, +            putRequest.setCannedAcl(blobStore.getCannedACL());, +, +            blobStore.client().putObject(putRequest);, +        } catch (AmazonClientException e) {, +            throw new IOException("Unable to upload object [" + blobName + "] using a single upload", e);, +        }, +    }, +, +    /**, +     * Uploads a blob using multipart upload requests., +     */, +    void executeMultipartUpload(final S3BlobStore blobStore,, +                                final String blobName,, +                                final InputStream input,, +                                final long blobSize) throws IOException {, +, +        if (blobSize > MAX_FILE_SIZE_USING_MULTIPART.getBytes()) {, +            throw new IllegalArgumentException("Multipart upload request size [" + blobSize, +                                                + "] can't be larger than " + MAX_FILE_SIZE_USING_MULTIPART);, +        }, +        if (blobSize < MIN_PART_SIZE_USING_MULTIPART.getBytes()) {, +            throw new IllegalArgumentException("Multipart upload request size [" + blobSize, +                                               + "] can't be smaller than " + MIN_PART_SIZE_USING_MULTIPART);, +        }, +, +        final long partSize = blobStore.bufferSizeInBytes();, +        final Tuple<Long, Long> multiparts = numberOfMultiparts(blobSize, partSize);, +, +        if (multiparts.v1() > Integer.MAX_VALUE) {]