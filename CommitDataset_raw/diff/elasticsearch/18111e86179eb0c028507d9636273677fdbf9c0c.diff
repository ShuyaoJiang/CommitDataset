[+++ b/docs/en/ml/getting-started.asciidoc, +TBD., +////, +{xpack} {ml} features automatically detect:, +* Anomalies in single or multiple time series, +* Outliers in a population (also known as _entity profiling_), +* Rare events (also known as _log categorization_), +, +This tutorial is focuses on an anomaly detection scenario in single time series., +////, +, +In this tutorial, you will explore the {xpack} {ml} features by using sample, +data. You will create two simple jobs and use the results to identify possible, +anomalies in the data. You can also optionally create an alert. At the end of, +this tutorial, you should have a good idea of what {ml} is and will hopefully, +be inspired to use it to detect anomalies in your own data., +, +[float], +[[ml-gs-sysoverview]], +=== System Overview, +, +TBD., +, +To follow the steps in this tutorial, you will need the following, +components of the Elastic Stack:, +, +* Elasticsearch {version}, which stores the data and the analysis results, +* {xpack} {version}, which provides the {ml} features, +* Kibana {version}, which provides a helpful user interface for creating, +and viewing jobs, +, +See the https://www.elastic.co/support/matrix[Elastic Support Matrix] for, +information about supported operating systems and product compatibility., +, +See {stack-ref}/installing-elastic-stack.html[Installing the Elastic Stack] for, +information about installing each of the components., +, +NOTE: To get started, you can install Elasticsearch and Kibana on a, +single VM or even on your laptop. As you add more data and your traffic grows,, +you'll want to replace the single Elasticsearch instance with a cluster., +, +When you install {xpack} into Elasticsearch and Kibana, the {ml} features are, +enabled by default. If you have multiple nodes in your cluster, you can, +optionally dedicate nodes to specific purposes. If you want to control which, +nodes are _machine learning nodes_ or limit which nodes run resource-intensive, +activity related to jobs, see <<ml-settings>>., +, +NOTE: This tutorial uses Kibana to create jobs and view results, but you can, +alternatively use APIs to accomplish most tasks., +For API reference information, see <<ml-apis>>., +, +[[ml-gs-data]], +=== Identifying Data for Analysis, +, +TBD., +, +For the purposes of this tutorial, we provide sample data that you can play with., +When you consider your own data, however, it's important to take a moment, +and consider where the {xpack} {ml} features will be most impactful., +, +The first consideration is that it must be time series data., +Generally, it's best to use data that is in chronological order. When the data, +feed occurs in ascending time order, the statistical models and calculations are, +very efficient and occur in real-time., +//TBD: Talk about handling out of sequence data?, +, +The second consideration, especially when you are first learning to use {ml},, +is the importance of the data and how familiar you are with it. Ideally, it is, +information that contains key performance indicators (KPIs) for the health or, +success of your business or system. It is information for which you want alarms, +to ring when anomalous behavior occurs. You might even have Kibana dashboards, +that you're already using to watch this data. The better you know the data,, +the quicker you will be able to create jobs that generate useful insights from, +{ml}., +, +//TBD: Talk about layering additional jobs?, +////, + You can then create additional jobs to troubleshoot the situation and put it, +into context of what was going on in the system at the time., +The troubleshooting job would not create alarms of its own, but rather would, +help explain the overall situation.  It's usually a different job because it's, +operating on different indices. Layering jobs is an important concept., +////, +////, +* Working with out of sequence data:, +** In the typical case where data arrives in ascending time order,, +each new record pushes the time forward. When a record is received that belongs, +to a new bucket, the current bucket is considered to be completed., +At this point, the model is updated and final results are calculated for the, +completed bucket and the new bucket is created., +** Expecting data to be in time sequence means that modeling and results, +calculations can be performed very efficiently and in real-time., +As a direct consequence of this approach, out-of-sequence records are ignored., +** When data is expected to arrive out-of-sequence, a latency window can be, +specified in the job configuration (does not apply to data feeds?). (If we're, +using a data feed in the sample, perhaps this discussion can be deferred for, +future more-advanced scenario.), +//See http://www.prelert.com/docs/behavioral_analytics/latest/concepts/outofsequence.html, +////, +]