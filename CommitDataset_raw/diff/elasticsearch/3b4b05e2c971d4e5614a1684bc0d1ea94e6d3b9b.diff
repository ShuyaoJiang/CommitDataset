[+++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java, +                                        performOnPrimary(shard.id(), shard, clusterState);, +                            performOnPrimary(shard.id(), shard, clusterState);, +                        // check if state version changed while we were adding this listener, +                        if (clusterState.version() != clusterService.state().version()) {, +                            logger.trace("state change while we were trying to add listener, trying to index again");, +                    }, +        void performOnPrimary(int primaryShardId, final ShardRouting shard, ClusterState clusterState) {, +                    retry(false, null);, +++ b/src/main/java/org/elasticsearch/action/support/replication/TransportShardReplicationOperationAction.java, +                                        performOnPrimary(shard.id(), shard, clusterState);, +                            performOnPrimary(shard.id(), shard, clusterState);, +                        // check if state version changed while we were adding this listener, +                        if (clusterState.version() != clusterService.state().version()) {, +                            logger.trace("state change while we were trying to add listener, trying to index again");, +                    }, +        void performOnPrimary(int primaryShardId, final ShardRouting shard, ClusterState clusterState) {, +                    retry(false, null);, +++ b/src/test/java/org/elasticsearch/recovery/RecoveryWhileUnderLoadTests.java, +import org.elasticsearch.common.settings.ImmutableSettings;, +import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;, +        assertAcked(prepareCreate("test", 1));, +        assertAcked(prepareCreate("test", 1));, +        assertAcked(prepareCreate("test", 2));, +    @Test, +    @TestLogging("action.search.type:TRACE,action.admin.indices.refresh:TRACE,action.index:TRACE,action.support.replication:TRACE,cluster.service:DEBUG"), +    @Slow, +    public void recoverWhileRelocating() throws Exception {, +        final int numShards = between(5, 10);, +        final int numReplicas = 0;, +        cluster().ensureAtLeastNumNodes(3);, +        logger.info("--> creating test index ...");, +        int allowNodes = 2;, +        assertAcked(prepareCreate("test").setSettings(randomSettingsBuilder().put("number_of_shards", numShards).put("number_of_replicas", numReplicas).build()));, +, +        final AtomicLong idGenerator = new AtomicLong();, +        final AtomicLong indexCounter = new AtomicLong();, +        final AtomicBoolean stop = new AtomicBoolean(false);, +        Thread[] writers = new Thread[5];, +        final CountDownLatch stopLatch = new CountDownLatch(writers.length);, +        logger.info("--> starting {} indexing threads", writers.length);, +        for (int i = 0; i < writers.length; i++) {, +            final int indexerId = i;, +            final Client client = client();, +            writers[i] = new Thread() {, +                @Override, +                public void run() {, +                    try {, +                        logger.info("**** starting indexing thread {}", indexerId);, +                        while (!stop.get()) {, +                            long id = idGenerator.incrementAndGet();, +                            client.prepareIndex("test", "type1", Long.toString(id) + "-" + indexerId), +                                    .setSource(MapBuilder.<String, Object>newMapBuilder().put("test", "value" + id).map()).execute().actionGet();, +                            indexCounter.incrementAndGet();, +                        }, +                        logger.info("**** done indexing thread {}", indexerId);, +                    } catch (Throwable e) {, +                        logger.warn("**** failed indexing thread {}", e, indexerId);, +                    } finally {, +                        stopLatch.countDown();, +                    }, +                }, +            };, +            writers[i].start();, +        }, +, +        for (int i = 0; i < 100000; i += 1000) {, +            logger.info("--> waiting for {} docs to be indexed ...", i);, +            waitForDocs(i);, +            logger.info("--> {} docs indexed", i);, +            allowNodes = 2 / allowNodes;, +            allowNodes("test", allowNodes);, +            logger.info("--> waiting for GREEN health status ...");, +            assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout("1m").setWaitForGreenStatus().execute().actionGet().isTimedOut(), equalTo(false));, +        }, +, +        logger.info("--> marking and waiting for indexing threads to stop ...");, +        stop.set(true);, +        stopLatch.await();, +        logger.info("--> indexing threads stopped");, +, +        assertThat(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout("1m").setWaitForYellowStatus().execute().actionGet().isTimedOut(), equalTo(false));, +, +        logger.info("--> refreshing the index");, +        refreshAndAssert();, +        logger.info("--> verifying indexed content");, +        iterateAssertCount(5, indexCounter.get(), 10);, +    }, +]