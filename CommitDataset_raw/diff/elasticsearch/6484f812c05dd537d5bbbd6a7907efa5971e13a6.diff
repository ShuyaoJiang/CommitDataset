[+++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/DatafeedConfig.java, +     * an {@link ElasticsearchException} with the validation error, +            throw ExceptionsHelper.badRequestException("ML requires date_histogram.time_zone to be UTC");, +                    throw ExceptionsHelper.badRequestException(invalidDateHistogramCalendarIntervalMessage(calendarInterval));, +                    throw ExceptionsHelper.badRequestException("Unexpected dateTimeUnit [" + dateTimeUnit + "]");, +            throw ExceptionsHelper.badRequestException(invalidDateHistogramCalendarIntervalMessage(calendarInterval));, +        throw ExceptionsHelper.badRequestException("When specifying a date_histogram calendar interval [", +                throw ExceptionsHelper.badRequestException(msg);, +                throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.INVALID_ID, ID.getPreferredName()));, +                throw ExceptionsHelper.badRequestException(, +                        Messages.getMessage(Messages.DATAFEED_CONFIG_CANNOT_USE_SCRIPT_FIELDS_WITH_AGGS));, +                throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_REQUIRES_DATE_HISTOGRAM);, +                    throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_INTERVAL_MUST_BE_GREATER_THAN_ZERO);, +                    throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_INTERVAL_MUST_BE_GREATER_THAN_ZERO);, +                throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_REQUIRES_DATE_HISTOGRAM);, +            throw ExceptionsHelper.badRequestException(msg);, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/DatafeedConfig.java, +     * an {@link ElasticsearchException} with the validation error, +            throw ExceptionsHelper.badRequestException("ML requires date_histogram.time_zone to be UTC");, +                    throw ExceptionsHelper.badRequestException(invalidDateHistogramCalendarIntervalMessage(calendarInterval));, +                    throw ExceptionsHelper.badRequestException("Unexpected dateTimeUnit [" + dateTimeUnit + "]");, +            throw ExceptionsHelper.badRequestException(invalidDateHistogramCalendarIntervalMessage(calendarInterval));, +        throw ExceptionsHelper.badRequestException("When specifying a date_histogram calendar interval [", +                throw ExceptionsHelper.badRequestException(msg);, +                throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.INVALID_ID, ID.getPreferredName()));, +                throw ExceptionsHelper.badRequestException(, +                        Messages.getMessage(Messages.DATAFEED_CONFIG_CANNOT_USE_SCRIPT_FIELDS_WITH_AGGS));, +                throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_REQUIRES_DATE_HISTOGRAM);, +                    throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_INTERVAL_MUST_BE_GREATER_THAN_ZERO);, +                    throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_INTERVAL_MUST_BE_GREATER_THAN_ZERO);, +                throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_REQUIRES_DATE_HISTOGRAM);, +            throw ExceptionsHelper.badRequestException(msg);, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/JobManager.java, +                    actionListener.onFailure(ExceptionsHelper.badRequestException(Messages.JOB_CONFIG_MAPPING_TYPE_CLASH, e));, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/datafeed/DatafeedConfig.java, +     * an {@link ElasticsearchException} with the validation error, +            throw ExceptionsHelper.badRequestException("ML requires date_histogram.time_zone to be UTC");, +                    throw ExceptionsHelper.badRequestException(invalidDateHistogramCalendarIntervalMessage(calendarInterval));, +                    throw ExceptionsHelper.badRequestException("Unexpected dateTimeUnit [" + dateTimeUnit + "]");, +            throw ExceptionsHelper.badRequestException(invalidDateHistogramCalendarIntervalMessage(calendarInterval));, +        throw ExceptionsHelper.badRequestException("When specifying a date_histogram calendar interval [", +                throw ExceptionsHelper.badRequestException(msg);, +                throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.INVALID_ID, ID.getPreferredName()));, +                throw ExceptionsHelper.badRequestException(, +                        Messages.getMessage(Messages.DATAFEED_CONFIG_CANNOT_USE_SCRIPT_FIELDS_WITH_AGGS));, +                throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_REQUIRES_DATE_HISTOGRAM);, +                    throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_INTERVAL_MUST_BE_GREATER_THAN_ZERO);, +                    throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_INTERVAL_MUST_BE_GREATER_THAN_ZERO);, +                throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_REQUIRES_DATE_HISTOGRAM);, +            throw ExceptionsHelper.badRequestException(msg);, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/JobManager.java, +                    actionListener.onFailure(ExceptionsHelper.badRequestException(Messages.JOB_CONFIG_MAPPING_TYPE_CLASH, e));, +++ b/plugin/src/main/java/org/elasticsearch/xpack/ml/job/config/AnalysisConfig.java, +import org.elasticsearch.xpack.ml.utils.ExceptionsHelper;, +import java.util.Collections;, +import java.util.SortedSet;, +    static final ParseField CATEGORIZATION_FILTERS = new ParseField("categorization_filters");, +    public static final Set<String> AUTO_CREATED_FIELDS = new HashSet<>(Collections.singletonList(ML_CATEGORY_FIELD));, +        return termFields(getDetectors(), getInfluencers());, +    }, +    static SortedSet<String> termFields(List<Detector> detectors, List<String> influencers) {, +        SortedSet<String> termFields = new TreeSet<>();, +        detectors.forEach(d -> termFields.addAll(d.getByOverPartitionTerms()));, +, +        for (String i : influencers) {, +        return collectNonNullAndNonEmptyDetectorFields(Detector::getFieldName);, +        return collectNonNullAndNonEmptyDetectorFields(Detector::getByFieldName);, +        return collectNonNullAndNonEmptyDetectorFields(Detector::getOverFieldName);, +        return collectNonNullAndNonEmptyDetectorFields(Detector::getPartitionFieldName);, +                    multipleBucketSpans.stream().map(TimeValue::getStringRep).collect(Collectors.toList()));, +        static final TimeValue DEFAULT_BUCKET_SPAN = TimeValue.timeValueMinutes(5);, +            verifyNoInconsistentNestedFieldNames();, +, +                throw ExceptionsHelper.badRequestException(msg);, +                throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.JOB_CONFIG_NO_DETECTORS));, +            }, +        }, +, +        private void verifyNoInconsistentNestedFieldNames() {, +            SortedSet<String> termFields = termFields(detectors, influencers);, +            // We want to outlaw nested fields where a less nested field clashes with one of the nested levels., +            // For example, this is not allowed:, +            // - a, +            // - a.b, +            // Nor is this:, +            // - a.b, +            // - a.b.c, +            // But this is OK:, +            // - a.b, +            // - a.c, +            // The sorted set makes it relatively easy to detect the situations we want to avoid., +            String prevTermField = null;, +            for (String termField : termFields) {, +                if (prevTermField != null && termField.startsWith(prevTermField + ".")) {, +                    throw ExceptionsHelper.badRequestException("Fields " + prevTermField + " and " + termField +, +                            " cannot both be used in the same analysis_config");, +                }, +                prevTermField = termField;, +            detectors.forEach(d -> byOverPartitionFields.addAll(d.getByOverPartitionTerms()));, +                throw ExceptionsHelper.badRequestException(CATEGORIZATION_FIELD_NAME.getPreferredName()]