[+++ b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java, +        // TODO: why is this not specifying CREATE_NEW? Do we really need to be able to truncate existing files?, +++ b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java, +        // TODO: why is this not specifying CREATE_NEW? Do we really need to be able to truncate existing files?, +++ b/core/src/main/java/org/elasticsearch/common/blobstore/support/AbstractBlobContainer.java, +import org.elasticsearch.common.bytes.BytesReference;, +import java.io.InputStream;, +    , +    @Override, +    public void writeBlob(String blobName, BytesReference bytes) throws IOException {, +        try (InputStream stream = bytes.streamInput()) {, +            writeBlob(blobName, stream, bytes.length());, +        }, +    }, +++ b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java, +        // TODO: why is this not specifying CREATE_NEW? Do we really need to be able to truncate existing files?, +++ b/core/src/main/java/org/elasticsearch/common/blobstore/support/AbstractBlobContainer.java, +import org.elasticsearch.common.bytes.BytesReference;, +import java.io.InputStream;, +    , +    @Override, +    public void writeBlob(String blobName, BytesReference bytes) throws IOException {, +        try (InputStream stream = bytes.streamInput()) {, +            writeBlob(blobName, stream, bytes.length());, +        }, +    }, +++ b/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/HdfsBlobContainer.java, +import java.io.FileNotFoundException;, +        try {, +        } catch (FileNotFoundException ok) {, +            // behaves like Files.deleteIfExists, +        }, +                fc.rename(new Path(path, sourceBlobName), new Path(path, targetBlobName));, +                Path blob = new Path(path, blobName);, +                // we pass CREATE, which means it fails if a blob already exists., +                // NOTE: this behavior differs from FSBlobContainer, which passes TRUNCATE_EXISTING, +                // that should be fixed there, no need to bring truncation into this, give the user an error., +                EnumSet<CreateFlag> flags = EnumSet.of(CreateFlag.CREATE, CreateFlag.SYNC_BLOCK);, +                CreateOpts[] opts = { CreateOpts.bufferSize(blobStore.bufferSizeInBytes()) };, +                try (FSDataOutputStream stream = fc.create(blob, flags, opts)) {, +                        //  For safety we also hsync each write as well, because of its docs:, +                        //  SYNC_BLOCK - to force closed blocks to the disk device, +                        // "In addition Syncable.hsync() should be called after each write,, +                        //  if true synchronous behavior is required", +                }, +                return (fc.util().listStatus(path, new PathFilter() {, +                return fc.util().listStatus(path);, +++ b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java, +        // TODO: why is this not specifying CREATE_NEW? Do we really need to be able to truncate existing files?, +++ b/core/src/main/java/org/elasticsearch/common/blobstore/support/AbstractBlobContainer.java, +import org.elasticsearch.common.bytes.BytesReference;, +import java.io.InputStream;, +    , +    @Override, +    public void writeBlob(String blobName, BytesReference bytes) throws IOException {, +        try (InputStream stream = bytes.streamInput()) {, +            writeBlob(blobName, stream, bytes.length());, +        }, +    }, +++ b/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/HdfsBlobContainer.java, +import java.io.FileNotFoundException;, +        try {, +        } catch (FileNotFoundException ok) {, +            // behaves like Files.deleteIfExists, +        }, +                fc.rename(new Path(path, sourceBlobName), new Path(path, targetBlobName));, +                Path blob = new Path(path, blobName);, +                // we pass CREATE, which means it fails if a blob already exists., +                // NOTE: this behavior differs from FSBlobContainer, which passes TRUNCATE_EXISTING, +                // that should be fixed there, no need to bring truncation into this, give the user an error., +                EnumSet<CreateFlag> flags = EnumSet.of(CreateFlag.CREATE, CreateFlag.SYNC_BLOCK);, +                CreateOpts[] opts = { CreateOpts.bufferSize(blobStore.bufferSizeInBytes()) };, +                try (FSDataOutputStream stream = fc.create(blob, flags, opts)) {, +                        //  For safety we also hsync each write as well, because of its docs:, +                        //  SYNC_BLOCK - to force closed blocks to the disk device, +                        // "In addition Syncable.hsync() should be called after each write,, +                        //  if true synchronous behavior is required", +                }, +                return (fc.util().listStatus(path, new PathFilter() {, +                return fc.util().listStatus(path);, +++ b/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/HdfsBlobStore.java, +import org.apache.hadoop.fs.FileAlreadyExistsException;, +    private final Path root;, +    HdfsBlobStore(Settings settings, FileContextFactory fcf, Path root) throws IOException {, +        this.root = root;, +        try {, +            mkdirs(root);, +        } catch (FileAlreadyExistsException ok) {, +            // behaves like Files.createDirectories, +        }, +        return root.toUri().toString();, +        } catch (FileAlreadyExistsException ok) {, +            // behaves like Files.createDirectories, +        Path path = root;]