[+++ b/server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregationBuilder.java, +import org.apache.lucene.index.IndexReader;, +import org.apache.lucene.index.LeafReaderContext;, +import org.apache.lucene.index.SortedNumericDocValues;, +import org.apache.lucene.search.DocIdSetIterator;, +import org.elasticsearch.index.fielddata.AtomicNumericFieldData;, +import org.elasticsearch.index.fielddata.IndexNumericFieldData;, +import org.elasticsearch.index.mapper.MappedFieldType;, +import org.elasticsearch.index.mapper.MappedFieldType.Relation;, +import org.elasticsearch.index.query.QueryShardContext;, +import org.elasticsearch.search.DocValueFormat;, +import org.joda.time.DateTimeField;, +import org.joda.time.DateTimeZone;, +    /*, +     * NOTE: this can't be done in rewrite() because the timezone is then also used on the, +     * coordinating node in order to generate missing buckets, which may cross a transition, +     * even though data on the shards doesn't., +     */, +    DateTimeZone rewriteTimeZone(QueryShardContext context) throws IOException {, +        final DateTimeZone tz = timeZone();, +        if (field() != null &&, +                tz != null &&, +                tz.isFixed() == false &&, +                field() != null &&, +                script() == null) {, +            final MappedFieldType ft = context.fieldMapper(field());, +            final IndexReader reader = context.getIndexReader();, +            if (ft != null && reader != null) {, +                Long anyInstant = null;, +                final IndexNumericFieldData fieldData = context.getForField(ft);, +                for (LeafReaderContext ctx : reader.leaves()) {, +                    AtomicNumericFieldData leafFD = ((IndexNumericFieldData) fieldData).load(ctx);, +                    SortedNumericDocValues values = leafFD.getLongValues();, +                    if (values.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {, +                        anyInstant = values.nextValue();, +                        break;, +                    }, +                }, +, +                if (anyInstant != null) {, +                    final long prevTransition = tz.previousTransition(anyInstant);, +                    final long nextTransition = tz.nextTransition(anyInstant);, +, +                    // We need all not only values but also rounded values to be within, +                    // [prevTransition, nextTransition]., +                    final long low;, +                    DateTimeUnit intervalAsUnit = getIntervalAsDateTimeUnit();, +                    if (intervalAsUnit != null) {, +                        final DateTimeField dateTimeField = intervalAsUnit.field(tz);, +                        low = dateTimeField.roundCeiling(prevTransition);, +                    } else {, +                        final TimeValue intervalAsMillis = getIntervalAsTimeValue();, +                        low = Math.addExact(prevTransition, intervalAsMillis.millis());, +                    }, +                    // rounding rounds down, so 'nextTransition' is a good upper bound, +                    final long high = nextTransition;, +, +                    final DocValueFormat format = ft.docValueFormat(null, null);, +                    final String formattedLow = format.format(low);, +                    final String formattedHigh = format.format(high);, +                    if (ft.isFieldWithinQuery(reader, formattedLow, formattedHigh,, +                            true, false, tz, null, context) == Relation.WITHIN) {, +                        // All values in this reader have the same offset despite daylight saving times., +                        // This is very common for location-based timezones such as Europe/Paris in, +                        // combination with time-based indices., +                        return DateTimeZone.forOffsetMillis(tz.getOffset(anyInstant));, +                    }, +                }, +            }, +        }, +        return tz;, +    }, +, +        final DateTimeZone tz = timeZone();, +        final Rounding rounding = createRounding(tz);, +        final DateTimeZone rewrittenTimeZone = rewriteTimeZone(context.getQueryShardContext());, +        final Rounding shardRounding;, +        if (tz == rewrittenTimeZone) {, +            shardRounding = rounding;, +        } else {, +            shardRounding = createRounding(rewrittenTimeZone);, +        }, +, +        return new DateHistogramAggregatorFactory(name, config, offset, order, keyed, minDocCount,, +                rounding, shardRounding, roundedBounds, context, parent, subFactoriesBuilder, metaData);, +    /** Return the interval as a date time unit if applicable. If this returns, +     *  {@code null} then it means that the interval is expressed as a fixed, +     *  {@link TimeValue} and may be accessed via, +     *  {@link #getIntervalAsTimeValue()}. */, +    private DateTimeUnit getIntervalAsDateTimeUnit() {, +            return DATE_FIELD_UNITS.get(dateHistogramInterval.toString());, +        return null;, +, +    /**, +     * Get the interval as a {@link TimeValue}. Should only be called if, +     * {@link #getIntervalAsDateTimeUnit()} returned {@code null}., +     */, +    private TimeValue getIntervalAsTimeValue() {, +        if (dateHistogramInterval != null) {, +            return TimeValue.parseTimeValue(dateHistogramInterval.toString(), null, getClass().getSimpleName() + ".interval");]