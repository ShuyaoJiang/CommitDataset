[+++ b/.gitignore, +/.project, +++ b/.gitignore, +/.project, +++ b/CONTRIBUTING.md, +**Repository:** [https://github.com/elasticsearch/elasticsearch-analysis-kuromoji](https://github.com/elasticsearch/elasticsearch-analysis-kuromoji), +cd elasticsearch-analysis-kuromoji/, +++ b/.gitignore, +/.project, +++ b/CONTRIBUTING.md, +**Repository:** [https://github.com/elasticsearch/elasticsearch-analysis-kuromoji](https://github.com/elasticsearch/elasticsearch-analysis-kuromoji), +cd elasticsearch-analysis-kuromoji/, +++ b/README.md, +Japanese (kuromoji) Analysis for ElasticSearch, +The Japanese (kuromoji) Analysis plugin integrates Lucene kuromoji analysis module into elasticsearch., +In order to install the plugin, simply run: `bin/plugin -install elasticsearch/elasticsearch-analysis-kuromoji/1.5.0`., +			<td>Kuromoji Analysis Plugin</td>, +			<td>1.6.0-SNAPSHOT (master)</td>, +			<td>1.5.0</td>, +			<td>1.4.0</td>, +			<td>1.3.0</td>, +			<td>1.2.0</td>, +			<td>0.19.2 -> 0.20</td>, +			<td>2012-11-21</td>, +			<td>0.19.0 -> 0.19.1</td>, +			<td>2012-04-30</td>, +The plugin includes the `kuromoji` analyzer., +, +Includes Analyzer, Tokenizer, TokenFilter, +----------------------------------------, +, +The plugin includes these analyzer and tokenizer, tokenfilter., +, +| name                    | type        |, +|-------------------------|-------------|, +| kuromoji                | analyzer    |, +| kuromoji_tokenizer      | tokenizer   |, +| kuromoji_baseform       | tokenfilter |, +| kuromoji_part_of_speech | tokenfilter |, +| kuromoji_readingform    | tokenfilter |, +| kuromoji_stemmer        | tokenfilter |, +, +, +Usage, +-----, +, +## Analyzer : kuromoji, +, +An analyzer of type `kuromoji`., +This analyzer is the following tokenizer and tokenfilter combination., +, +* `kuromoji_tokenizer` : Kuromoji Tokenizer, +* `kuromoji_baseform` : Kuromoji BasicFormFilter (TokenFilter), +* `kuromoji_part_of_speech` : Kuromoji Part of Speech Stop Filter (TokenFilter), +* `cjk_width` : CJK Width Filter (TokenFilter), +* `stop` : Stop Filter (TokenFilter), +* `kuromoji_stemmer` : Kuromiji Katakana Stemmer Filter(TokenFilter), +* `lowercase` : LowerCase Filter (TokenFilter), +, +## Tokenizer : kuromoji_tokenizer, +, +A tokenizer of type `kuromoji_tokenizer`., +, +The following are settings that can be set for a `kuromoji_tokenizer` tokenizer type:, +, +| **Setting**         | **Description**                                                                                                           | **Default value** |, +|:--------------------|:--------------------------------------------------------------------------------------------------------------------------|:------------------|, +| mode                | Tokenization mode: this determines how the tokenizer handles compound and unknown words. `normal` and `search`, `extended`| `search`          |, +| discard_punctuation | `true` if punctuation tokens should be dropped from the output.                                                           | `true`            |, +| user_dict           | set User Dictionary file                                                                                                  |                   |, +, +### Tokenization mode, +, +The mode is three types., +, +* `normal` : Ordinary segmentation: no decomposition for compounds, +, +* `search` : Segmentation geared towards search: this includes a decompounding process for long nouns, also includeing the full compound token as a synonym., +, +* `extended` : Extended mode outputs unigrams for unknown words., +, +#### Difference tokenization mode outputs, +, +Input text is `関西国際空港` and `アブラカダブラ`., +, +| **mode**   | `関西国際空港` | `アブラカダブラ` |, +|:-----------|:-------------|:-------|, +| `normal`   | `関西国際空港` | `アブラカダブラ` |, +| `search`   | `関西` `関西国際空港` `国際` `空港` | `アブラカダブラ` |, +| `extended` | `関西` `国際` `空港` | `ア` `ブ` `ラ` `カ` `ダ` `ブ` `ラ` |, +, +### User Dictionary, +, +Kuromoji tokenizer use MecCab-IPADIC dictionary by default., +And Kuromoji is added an entry of dictionary to define by user; this is User Dictionary., +User Dictionary entries are defined using the following CSV format:, +, +```, +<text>,<token 1> ... <token n>,<reading 1> ... <reading n>,<part-of-speech tag>, +```]