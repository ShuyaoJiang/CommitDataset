[+++ /dev/null, +++ /dev/null, +++ b/x-pack/plugin/ml/log-structure-finder/src/main/java/org/elasticsearch/xpack/ml/logstructurefinder/DelimitedLogStructureFinder.java, +/*, + * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one, + * or more contributor license agreements. Licensed under the Elastic License;, + * you may not use this file except in compliance with the Elastic License., + */, +package org.elasticsearch.xpack.ml.logstructurefinder;, +, +import org.elasticsearch.common.collect.Tuple;, +import org.elasticsearch.xpack.ml.logstructurefinder.TimestampFormatFinder.TimestampMatch;, +import org.supercsv.exception.SuperCsvException;, +import org.supercsv.io.CsvListReader;, +import org.supercsv.prefs.CsvPreference;, +import org.supercsv.util.Util;, +, +import java.io.IOException;, +import java.io.StringReader;, +import java.util.ArrayList;, +import java.util.Arrays;, +import java.util.Collections;, +import java.util.DoubleSummaryStatistics;, +import java.util.HashSet;, +import java.util.LinkedHashMap;, +import java.util.List;, +import java.util.Locale;, +import java.util.Map;, +import java.util.Random;, +import java.util.SortedMap;, +import java.util.regex.Pattern;, +import java.util.stream.Collectors;, +import java.util.stream.IntStream;, +, +public class DelimitedLogStructureFinder implements LogStructureFinder {, +, +    private static final int MAX_LEVENSHTEIN_COMPARISONS = 100;, +, +    private final List<String> sampleMessages;, +    private final LogStructure structure;, +, +    static DelimitedLogStructureFinder makeDelimitedLogStructureFinder(List<String> explanation, String sample, String charsetName,, +                                                                       Boolean hasByteOrderMarker, CsvPreference csvPreference,, +                                                                       boolean trimFields) throws IOException {, +, +        Tuple<List<List<String>>, List<Integer>> parsed = readRows(sample, csvPreference);, +        List<List<String>> rows = parsed.v1();, +        List<Integer> lineNumbers = parsed.v2();, +, +        Tuple<Boolean, String[]> headerInfo = findHeaderFromSample(explanation, rows);, +        boolean isHeaderInFile = headerInfo.v1();, +        String[] header = headerInfo.v2();, +        String[] headerWithNamedBlanks = new String[header.length];, +        for (int i = 0; i < header.length; ++i) {, +            String rawHeader = header[i].isEmpty() ? "column" + (i + 1) : header[i];, +            headerWithNamedBlanks[i] = trimFields ? rawHeader.trim() : rawHeader;, +        }, +, +        List<String> sampleLines = Arrays.asList(sample.split("\n"));, +        List<String> sampleMessages = new ArrayList<>();, +        List<Map<String, ?>> sampleRecords = new ArrayList<>();, +        int prevMessageEndLineNumber = isHeaderInFile ? lineNumbers.get(0) : -1;, +        for (int index = isHeaderInFile ? 1 : 0; index < rows.size(); ++index) {, +            List<String> row = rows.get(index);, +            int lineNumber = lineNumbers.get(index);, +            Map<String, String> sampleRecord = new LinkedHashMap<>();, +            Util.filterListToMap(sampleRecord, headerWithNamedBlanks,, +                trimFields ? row.stream().map(String::trim).collect(Collectors.toList()) : row);, +            sampleRecords.add(sampleRecord);, +            sampleMessages.add(, +                sampleLines.subList(prevMessageEndLineNumber + 1, lineNumbers.get(index)).stream().collect(Collectors.joining("\n")));, +            prevMessageEndLineNumber = lineNumber;, +        }, +, +        String preamble = Pattern.compile("\n").splitAsStream(sample).limit(lineNumbers.get(1)).collect(Collectors.joining("\n", "", "\n"));, +, +        char delimiter = (char) csvPreference.getDelimiterChar();, +        LogStructure.Builder structureBuilder = new LogStructure.Builder(LogStructure.Format.DELIMITED), +            .setCharset(charsetName), +            .setHasByteOrderMarker(hasByteOrderMarker), +            .setSampleStart(preamble), +            .setNumLinesAnalyzed(lineNumbers.get(lineNumbers.size() - 1)), +            .setNumMessagesAnalyzed(sampleRecords.size()), +            .setHasHeaderRow(isHeaderInFile), +            .setDelimiter(delimiter), +            .setInputFields(Arrays.stream(headerWithNamedBlanks).collect(Collectors.toList()));, +, +        if (trimFields) {, +            structureBuilder.setShouldTrimFields(true);, +        }, +, +        Tuple<String, TimestampMatch> timeField = LogStructureUtils.guessTimestampField(explanation, sampleRecords);, +        if (timeField != null) {, +            String timeLineRegex = null;, +            StringBuilder builder = new StringBuilder("^");, +            // We make the assumption that the timestamp will be on the first line of each record.  Therefore, if the, +            // timestamp is the last column then either our assumption is wrong (and the approach will completely, +            // break down) or else every record is on a single line and there's no point creating a multiline config., +            // This is why the loop excludes the last column., +            for (String column : Arrays.asList(header).subList(0, header.length - 1)) {]