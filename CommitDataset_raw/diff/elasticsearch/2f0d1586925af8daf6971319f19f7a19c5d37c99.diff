[+++ b/src/main/java/org/elasticsearch/cluster/action/index/NodeIndexDeletedAction.java, +import org.apache.lucene.store.LockObtainFailedException;, +import org.apache.lucene.util.IOUtils;, +import org.elasticsearch.common.util.concurrent.AbstractRunnable;, +import org.elasticsearch.env.NodeEnvironment;, +import org.elasticsearch.env.ShardLock;, +import org.elasticsearch.index.Index;, +import org.elasticsearch.indices.IndicesService;, +import java.io.Closeable;, +import java.util.concurrent.TimeUnit;, +    private final NodeEnvironment nodeEnv;, +    public NodeIndexDeletedAction(Settings settings, ThreadPool threadPool, TransportService transportService, NodeEnvironment nodeEnv) {, +        this.nodeEnv = nodeEnv;, +        final DiscoveryNodes nodes = clusterState.nodes();, +            threadPool.generic().execute(new AbstractRunnable() {, +, +                public void onFailure(Throwable t) {, +                    logger.warn("[{}]failed to ack index store deleted for index", t, index);, +                }, +, +                @Override, +                protected void doRun() throws Exception {, +                    lockIndexAndAck(index, nodes, nodeId, clusterState);, +, +            threadPool.generic().execute(new AbstractRunnable() {, +                @Override, +                public void onFailure(Throwable t) {, +                    logger.warn("[{}]failed to ack index store deleted for  index", t, index);, +                }, +, +                @Override, +                protected void doRun() throws Exception {, +                    lockIndexAndAck(index, nodes, nodeId, clusterState);, +                }, +            });, +    private void lockIndexAndAck(String index, DiscoveryNodes nodes, String nodeId, ClusterState clusterState) throws IOException {, +        try {, +            // we are waiting until we can lock the index / all shards on the node and then we ack the delete of the store to the, +            // master. If we can't acquire the locks here immediately there might be a shard of this index still holding on to the lock, +            // due to a "currently canceled recovery" or so. The shard will delete itself BEFORE the lock is released so it's guaranteed to be, +            // deleted by the time we get the lock, +            final List<ShardLock> locks = nodeEnv.lockAllForIndex(new Index(index), TimeUnit.MINUTES.toMillis(30));, +            try {, +            } finally {, +                IOUtils.close(locks); // release them again, +            }, +        } catch (LockObtainFailedException exc) {, +            logger.warn("[{}] failed to lock all shards for index - timed out after 30 seconds", index);, +        }, +++ b/src/main/java/org/elasticsearch/cluster/action/index/NodeIndexDeletedAction.java, +import org.apache.lucene.store.LockObtainFailedException;, +import org.apache.lucene.util.IOUtils;, +import org.elasticsearch.common.util.concurrent.AbstractRunnable;, +import org.elasticsearch.env.NodeEnvironment;, +import org.elasticsearch.env.ShardLock;, +import org.elasticsearch.index.Index;, +import org.elasticsearch.indices.IndicesService;, +import java.io.Closeable;, +import java.util.concurrent.TimeUnit;, +    private final NodeEnvironment nodeEnv;, +    public NodeIndexDeletedAction(Settings settings, ThreadPool threadPool, TransportService transportService, NodeEnvironment nodeEnv) {, +        this.nodeEnv = nodeEnv;, +        final DiscoveryNodes nodes = clusterState.nodes();, +            threadPool.generic().execute(new AbstractRunnable() {, +, +                public void onFailure(Throwable t) {, +                    logger.warn("[{}]failed to ack index store deleted for index", t, index);, +                }, +, +                @Override, +                protected void doRun() throws Exception {, +                    lockIndexAndAck(index, nodes, nodeId, clusterState);, +, +            threadPool.generic().execute(new AbstractRunnable() {, +                @Override, +                public void onFailure(Throwable t) {, +                    logger.warn("[{}]failed to ack index store deleted for  index", t, index);, +                }, +, +                @Override, +                protected void doRun() throws Exception {, +                    lockIndexAndAck(index, nodes, nodeId, clusterState);, +                }, +            });, +    private void lockIndexAndAck(String index, DiscoveryNodes nodes, String nodeId, ClusterState clusterState) throws IOException {, +        try {, +            // we are waiting until we can lock the index / all shards on the node and then we ack the delete of the store to the, +            // master. If we can't acquire the locks here immediately there might be a shard of this index still holding on to the lock, +            // due to a "currently canceled recovery" or so. The shard will delete itself BEFORE the lock is released so it's guaranteed to be, +            // deleted by the time we get the lock, +            final List<ShardLock> locks = nodeEnv.lockAllForIndex(new Index(index), TimeUnit.MINUTES.toMillis(30));, +            try {, +            } finally {, +                IOUtils.close(locks); // release them again, +            }, +        } catch (LockObtainFailedException exc) {, +            logger.warn("[{}] failed to lock all shards for index - timed out after 30 seconds", index);, +        }, +++ b/src/main/java/org/elasticsearch/gateway/GatewayMetaState.java, +import org.elasticsearch.cluster.ClusterState;]