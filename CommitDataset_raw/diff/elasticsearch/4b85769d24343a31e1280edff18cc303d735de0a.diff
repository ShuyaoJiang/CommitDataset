[+++ b/server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java, +    final EmptyBucketInfo emptyBucketInfo;, +                return Double.compare(a.current.key, b.current.key) < 0;, +                    assert key == nextBucket.key || Double.isNaN(nextBucket.key) : "key: " + key + ", nextBucket.key: " + nextBucket.key;, +++ b/server/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java, +    final EmptyBucketInfo emptyBucketInfo;, +                return Double.compare(a.current.key, b.current.key) < 0;, +                    assert key == nextBucket.key || Double.isNaN(nextBucket.key) : "key: " + key + ", nextBucket.key: " + nextBucket.key;, +++ b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogramTests.java, +import org.elasticsearch.test.InternalMultiBucketAggregationTestCase;, +    private int interval;, +    private int minDocCount;, +    private InternalHistogram.EmptyBucketInfo emptyBucketInfo;, +    private int offset;, +        //in order for reduction to work properly (and be realistic) we need to use the same interval, minDocCount, emptyBucketInfo, +        //and offset in all randomly created aggs as part of the same test run. This is particularly important when minDocCount is, +        //set to 0 as empty buckets need to be added to fill the holes., +        interval = randomIntBetween(1, 3);, +        offset = randomIntBetween(0, 3);, +        if (randomBoolean()) {, +            minDocCount = randomIntBetween(1, 10);, +            emptyBucketInfo = null;, +        } else {, +            minDocCount = 0;, +            //it's ok if minBound and maxBound are outside the range of the generated buckets, that will just mean that, +            //empty buckets won't be added before the first bucket and/or after the last one, +            int minBound = randomInt(50) - 30;, +            int maxBound =  randomNumberOfBuckets() * interval + randomIntBetween(0, 10);, +            emptyBucketInfo = new InternalHistogram.EmptyBucketInfo(interval, offset, minBound, maxBound, InternalAggregations.EMPTY);, +        }, +    }, +, +    private double round(double key) {, +        return Math.floor((key - offset) / interval) * interval + offset;, +        final double base = round(randomInt(50) - 30);, +            //rarely leave some holes to be filled up with empty buckets in case minDocCount is set to 0, +            if (frequently()) {, +        }, +        return new InternalHistogram(name, buckets, order, minDocCount, emptyBucketInfo, format, keyed, pipelineAggregators, metaData);, +        TreeMap<Double, Long> expectedCounts = new TreeMap<>();, +        if (minDocCount == 0) {, +            double minBound = round(emptyBucketInfo.minBound);, +            if (expectedCounts.isEmpty() && emptyBucketInfo.minBound < emptyBucketInfo.maxBound) {, +                expectedCounts.put(minBound, 0L);, +            }, +            if (expectedCounts.isEmpty() == false) {, +                Double nextKey = expectedCounts.firstKey();, +                while (nextKey < expectedCounts.lastKey()) {, +                    expectedCounts.putIfAbsent(nextKey, 0L);, +                    nextKey += interval;, +                }, +                while (minBound < expectedCounts.firstKey()) {, +                    expectedCounts.put(expectedCounts.firstKey() - interval, 0L);, +                }, +                double maxBound = round(emptyBucketInfo.maxBound);, +                while (expectedCounts.lastKey() < maxBound) {, +                    expectedCounts.put(expectedCounts.lastKey() + interval, 0L);, +                }, +            }, +        } else {, +            expectedCounts.entrySet().removeIf(doubleLongEntry -> doubleLongEntry.getValue() < minDocCount);, +        }, +, +        InternalHistogram.EmptyBucketInfo emptyBucketInfo = instance.emptyBucketInfo;, +            emptyBucketInfo = null;, +        return new InternalHistogram(name, buckets, order, minDocCount, emptyBucketInfo, format, keyed, pipelineAggregators, metaData);]