[+++ b/modules/lang-painless/ant.xml, +      <local name="grammar.path"/>, +      <property name="grammar.path" location="src/main/antlr"/>, +      <!-- delete token files so files will be generated -->, +      <delete dir="${grammar.path}" includes="@{grammar}*.tokens"/>, +        <include name="@{grammar}Lexer.tokens" />, +        <include name="@{grammar}Parser.tokens" />, +        <arg value="-Werror"/>, +        <arg value="-Werror"/>, +      <!-- moves token files to grammar directory for use with IDE's -->, +      <move file="${output.path}/@{grammar}Lexer.tokens" todir="${grammar.path}"/>, +      <move file="${output.path}/@{grammar}Parser.tokens" todir="${grammar.path}"/>, +++ b/modules/lang-painless/ant.xml, +      <local name="grammar.path"/>, +      <property name="grammar.path" location="src/main/antlr"/>, +      <!-- delete token files so files will be generated -->, +      <delete dir="${grammar.path}" includes="@{grammar}*.tokens"/>, +        <include name="@{grammar}Lexer.tokens" />, +        <include name="@{grammar}Parser.tokens" />, +        <arg value="-Werror"/>, +        <arg value="-Werror"/>, +      <!-- moves token files to grammar directory for use with IDE's -->, +      <move file="${output.path}/@{grammar}Lexer.tokens" todir="${grammar.path}"/>, +      <move file="${output.path}/@{grammar}Parser.tokens" todir="${grammar.path}"/>, +++ b/modules/lang-painless/src/main/antlr/PainlessLexer.g4, +@header {, +import org.elasticsearch.painless.Definition;, +}, +, +DOT:       '.' -> mode(AFTER_DOT);, +DECIMAL: ( '0' | [1-9] [0-9]* ) (DOT [0-9]+)? ( [eE] [+\-]? [0-9]+ )? [fF]?;, +// The predicate here allows us to remove ambiguities when, +// dealing with types versus identifiers.  We check against, +// the current whitelist to determine whether a token is a type, +// or not.  Note this works by processing one character at a time, +// and the rule is added or removed as this happens.  This is also known, +// as "the lexer hack."  See (https://en.wikipedia.org/wiki/The_lexer_hack)., +TYPE: ID ( DOT ID )* { Definition.isSimpleType(getText()) }?;, +mode AFTER_DOT;, +, +DOTINTEGER: ( '0' | [1-9] [0-9]* )                        -> mode(DEFAULT_MODE);, +DOTID: [_a-z] [_a-zA-Z0-9]*                               -> mode(DEFAULT_MODE);, +++ b/modules/lang-painless/ant.xml, +      <local name="grammar.path"/>, +      <property name="grammar.path" location="src/main/antlr"/>, +      <!-- delete token files so files will be generated -->, +      <delete dir="${grammar.path}" includes="@{grammar}*.tokens"/>, +        <include name="@{grammar}Lexer.tokens" />, +        <include name="@{grammar}Parser.tokens" />, +        <arg value="-Werror"/>, +        <arg value="-Werror"/>, +      <!-- moves token files to grammar directory for use with IDE's -->, +      <move file="${output.path}/@{grammar}Lexer.tokens" todir="${grammar.path}"/>, +      <move file="${output.path}/@{grammar}Parser.tokens" todir="${grammar.path}"/>, +++ b/modules/lang-painless/src/main/antlr/PainlessLexer.g4, +@header {, +import org.elasticsearch.painless.Definition;, +}, +, +DOT:       '.' -> mode(AFTER_DOT);, +DECIMAL: ( '0' | [1-9] [0-9]* ) (DOT [0-9]+)? ( [eE] [+\-]? [0-9]+ )? [fF]?;, +// The predicate here allows us to remove ambiguities when, +// dealing with types versus identifiers.  We check against, +// the current whitelist to determine whether a token is a type, +// or not.  Note this works by processing one character at a time, +// and the rule is added or removed as this happens.  This is also known, +// as "the lexer hack."  See (https://en.wikipedia.org/wiki/The_lexer_hack)., +TYPE: ID ( DOT ID )* { Definition.isSimpleType(getText()) }?;, +mode AFTER_DOT;, +, +DOTINTEGER: ( '0' | [1-9] [0-9]* )                        -> mode(DEFAULT_MODE);, +DOTID: [_a-z] [_a-zA-Z0-9]*                               -> mode(DEFAULT_MODE);, +++ b/modules/lang-painless/src/main/antlr/PainlessLexer.tokens, +WS=1, +COMMENT=2, +LBRACK=3, +RBRACK=4, +LBRACE=5, +RBRACE=6, +LP=7, +RP=8, +DOT=9, +COMMA=10, +SEMICOLON=11, +IF=12, +ELSE=13, +WHILE=14, +DO=15, +FOR=16, +CONTINUE=17, +BREAK=18, +RETURN=19, +NEW=20, +TRY=21, +CATCH=22, +THROW=23, +BOOLNOT=24, +BWNOT=25, +MUL=26, +DIV=27]