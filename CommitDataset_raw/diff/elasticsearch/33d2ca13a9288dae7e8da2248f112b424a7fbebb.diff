[+++ b/core/src/main/java/org/elasticsearch/gateway/ReplicaShardAllocator.java, +import com.carrotsearch.hppc.ObjectLongHashMap;, +import com.carrotsearch.hppc.ObjectLongMap;, +import com.carrotsearch.hppc.cursors.ObjectLongCursor;, +import org.elasticsearch.common.Nullable;, +            if (canBeAllocatedToAtLeastOneNode(shard, allocation) == false) {, +            assert primaryShard != null : "the replica shard can be allocated on at least one node, so there must be an active primary";, +            TransportNodesListShardStoreMetaData.StoreFilesMetaData primaryStore = findStore(primaryShard, allocation, shardStores);, +            if (primaryStore == null || primaryStore.allocated() == false) {, +                // if we can't find the primary data, it is probably because the primary shard is corrupted (and listing failed), +                // we want to let the replica be allocated in order to expose the actual problem with the primary that the replica, +                // will try and recover from, +                // Note, this is the existing behavior, as exposed in running CorruptFileTest#testNoPrimaryData, +                logger.trace("{}: no primary shard store found or allocated, letting actual allocation figure it out", shard);, +                continue;, +            MatchingNodes matchingNodes = findMatchingNodes(shard, allocation, primaryStore, shardStores);, +, +            if (matchingNodes.getNodeWithHighestMatch() != null) {, +                RoutingNode nodeWithHighestMatch = allocation.routingNodes().node(matchingNodes.getNodeWithHighestMatch().id());, +                Decision decision = allocation.deciders().canAllocate(shard, nodeWithHighestMatch, allocation);, +                    logger.debug("[{}][{}]: throttling allocation [{}] to [{}] in order to reuse its unallocated persistent store", shard.index(), shard.id(), shard, nodeWithHighestMatch.node());, +                    logger.debug("[{}][{}]: allocating [{}] to [{}] in order to reuse its unallocated persistent store", shard.index(), shard.id(), shard, nodeWithHighestMatch.node());, +                    unassignedIterator.initialize(nodeWithHighestMatch.nodeId());, +            } else if (matchingNodes.hasAnyData() == false) {, +                IndexMetaData indexMetaData = allocation.metaData().index(shard.getIndex());, +    /**, +     * Can the shard be allocated on at least one node based on the allocation deciders., +     */, +    private boolean canBeAllocatedToAtLeastOneNode(ShardRouting shard, RoutingAllocation allocation) {, +        for (ObjectCursor<DiscoveryNode> cursor : allocation.nodes().dataNodes().values()) {, +            RoutingNode node = allocation.routingNodes().node(cursor.value.id());, +            if (node == null) {, +                continue;, +            }, +            // if we can't allocate it on a node, ignore it, for example, this handles, +            // cases for only allocating a replica after a primary, +            Decision decision = allocation.deciders().canAllocate(shard, node, allocation);, +            if (decision.type() == Decision.Type.YES) {, +                return true;, +            }, +        }, +        return false;, +    }, +, +    /**, +     * Finds the store for the assigned shard in the fetched data, returns null if none is found., +     */, +    private TransportNodesListShardStoreMetaData.StoreFilesMetaData findStore(ShardRouting shard, RoutingAllocation allocation, AsyncShardFetch.FetchResult<TransportNodesListShardStoreMetaData.NodeStoreFilesMetaData> data) {, +        assert shard.currentNodeId() != null;, +        DiscoveryNode primaryNode = allocation.nodes().get(shard.currentNodeId());, +        if (primaryNode == null) {, +            return null;, +        }, +        TransportNodesListShardStoreMetaData.NodeStoreFilesMetaData primaryNodeFilesStore = data.getData().get(primaryNode);, +        if (primaryNodeFilesStore == null) {, +            return null;, +        }, +        return primaryNodeFilesStore.storeFilesMetaData();, +    }, +, +    private MatchingNodes findMatchingNodes(ShardRouting shard, RoutingAllocation allocation,, +                                            TransportNodesListShardStoreMetaData.StoreFilesMetaData primaryStore,, +                                            AsyncShardFetch.FetchResult<TransportNodesListShardStoreMetaData.NodeStoreFilesMetaData> data) {, +        ObjectLongMap<DiscoveryNode> nodesToSize = new ObjectLongHashMap<>();, +        for (Map.Entry<DiscoveryNode, TransportNodesListShardStoreMetaData.NodeStoreFilesMetaData> nodeStoreEntry : data.getData().entrySet()) {, +            DiscoveryNode discoNode = nodeStoreEntry.getKey();, +            TransportNodesListShardStoreMetaData.StoreFilesMetaData storeFilesMetaData = nodeStoreEntry.getValue().storeFilesMetaData();, +            if (storeFilesMetaData == null) {, +                // already allocated on that node..., +                continue;, +            }, +, +            RoutingNode node = allocation.routingNodes().node(discoNode.id());, +            if (node == null) {, +                continue;, +            }, +, +            // check if we can allocate on that node..., +            // we only check for NO, since if this node is THROTTLING and it has enough "same data", +            // then we will try and assign it next time, +            Decision decision = allocation.deciders().canAllocate(shard, node, allocation);, +            if (decision.type() == Decision.Type.NO) {, +                continue;, +            }, +, +            // if it is already allocated, we can't assign to it... (and it might be primary as well), +            if (storeFilesMetaData.allocated()) {, +                continue;, +            }, +, +            // we don't have any files at all, it is an empty index, +            if (storeFilesMetaData.iterator().hasNext() == false) {, +                continue;, +            }, +, +            String primarySyncId = primaryStore.syncId();, +            String replicaSyncId = storeFilesMetaData.syncId();, +            // see if we have a sync id we can make use of, +            if (replicaSyncId != null && replicaSyncId.equals(primarySyncId)) {, +                logger.trace("{}: node [{}] has same sync id {} as primary", shard, discoNode.name(), replicaSyncId);]