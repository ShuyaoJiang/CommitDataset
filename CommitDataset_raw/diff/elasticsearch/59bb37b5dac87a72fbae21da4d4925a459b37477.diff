[+++ b/docs/reference/index-modules/store.asciidoc, +++ b/docs/reference/index-modules/store.asciidoc, +++ b/docs/reference/setup/bootstrap-checks.asciidoc, +=== Max file size check, +, +The segment files that are the components of individual shards and the translog, +generations that are components of the translog can get large (exceeding, +multiple gigabytes). On systems where the max size of files that can be created, +by the Elasticsearch process is limited, this can lead to failed, +writes. Therefore, the safest option here is that the max file size is unlimited, +and that is what the max file size bootstrap check enforces. To pass the max, +file check, you must configure your system to allow the Elasticsearch process, +the ability to write files of unlimited size. This can be done via, +`/etc/security/limits.conf` using the `fsize` setting to `unlimited` (note that, +you might have to increase the limits for the `root` user too)., +, +++ b/docs/reference/index-modules/store.asciidoc, +++ b/docs/reference/setup/bootstrap-checks.asciidoc, +=== Max file size check, +, +The segment files that are the components of individual shards and the translog, +generations that are components of the translog can get large (exceeding, +multiple gigabytes). On systems where the max size of files that can be created, +by the Elasticsearch process is limited, this can lead to failed, +writes. Therefore, the safest option here is that the max file size is unlimited, +and that is what the max file size bootstrap check enforces. To pass the max, +file check, you must configure your system to allow the Elasticsearch process, +the ability to write files of unlimited size. This can be done via, +`/etc/security/limits.conf` using the `fsize` setting to `unlimited` (note that, +you might have to increase the limits for the `root` user too)., +, +++ b/docs/reference/setup/sysconfig/virtual-memory.asciidoc, +Elasticsearch uses a <<mmapfs,`mmapfs`>> directory by, +++ b/docs/reference/index-modules/store.asciidoc, +++ b/docs/reference/setup/bootstrap-checks.asciidoc, +=== Max file size check, +, +The segment files that are the components of individual shards and the translog, +generations that are components of the translog can get large (exceeding, +multiple gigabytes). On systems where the max size of files that can be created, +by the Elasticsearch process is limited, this can lead to failed, +writes. Therefore, the safest option here is that the max file size is unlimited, +and that is what the max file size bootstrap check enforces. To pass the max, +file check, you must configure your system to allow the Elasticsearch process, +the ability to write files of unlimited size. This can be done via, +`/etc/security/limits.conf` using the `fsize` setting to `unlimited` (note that, +you might have to increase the limits for the `root` user too)., +, +++ b/docs/reference/setup/sysconfig/virtual-memory.asciidoc, +Elasticsearch uses a <<mmapfs,`mmapfs`>> directory by, +++ b/modules/ingest-common/src/test/java/org/elasticsearch/ingest/common/ConvertProcessorTests.java, +import org.elasticsearch.ingest.IngestDocument;, +import org.elasticsearch.ingest.Processor;, +import org.elasticsearch.ingest.RandomDocumentPicks;, +import org.elasticsearch.test.ESTestCase;, +, +import static org.hamcrest.Matchers.sameInstance;, +    @AwaitsFix( bugUrl = "https://github.com/elastic/elasticsearch/issues/32370"), +++ b/docs/reference/index-modules/store.asciidoc, +++ b/docs/reference/setup/bootstrap-checks.asciidoc, +=== Max file size check, +, +The segment files that are the components of individual shards and the translog, +generations that are components of the translog can get large (exceeding, +multiple gigabytes). On systems where the max size of files that can be created, +by the Elasticsearch process is limited, this can lead to failed, +writes. Therefore, the safest option here is that the max file size is unlimited, +and that is what the max file size bootstrap check enforces. To pass the max, +file check, you must configure your system to allow the Elasticsearch process, +the ability to write files of unlimited size. This can be done via, +`/etc/security/limits.conf` using the `fsize` setting to `unlimited` (note that, +you might have to increase the limits for the `root` user too)., +, +++ b/docs/reference/setup/sysconfig/virtual-memory.asciidoc, +Elasticsearch uses a <<mmapfs,`mmapfs`>> directory by, +++ b/modules/ingest-common/src/test/java/org/elasticsearch/ingest/common/ConvertProcessorTests.java, +import org.elasticsearch.ingest.IngestDocument;, +import org.elasticsearch.ingest.Processor;, +import org.elasticsearch.ingest.RandomDocumentPicks;, +import org.elasticsearch.test.ESTestCase;, +, +import static org.hamcrest.Matchers.sameInstance;, +    @AwaitsFix( bugUrl = "https://github.com/elastic/elasticsearch/issues/32370"), +++ b/modules/lang-painless/src/main/java/org/elasticsearch/painless/FunctionRef.java, +        MethodType delegateMethodType = delegateMethod.methodType;, +        interfaceMethodType = interfaceMethod.methodType.dropParameterTypes(0, 1);, +        interfaceMethodType = interfaceMethod.methodType.dropParameterTypes(0, 1);, +++ b/docs/reference/index-modules/store.asciidoc, +++ b/docs/reference/setup/bootstrap-checks.asciidoc, +=== Max file size check, +, +The segment files that are the components of individual shards and the translog, +generations that are components of the translog can get large (exceeding, +multiple gigabytes). On systems where the max size of files that can be created, +by the Elasticsearch process is limited, this can lead to failed, +writes. Therefore, the safest option here is that the max file size is unlimited, +and that is what the max file size bootstrap check enforces. To pass the max, +file check, you must configure your system to allow the Elasticsearch process, +the ability to write files of unlimited size. This can be done via, +`/etc/security/limits.conf` using the `fsize` setting to `unlimited` (note that]