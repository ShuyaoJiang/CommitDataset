[+++ b/core/src/test/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java, +import org.elasticsearch.common.unit.TimeValue;, +import java.util.*;, +        final CorrelatingBackoffPolicy internalPolicy = new CorrelatingBackoffPolicy(backoffPolicy);, +                internalPolicy.logResponse(response);, +                .setBackoffPolicy(internalPolicy), +                                Iterator<TimeValue> backoffState = internalPolicy.backoffStateFor(bulkResponse);, +                                assertNotNull("backoffState is null (indicates a bulk request got rejected without retry)", backoffState);, +                                if (backoffState.hasNext()) {, +                                    // we're not expecting that we overwhelmed it even once when we maxed out the number of retries, +                                    throw new AssertionError("Got rejected although backoff policy would allow more retries", rootCause);, +                                } else {, +                                    logger.debug("We maxed out the number of bulk retries and got rejected (this is ok).");, +                                }, +        // it is ok if we lost some index operations to rejected executions (which is possible even when backing off (although less likely), +, +    /**, +     * Internal helper class to correlate backoff states with bulk responses. This is needed to check whether we maxed out the number, +     * of retries but still got rejected (which is perfectly fine and can also happen from time to time under heavy load)., +     *, +     * This implementation relies on an implementation detail in Retry, namely that the bulk listener is notified on the same thread, +     * as the last call to the backoff policy's iterator. The advantage is that this is non-invasive to the rest of the production code., +     */, +    private static class CorrelatingBackoffPolicy extends BackoffPolicy {, +        private final Map<BulkResponse, Iterator<TimeValue>> correlations = new ConcurrentHashMap<>();, +        // this is intentionally *not* static final. We will only ever have one instance of this class per test case and want the, +        // thread local to be eligible for garbage collection right after the test to avoid leaks., +        private final ThreadLocal<Iterator<TimeValue>> iterators = new ThreadLocal<>();, +, +        private final BackoffPolicy delegate;, +, +        private CorrelatingBackoffPolicy(BackoffPolicy delegate) {, +            this.delegate = delegate;, +        }, +, +        public Iterator<TimeValue> backoffStateFor(BulkResponse response) {, +            return correlations.get(response);, +        }, +, +        // Assumption: This method is called from the same thread as the last call to the internal iterator's #hasNext() / #next(), +        // see also Retry.AbstractRetryHandler#onResponse()., +        public void logResponse(BulkResponse response) {, +            Iterator<TimeValue> iterator = iterators.get();, +            // did we ever retry?, +            if (iterator != null) {, +                // we should correlate any iterator only once, +                iterators.remove();, +                correlations.put(response, iterator);, +            }, +        }, +, +        @Override, +        public Iterator<TimeValue> iterator() {, +            return new CorrelatingIterator(iterators, delegate.iterator());, +        }, +, +        private static class CorrelatingIterator implements Iterator<TimeValue> {, +            private final Iterator<TimeValue> delegate;, +            private final ThreadLocal<Iterator<TimeValue>> iterators;, +, +            private CorrelatingIterator(ThreadLocal<Iterator<TimeValue>> iterators, Iterator<TimeValue> delegate) {, +                this.iterators = iterators;, +                this.delegate = delegate;, +            }, +, +            @Override, +            public boolean hasNext() {, +                // update on every invocation as we might get rescheduled on a different thread. Unfortunately, there is a chance that, +                // we pollute the thread local map with stale values. Due to the implementation of Retry and the life cycle of the, +                // enclosing class CorrelatingBackoffPolicy this should not pose a major problem though., +                iterators.set(this);, +                return delegate.hasNext();, +            }, +, +            @Override, +            public TimeValue next() {, +                // update on every invocation, +                iterators.set(this);, +                return delegate.next();, +            }, +        }, +    }, +++ b/core/src/test/java/org/elasticsearch/action/bulk/BulkProcessorRetryIT.java, +import org.elasticsearch.common.unit.TimeValue;, +import java.util.*;, +        final CorrelatingBackoffPolicy internalPolicy = new CorrelatingBackoffPolicy(backoffPolicy);, +                internalPolicy.logResponse(response);, +                .setBackoffPolicy(internalPolicy), +                                Iterator<TimeValue> backoffState = internalPolicy.backoffStateFor(bulkResponse);, +                                assertNotNull("backoffState is null (indicates a bulk request got rejected without retry)", backoffState);, +                                if (backoffState.hasNext()) {, +                                    // we're not expecting that we overwhelmed it even once when we maxed out the number of retries, +                                    throw new AssertionError("Got rejected although backoff policy would allow more retries", rootCause);, +                                } else {, +                                    logger.debug("We maxed out the number of bulk retries and got rejected (this is ok).");, +                                }, +        // it is ok if we lost some index operations to rejected executions (which is possible even when backing off (although less likely), +, +    /**, +     * Internal helper class to correlate backoff states with bulk responses. This is needed to check whether we maxed out the number]