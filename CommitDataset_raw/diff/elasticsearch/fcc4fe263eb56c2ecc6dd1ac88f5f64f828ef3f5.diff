[+++ b/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java, +++ b/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java, +++ b/src/main/java/org/elasticsearch/index/mapper/Uid.java, +import org.apache.lucene.util.BytesRef;, +import org.elasticsearch.common.bytes.HashedBytesArray;, +, +    public static HashedBytesArray idFromUid(BytesRef uid) {, +        return splitUidIntoTypeAndId(uid)[1];, +    }, +, +    public static HashedBytesArray typeFromUid(BytesRef uid) {, +        return splitUidIntoTypeAndId(uid)[0];, +    }, +, +, +    // LUCENE 4 UPGRADE: HashedBytesArray or BytesRef as return type?, +    private static HashedBytesArray[] splitUidIntoTypeAndId(BytesRef uid) {, +        int loc = -1;, +        for (int i = uid.offset; i < uid.length; i++) {, +            if (uid.bytes[i] == 0x23) { // 0x23 is equal to '#', +                loc = i;, +                break;, +            }, +        }, +, +        if (loc == -1) {, +            return null;, +        }, +, +        byte[] type = new byte[loc - uid.offset];, +        System.arraycopy(uid.bytes, uid.offset, type, 0, type.length);, +, +        byte[] id = new byte[uid.length - type.length -1];, +        System.arraycopy(uid.bytes, loc + 1, id, 0, id.length);, +        return new HashedBytesArray[]{new HashedBytesArray(type), new HashedBytesArray(id)};, +    }, +, +++ b/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java, +++ b/src/main/java/org/elasticsearch/index/mapper/Uid.java, +import org.apache.lucene.util.BytesRef;, +import org.elasticsearch.common.bytes.HashedBytesArray;, +, +    public static HashedBytesArray idFromUid(BytesRef uid) {, +        return splitUidIntoTypeAndId(uid)[1];, +    }, +, +    public static HashedBytesArray typeFromUid(BytesRef uid) {, +        return splitUidIntoTypeAndId(uid)[0];, +    }, +, +, +    // LUCENE 4 UPGRADE: HashedBytesArray or BytesRef as return type?, +    private static HashedBytesArray[] splitUidIntoTypeAndId(BytesRef uid) {, +        int loc = -1;, +        for (int i = uid.offset; i < uid.length; i++) {, +            if (uid.bytes[i] == 0x23) { // 0x23 is equal to '#', +                loc = i;, +                break;, +            }, +        }, +, +        if (loc == -1) {, +            return null;, +        }, +, +        byte[] type = new byte[loc - uid.offset];, +        System.arraycopy(uid.bytes, uid.offset, type, 0, type.length);, +, +        byte[] id = new byte[uid.length - type.length -1];, +        System.arraycopy(uid.bytes, loc + 1, id, 0, id.length);, +        return new HashedBytesArray[]{new HashedBytesArray(type), new HashedBytesArray(id)};, +    }, +, +++ b/src/main/java/org/elasticsearch/index/percolator/PercolatorExecutor.java, +import org.apache.lucene.index.AtomicReaderContext;, +import org.apache.lucene.index.IndexableField;, +import org.apache.lucene.util.BytesRef;, +        for (IndexableField field : request.doc().rootDoc().getFields()) {, +            if (!field.fieldType().indexed()) {, +            TokenStream tokenStream;, +            try {, +                tokenStream = field.tokenStream(, +                        mapperService.documentMapper(request.doc().type()).mappers().smartNameFieldMapper(field.name()).indexAnalyzer(), +                );, +            } catch (IOException e) {, +                throw new ElasticSearchException("Failed to create token stream", e);, +            }, +                memoryIndex.addField(field.name(), tokenStream, field.boost());, +                        memoryIndex.addField(field.name(), request.doc().analyzer().tokenStream(field.name(), reader), field.boost() /** request.doc().rootDoc().getBoost()*/);, +                            memoryIndex.addField(field.name(), request.doc().analyzer().tokenStream(field.name(), new FastStringReader(value)), field.boost() /** request.doc().rootDoc().getBoost()*/);, +            BytesRef uid = fieldData.stringValue(doc);, +            String id = Uid.idFromUid(uid).toUtf8();, +        public void setNextReader(AtomicReaderContext context) throws IOException {, +            fieldData = percolatorIndex.cache().fieldData().cache(FieldDataType.DefaultTypes.STRING, context.reader(), UidFieldMapper.NAME);]