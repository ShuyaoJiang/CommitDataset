[+++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java, +                    return Collections.emptySet();, +            try (IndexAnalyzers fakeIndexAnalzyers = new IndexAnalyzers(indexSettings, fakeDefault, fakeDefault, fakeDefault, analyzerMap, analyzerMap)) {, +++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaDataIndexUpgradeService.java, +                    return Collections.emptySet();, +            try (IndexAnalyzers fakeIndexAnalzyers = new IndexAnalyzers(indexSettings, fakeDefault, fakeDefault, fakeDefault, analyzerMap, analyzerMap)) {, +++ b/core/src/main/java/org/elasticsearch/index/analysis/AnalysisRegistry.java, +    private final Map<String, AnalysisProvider<AnalyzerProvider<?>>> normalizers;, +                            Map<String, AnalysisProvider<AnalyzerProvider<?>>> analyzers,, +                            Map<String, AnalysisProvider<AnalyzerProvider<?>>> normalizers) {, +        this.normalizers = unmodifiableMap(normalizers);, +        final Map<String, AnalyzerProvider<?>> normalizerFactories = buildNormalizerFactories(indexSettings);, +        return build(indexSettings, analyzierFactories, normalizerFactories, tokenizerFactories, charFilterFactories, tokenFilterFactories);, +        return buildMapping(Component.FILTER, indexSettings, tokenFiltersSettings, Collections.unmodifiableMap(tokenFilters), prebuiltAnalysis.tokenFilterFactories);, +        return buildMapping(Component.TOKENIZER, indexSettings, tokenizersSettings, tokenizers, prebuiltAnalysis.tokenizerFactories);, +        return buildMapping(Component.CHAR_FILTER, indexSettings, charFiltersSettings, charFilters, prebuiltAnalysis.charFilterFactories);, +        return buildMapping(Component.ANALYZER, indexSettings, analyzersSettings, analyzers, prebuiltAnalysis.analyzerProviderFactories);, +    }, +, +    public Map<String, AnalyzerProvider<?>> buildNormalizerFactories(IndexSettings indexSettings) throws IOException {, +        final Map<String, Settings> noralizersSettings = indexSettings.getSettings().getGroups("index.analysis.normalizer");, +        // TODO: Have pre-built normalizers, +        return buildMapping(Component.NORMALIZER, indexSettings, noralizersSettings, normalizers, Collections.emptyMap());, +            return getAnalysisProvider(Component.TOKENIZER, tokenizers, tokenizer, currentSettings.get("type"));, +                return getAnalysisProvider(Component.FILTER, tokenFilters, tokenFilter, typeName);, +            return getAnalysisProvider(Component.CHAR_FILTER, charFilters, charFilter, currentSettings.get("type"));, +    enum Component {, +        ANALYZER {, +            @Override, +            public String toString() {, +                return "analyzer";, +            }, +        },, +        NORMALIZER {, +            @Override, +            public String toString() {, +                return "normalizer";, +            }, +        },, +        CHAR_FILTER {, +            @Override, +            public String toString() {, +                return "char_filter";, +            }, +        },, +        TOKENIZER {, +            @Override, +            public String toString() {, +                return "tokenizer";, +            }, +        },, +        FILTER {, +            @Override, +            public String toString() {, +                return "filter";, +            }, +        };, +    }, +, +    private <T> Map<String, T> buildMapping(Component component, IndexSettings settings, Map<String, Settings> settingsMap,, +            if (component == Component.ANALYZER) {, +                T factory = null;, +                        throw new IllegalArgumentException(component + " [" + name + "] must specify either an analyzer type, or a tokenizer");, +                if (factory != null) {, +                    continue;, +                }, +            } else if (component == Component.NORMALIZER) {, +                if (typeName == null || typeName.equals("custom")) {, +                    T factory = (T) new CustomNormalizerProvider(settings, name, currentSettings);, +                    factories.put(name, factory);, +                    continue;, +                }, +            }, +            AnalysisProvider<T> type = getAnalysisProvider(component, providerMap, name, typeName);, +            if (type == null) {, +                throw new IllegalArgumentException("Unknown " + component + " type [" + typeName + "] for [" + name + "]");, +            }, +    private <T> AnalysisProvider<T> getAnalysisProvider(Component component, Map<String, AnalysisProvider<T>> providerMap, String name, String typeName) {, +            throw new IllegalArgumentException(component + " [" + name + "] must specify either an analyzer type, or a tokenizer");, +            throw new IllegalArgumentException("Unknown " + component + " type [" + typeName + "] for [" + name + "]");, +                                Map<String, AnalyzerProvider<?>> normalizerProviders,, +        Map<String, NamedAnalyzer> normalizers = new HashMap<>();, +        for (Map.Entry<String, AnalyzerProvider<?>> entry : normalizerProviders.entrySet()) {, +            processNormalizerFactory(deprecationLogger, indexSettings, entry.getKey(), entry.getValue(), normalizers,, +                    tokenFilterFactoryFactories, charFilterFactoryFactories);, +        }, +            unmodifiableMap(analyzers), unmodifiableMap(normalizers));, +, +    private void processNormalizerFactory(DeprecationLogger deprecationLogger,, +            IndexSettings indexSettings,, +            String name,, +            AnalyzerProvider<?> normalizerFactory,, +            Map<String, NamedAnalyzer> normalizers,, +            Map<String, TokenFilterFactory> tokenFilters,, +            Map<String, CharFilterFactory> charFilters) {, +        if (normalizerFactory instanceof CustomNormalizerProvider) {, +            ((CustomNormalizerProvider) normalizerFactory).build(charFilters, tokenFilters);, +        }, +        Analyzer normalizerF = normalizerFactory.get();, +        if (normalizerF == null) {]