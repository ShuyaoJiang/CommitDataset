[+++ b/docs/reference/indices/benchmark.asciidoc, +[[search-benchmark]], +== Benchmark, +, +.Experimental!, +[IMPORTANT], +=====, +This feature is marked as experimental, and may be subject to change in the, +future. If you use this feature, please let us know your experience with it!, +=====, +, +The benchmark API provides a standard mechanism for submitting queries and, +measuring their performance relative to one another., +, +[IMPORTANT], +=====, +To be eligible to run benchmarks nodes must be started with: *es.node.bench=true*. This is just a way to mark certain nodes as "executors". Searches will still be distributed out to the cluster in the normal manner. This is primarily a defensive measure to prevent production nodes from being flooded with potentially many requests. Typically one would start a single node with this setting and sumbmit benchmark requests to it., +=====, +, +[source,bash], +--------------------------------------------------, +$ ./bin/elasticsearch -Des.node.bench=true, +--------------------------------------------------, +, +Benchmarking a search request is as simple as executing the following command:, +, +[source,js], +--------------------------------------------------, +$ curl -XPUT 'localhost:9200/_bench/?pretty=true' -d, +'{, +    "name": "my_benchmark",, +    "competitors": [ {, +        "name": "my_competitor",, +        "requests": [ {, +            "query": {, +                "match": { "_all": "a*" }, +            }, +        } ], +    } ], +}', +--------------------------------------------------, +, +Response:, +, +[source,js], +--------------------------------------------------, +{, +  "status" : "complete",, +  "competitors" : {, +    "my_competitor" : {, +      "summary" : {, +        "nodes" : [ "localhost" ],, +        "total_iterations" : 5,, +        "completed_iterations" : 5,, +        "total_queries" : 1000,, +        "concurrency" : 5,, +        "multiplier" : 100,, +        "avg_warmup_time" : 43.0,, +        "statistics" : {, +          "min" : 1,, +          "max" : 10,, +          "mean" : 4.19,, +          "qps" : 238.663,, +          "std_dev" : 1.938,, +          "millis_per_hit" : 1.064,, +          "percentile_10" : 2,, +          "percentile_25" : 3,, +          "percentile_50" : 4,, +          "percentile_75" : 5,, +          "percentile_90" : 7,, +          "percentile_99" : 10, +        },, +        "slowest" : [ {, +          "node" : "localhost",, +          "max_time" : 15,, +          "avg_time" : 4,, +          "request":{"query":{"match":{"_all":"a*"}}}, +        } ], +      }, +    }, +  }, +}, +--------------------------------------------------, +, +A 'competitor' defines one or more search requests to execute along with parameters that describe how the search(es) should be run. , +Multiple competitors may be submitted as a group in which case they will execute one after the other. This makes it easy to compare various, +competing alternatives side-by-side., +, +There are several parameters which may be set at the competition level:, +[horizontal], +`name`::            Unique name for the competition, +`iterations`::      Number of times to run the competitors, +`concurrency`::     Within each iteration use this level of parallelism, +`multiplier`::      Within each iteration run the query this many times, +`warmup`::          Perform warmup of query, +`num_slowest`::     Record N slowest queries, +`search_type`::     Type of search, e.g. "query_then_fetch", "dfs_query_then_fetch", "count" , +`requests`::        Query DSL describing search requests, +`clear_caches`::    Whether caches should be cleared on each iteration, and if so, how, +`indices`::         Array of indices (and optional types) to search, e.g. ["my_index_1/my_type_1", "my_index_2", "my_index_3/my_type_3"]]