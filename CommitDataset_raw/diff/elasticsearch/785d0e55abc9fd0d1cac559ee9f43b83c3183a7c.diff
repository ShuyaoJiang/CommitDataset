[+++ b/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java, +import org.elasticsearch.cluster.routing.operation.hash.djb.DjbHashFunction;, +import org.elasticsearch.common.unit.TimeValue;, +import org.elasticsearch.test.InternalTestCluster;, +@ClusterScope(scope = Scope.TEST, numDataNodes = 0, transportClientRatio = 0), +    @TestLogging("action.index:TRACE,action.get:TRACE,discovery:TRACE,cluster.service:TRACE,indices.recovery:TRACE,indices.cluster:TRACE"), +                                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1 + randomInt(1)), +        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>();, +            final int numPrimaries = getNumShards("test").numPrimaries;, +                        String id = null;, +                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits());, +                                id = Integer.toString(idGenerator.incrementAndGet());, +                                int shard = ((InternalTestCluster) cluster()).getInstance(DjbHashFunction.class).hash(id) % numPrimaries;, +                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard);, +                                assertThat(response.getVersion(), equalTo(1l));, +                                logger.trace("[{}] indexed id [{}] through node [{}]", name, id, node);, +                                countDownLatchRef.get().countDown();, +                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount());, +                            logger.trace("[{}] failed id [{}] through node [{}]", e, name, id, node);, +        logger.info("indexing " + docsPerIndexer + " docs per indexer before partition");, +        countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()));, +        assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES));, +            logger.info("indexing " + docsPerIndexer + " docs per indexer during partition");, +            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()));, +                assertThat(semaphore.availablePermits(), equalTo(0));, +            assertTrue(countDownLatchRef.get().await(disruptionScheme.afterDisruptionTimeOut().millis() * (docsPerIndexer * indexers.size()), TimeUnit.MILLISECONDS));, +            ensureStableCluster(3, disruptionScheme.afterDisruptionTimeOut());, +        ensureStableCluster(nodeCount, TimeValue.timeValueSeconds(30), null);, +    }, +, +    private void ensureStableCluster(int nodeCount, TimeValue timeValue) {, +        ensureStableCluster(nodeCount, timeValue, null);, +        ensureStableCluster(nodeCount, TimeValue.timeValueSeconds(30), null);, +    }, +, +    private void ensureStableCluster(int nodeCount, TimeValue timeValue, @Nullable String viaNode) {, +                .setTimeout(timeValue), +++ b/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java, +import org.elasticsearch.cluster.routing.operation.hash.djb.DjbHashFunction;, +import org.elasticsearch.common.unit.TimeValue;, +import org.elasticsearch.test.InternalTestCluster;, +@ClusterScope(scope = Scope.TEST, numDataNodes = 0, transportClientRatio = 0), +    @TestLogging("action.index:TRACE,action.get:TRACE,discovery:TRACE,cluster.service:TRACE,indices.recovery:TRACE,indices.cluster:TRACE"), +                                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1 + randomInt(1)), +        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>();, +            final int numPrimaries = getNumShards("test").numPrimaries;, +                        String id = null;, +                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits());, +                                id = Integer.toString(idGenerator.incrementAndGet());, +                                int shard = ((InternalTestCluster) cluster()).getInstance(DjbHashFunction.class).hash(id) % numPrimaries;, +                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard);, +                                assertThat(response.getVersion(), equalTo(1l));, +                                logger.trace("[{}] indexed id [{}] through node [{}]", name, id, node);, +                                countDownLatchRef.get().countDown();, +                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount());, +                            logger.trace("[{}] failed id [{}] through node [{}]", e, name, id, node);, +        logger.info("indexing " + docsPerIndexer + " docs per indexer before partition");, +        countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()));, +        assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES));, +            logger.info("indexing " + docsPerIndexer + " docs per indexer during partition");, +            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()));, +                assertThat(semaphore.availablePermits(), equalTo(0));, +            assertTrue(countDownLatchRef.get().await(disruptionScheme.afterDisruptionTimeOut().millis() * (docsPerIndexer * indexers.size()), TimeUnit.MILLISECONDS));, +            ensureStableCluster(3, disruptionScheme.afterDisruptionTimeOut());, +        ensureStableCluster(nodeCount, TimeValue.timeValueSeconds(30), null);, +    }, +, +    private void ensureStableCluster(int nodeCount, TimeValue timeValue) {, +        ensureStableCluster(nodeCount, timeValue, null);, +        ensureStableCluster(nodeCount, TimeValue.timeValueSeconds(30), null);, +    }, +, +    private void ensureStableCluster(int nodeCount, TimeValue timeValue, @Nullable String viaNode) {, +                .setTimeout(timeValue), +++ b/src/test/java/org/elasticsearch/test/disruption/NetworkDelaysPartition.java, +    @Override, +    public TimeValue afterDisruptionTimeOut() {, +        return TimeValue.timeValueMillis(delayMax + super.afterDisruptionTimeOut().millis());, +    }, +++ b/src/test/java/org/elasticsearch/discovery/DiscoveryWithNetworkFailuresTests.java, +import org.elasticsearch.cluster.routing.operation.hash.djb.DjbHashFunction;, +import org.elasticsearch.common.unit.TimeValue;, +import org.elasticsearch.test.InternalTestCluster;, +@ClusterScope(scope = Scope.TEST, numDataNodes = 0, transportClientRatio = 0), +    @TestLogging("action.index:TRACE,action.get:TRACE,discovery:TRACE,cluster.service:TRACE,indices.recovery:TRACE,indices.cluster:TRACE"), +                                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1 + randomInt(1)), +        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>();, +            final int numPrimaries = getNumShards("test").numPrimaries;, +                        String id = null;, +                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits());, +                                id = Integer.toString(idGenerator.incrementAndGet());, +                                int shard = ((InternalTestCluster) cluster()).getInstance(DjbHashFunction.class).hash(id) % numPrimaries;, +                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard);, +                                assertThat(response.getVersion(), equalTo(1l));, +                                logger.trace("[{}] indexed id [{}] through node [{}]", name, id, node);, +                                countDownLatchRef.get().countDown();, +                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount());, +                            logger.trace("[{}] failed id [{}] through node [{}]", e, name, id, node);, +        logger.info("indexing " + docsPerIndexer + " docs per indexer before partition");, +        countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()));]