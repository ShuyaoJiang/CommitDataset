[+++ b/server/src/test/java/org/elasticsearch/indices/state/CloseWhileRelocatingShardsIT.java, +import org.apache.logging.log4j.message.ParameterizedMessage;, +import org.elasticsearch.cluster.ClusterState;, +import org.elasticsearch.index.shard.ShardId;, +import org.elasticsearch.test.transport.StubbableTransport;, +import static org.hamcrest.Matchers.hasSize;, +        final int maxRecoveries = Integer.MAX_VALUE;, +            .put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_CONCURRENT_RECOVERIES_SETTING.getKey(), maxRecoveries), +            .put(ThrottlingAllocationDecider.CLUSTER_ROUTING_ALLOCATION_NODE_INITIAL_PRIMARIES_RECOVERIES_SETTING.getKey(), maxRecoveries), +            final ClusterState state = clusterService.state();, +            final CountDownLatch release = new CountDownLatch(indices.length);, +                final IndexRoutingTable indexRoutingTable = state.routingTable().index(index);, +                commands.add(new MoveAllocationCommand(index, shardId, state.nodes().resolveNode(currentNodeId).getName(), targetNode));, +            }, +            // Build the list of shards for which recoveries will be blocked, +            final Set<ShardId> blockedShards = commands.commands().stream(), +                .map(c -> (MoveAllocationCommand) c), +                .map(c -> new ShardId(clusterService.state().metaData().index(c.index()).getIndex(), c.shardId())), +                .collect(Collectors.toSet());, +            assertThat(blockedShards, hasSize(indices.length));, +, +            final Set<String> acknowledgedCloses = ConcurrentCollections.newConcurrentSet();, +            final Set<String> interruptedRecoveries = ConcurrentCollections.newConcurrentSet();, +, +            // Create a SendRequestBehavior that will block outgoing start recovery request, +            final StubbableTransport.SendRequestBehavior sendBehavior = (connection, requestId, action, request, options) -> {, +                    final StartRecoveryRequest startRecoveryRequest = ((StartRecoveryRequest) request);, +                    if (blockedShards.contains(startRecoveryRequest.shardId())) {, +                        logger.debug("blocking recovery of shard {}", startRecoveryRequest.shardId());, +                            logger.debug("releasing recovery of shard {}", startRecoveryRequest.shardId());, +                        } catch (final InterruptedException e) {, +                            logger.warn(() -> new ParameterizedMessage("exception when releasing recovery of shard {}",, +                                startRecoveryRequest.shardId()), e);, +                            interruptedRecoveries.add(startRecoveryRequest.shardId().getIndexName());, +                            Thread.currentThread().interrupt();, +                            return;, +                        }, +            };, +, +            final MockTransportService targetTransportService =, +                (MockTransportService) internalCluster().getInstance(TransportService.class, targetNode);, +, +            for (DiscoveryNode node : state.getNodes()) {, +                if (node.isDataNode() && node.getName().equals(targetNode) == false) {, +                    final TransportService sourceTransportService = internalCluster().getInstance(TransportService.class, node.getName());, +                    targetTransportService.addSendBehavior(sourceTransportService, sendBehavior);, +            // If a shard recovery has been interrupted, we expect its index to be closed, +            interruptedRecoveries.forEach(CloseIndexIT::assertIndexIsClosed);, +, +                long docsCount = client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get().getHits().getTotalHits().value;]