[+++ b/docs/en/ml/getting-started.asciidoc, +* {xpack} {version}, which includes the beta {ml} features for both Elasticsearch and Kibana, +All {ml} features are available to use as an API, however this tutorial , +will focus on using the {ml} tab in the Kibana UI., +, +Beta features are not subject to the same support SLA as GA features, , +and deployment in production is at your own risk. , +// Warning was supplied by Steve K (deleteme), +single VM or even on your laptop (requires 64-bit OS). , +As you add more data and your traffic grows,, +built-in `elastic` super user. If you are performing these steps in a production, +This data will be available to search in Elasticsearch. , +The first consideration is that it must be time series data as, +the {ml} features are designed to model and detect anomalies in time series data., +The final consideration is where the data is located. This guide assumes that, +your data is stored in Elasticsearch, and will guide you through the steps, +required to create a _data feed_ that will pass data to the job. If your data, +is outside of Elasticsearch, then analysis is still possible via a POST _data_., +In this step we will upload some sample data to Elasticsearch. This is standard, +Elasticsearch functionality, and is needed to set the stage for using {ml}., +, +this type of sum or average by using aggregations. One of the benefits of, +into {xpack} {ml} instead of raw results, which reduces the volume, +this tutorial, however, these summary values are stored in Elasticsearch,, +rather than created using the {ref}/search-aggregations.html[_aggregations framework_]., +//TBD link to working with aggregations page, +TIP: This will upload 200MB of data. This is split into 4 files as there is a , +maximum 100MB limit when using the `_bulk` API., +, +alternatively use APIs to accomplish these tasks., +TIP: If you are using aggregated data, you can create an advanced job, +and configure it to use a `summary_count_field`. The {ml} algorithms will, +make the best possible use of summarized data in this case. For simplicity in this tutorial, +.. For the **Bucket span**, enter `10m`. This value specifies the size of the, +The {xpack} {ml} features use the concept of a bucket to divide up the time series, +into batches for processing. For example, if you are monitoring, +want to perform the analysis, the frequency of the input data, the duration of typical anomalies, +and the frequency at which alerting is required., +the progress of {ml} as the data is processed. This view is only available whilst the , +job is running. , +, +// NOTE: Depending on how you send data to the job, the number of processed, +// records is not always equal to the number of input records. For more information,, +// see the `processed_record_count` description in <<ml-datacounts,Data Counts Objects>>., +// TBD delete for this getting started guide, but should be in the datacounts objects, +, +click **Continue from 2017-04-01** and **2017-04-30**, then click **Start**., +The date picker will default to the latest timestamp of processed data. , +Be careful not to leave any gaps in the analysis otherwise you may miss anoamlies., +TIP: If your data is being loaded continuously, you can continue running the job in real time., +For this, start your data feed and select **No end time**., +, +Result records for each anomaly are stored in `.ml-anomalies-*` indices in Elasticsearch. , +By default, the name of the index where {ml} results are stored is labelled `shared`, , +which corresponds to the `.ml-anomalies-shared` index., +  This view contains swimlanes showing the maximum anomaly score over time., +  There is an overall swimlane which shows the overall score for the job, and, +  also swimlanes for each influencer. By selecting a block in a swimlane, the, +  anomaly details are displayed along side the original source data (where applicable)., +//TBD: Are they swimlane blocks, tiles, segments or cards? hmmm, +//TBD: Do the time periods in the heat map correspond to buckets? hmmm is it a heat map?, +//As time is the x-axis, and the block sizes stay the same, it feels more intuitive call it a swimlane., +//The swimlane bucket intervals depends on the time range selected. Their smallest possible, +//granularity is a bucket, but if you have a big time range selected, then they will span many buckets, +  This view contains a chart that represents the actual and expected values over time. , +  This is only available for jobs which analyze a single time series, +  and where `model_plot_config` is enabled., +  different colors depending on their score., +The blue line in the chart represents the actual data values. , +The shaded blue area represents the bounds for the expected values. , +The area between the upper and lower bounds are the most likely values for the model. , +If a value is outside of this area then it can be said to be anomalous., +//TBD: What is meant by "95% prediction bounds"? Because we are using probability , +//to "predict" the values.. , +Slide the time selector to a section of the time series that contains a red anomaly data, +Click one of the red blocks in the swimlane to see details about the anomalies that occured in, +that time interval. For example:]