[+++ b/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzer.java, +import org.apache.lucene.analysis.Analyzer;, +import org.apache.lucene.analysis.TokenStream;, +import org.apache.lucene.analysis.Tokenizer;, +    public int getOffsetGap(String field) {, +    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {, +        Tokenizer tokenizer = tokenizerFactory.create(charFilterIfNeeded(reader));, +        return new TokenStreamComponents(tokenizer, tokenStream);, +++ b/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzer.java, +import org.apache.lucene.analysis.Analyzer;, +import org.apache.lucene.analysis.TokenStream;, +import org.apache.lucene.analysis.Tokenizer;, +    public int getOffsetGap(String field) {, +    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {, +        Tokenizer tokenizer = tokenizerFactory.create(charFilterIfNeeded(reader));, +        return new TokenStreamComponents(tokenizer, tokenStream);, +++ b/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java, +import org.apache.lucene.analysis.AnalyzerWrapper;, +public class NamedAnalyzer extends AnalyzerWrapper {, +    protected Analyzer getWrappedAnalyzer(String fieldName) {, +        return this.analyzer;, +    protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {, +        return components;, +++ b/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzer.java, +import org.apache.lucene.analysis.Analyzer;, +import org.apache.lucene.analysis.TokenStream;, +import org.apache.lucene.analysis.Tokenizer;, +    public int getOffsetGap(String field) {, +    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {, +        Tokenizer tokenizer = tokenizerFactory.create(charFilterIfNeeded(reader));, +        return new TokenStreamComponents(tokenizer, tokenStream);, +++ b/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java, +import org.apache.lucene.analysis.AnalyzerWrapper;, +public class NamedAnalyzer extends AnalyzerWrapper {, +    protected Analyzer getWrappedAnalyzer(String fieldName) {, +        return this.analyzer;, +    protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {, +        return components;, +++ b/src/main/java/org/elasticsearch/index/analysis/NumericAnalyzer.java, +    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {, +            // LUCENE 4 UPGRADE: in reusableTokenStream the buffer size was char[120], +            // Not sure if this is intentional or not, +            return new TokenStreamComponents(createNumericTokenizer(reader, new char[32]));, +++ b/src/main/java/org/elasticsearch/index/analysis/CustomAnalyzer.java, +import org.apache.lucene.analysis.Analyzer;, +import org.apache.lucene.analysis.TokenStream;, +import org.apache.lucene.analysis.Tokenizer;, +    public int getOffsetGap(String field) {, +    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {, +        Tokenizer tokenizer = tokenizerFactory.create(charFilterIfNeeded(reader));, +        return new TokenStreamComponents(tokenizer, tokenStream);, +++ b/src/main/java/org/elasticsearch/index/analysis/NamedAnalyzer.java, +import org.apache.lucene.analysis.AnalyzerWrapper;, +public class NamedAnalyzer extends AnalyzerWrapper {, +    protected Analyzer getWrappedAnalyzer(String fieldName) {, +        return this.analyzer;, +    protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {, +        return components;, +++ b/src/main/java/org/elasticsearch/index/analysis/NumericAnalyzer.java, +    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {, +            // LUCENE 4 UPGRADE: in reusableTokenStream the buffer size was char[120], +            // Not sure if this is intentional or not, +            return new TokenStreamComponents(createNumericTokenizer(reader, new char[32]));, +++ b/src/main/java/org/elasticsearch/index/analysis/NumericTokenizer.java, +        super(numericTokenStream, reader);, +        reset();, +        super(numericTokenStream, reader);, +        reset(buffer);, +    public void reset() throws IOException {, +        reset(buffer);, +    public void reset(char[] buffer) throws IOException {]