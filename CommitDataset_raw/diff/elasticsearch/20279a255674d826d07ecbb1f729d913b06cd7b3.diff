[+++ b/docs/reference/index.asciidoc, += Elasticsearch Reference, +++ b/docs/reference/index.asciidoc, += Elasticsearch Reference, +++ b/docs/reference/mapping/types/core-types.asciidoc, +++ b/docs/reference/index.asciidoc, += Elasticsearch Reference, +++ b/docs/reference/mapping/types/core-types.asciidoc, +++ b/docs/reference/migration/migrate_2_0.asciidoc, +* The `binary` field does not support the `compress` and `compress_threshold` options anymore., +++ b/docs/reference/index.asciidoc, += Elasticsearch Reference, +++ b/docs/reference/mapping/types/core-types.asciidoc, +++ b/docs/reference/migration/migrate_2_0.asciidoc, +* The `binary` field does not support the `compress` and `compress_threshold` options anymore., +++ b/pom.xml, +        <lucene.snapshot.revision>1681024</lucene.snapshot.revision>, +++ b/docs/reference/index.asciidoc, += Elasticsearch Reference, +++ b/docs/reference/mapping/types/core-types.asciidoc, +++ b/docs/reference/migration/migrate_2_0.asciidoc, +* The `binary` field does not support the `compress` and `compress_threshold` options anymore., +++ b/pom.xml, +        <lucene.snapshot.revision>1681024</lucene.snapshot.revision>, +++ b/src/main/java/org/elasticsearch/gateway/AsyncShardFetch.java, +    protected final String type;, +    protected AsyncShardFetch(ESLogger logger, String type, ShardId shardId, List<? extends NodesOperationResponse<T>, T> action) {, +        this.type = type;, +                reroute(shardId, "nodes failed [" + failedNodes.size() + "], ignored [" + allIgnoreNodes.size() + "]");, +                        logger.warn("{}: failed to list shard for {} on node [{}]", failure, shardId, type, failure.nodeId());, +++ b/docs/reference/index.asciidoc, += Elasticsearch Reference, +++ b/docs/reference/mapping/types/core-types.asciidoc, +++ b/docs/reference/migration/migrate_2_0.asciidoc, +* The `binary` field does not support the `compress` and `compress_threshold` options anymore., +++ b/pom.xml, +        <lucene.snapshot.revision>1681024</lucene.snapshot.revision>, +++ b/src/main/java/org/elasticsearch/gateway/AsyncShardFetch.java, +    protected final String type;, +    protected AsyncShardFetch(ESLogger logger, String type, ShardId shardId, List<? extends NodesOperationResponse<T>, T> action) {, +        this.type = type;, +                reroute(shardId, "nodes failed [" + failedNodes.size() + "], ignored [" + allIgnoreNodes.size() + "]");, +                        logger.warn("{}: failed to list shard for {} on node [{}]", failure, shardId, type, failure.nodeId());, +++ b/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java, +                fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction, clusterService, allocationService);, +                logger.trace("{}: ignoring allocation, still fetching shard started state");, +                logger.trace("{}: ignoring allocation, can't be allocated on any node");, +                fetch = new InternalAsyncFetch<>(logger, "shard_store", shard.shardId(), storeAction, clusterService, allocationService);, +                logger.trace("{}: ignoring allocation, still fetching shard stores");, +        public InternalAsyncFetch(ESLogger logger, String type, ShardId shardId, List<? extends NodesOperationResponse<T>, T> action,, +            super(logger, type, shardId, action);, +            clusterService.submitStateUpdateTask("async_shard_fetch(" + type + ") " + shardId + ", reasons (" + reason + ")", Priority.HIGH, new ClusterStateUpdateTask() {, +++ b/docs/reference/index.asciidoc, += Elasticsearch Reference, +++ b/docs/reference/mapping/types/core-types.asciidoc, +++ b/docs/reference/migration/migrate_2_0.asciidoc, +* The `binary` field does not support the `compress` and `compress_threshold` options anymore., +++ b/pom.xml, +        <lucene.snapshot.revision>1681024</lucene.snapshot.revision>, +++ b/src/main/java/org/elasticsearch/gateway/AsyncShardFetch.java, +    protected final String type;, +    protected AsyncShardFetch(ESLogger logger, String type, ShardId shardId, List<? extends NodesOperationResponse<T>, T> action) {, +        this.type = type;, +                reroute(shardId, "nodes failed [" + failedNodes.size() + "], ignored [" + allIgnoreNodes.size() + "]");, +                        logger.warn("{}: failed to list shard for {} on node [{}]", failure, shardId, type, failure.nodeId());, +++ b/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java, +                fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction, clusterService, allocationService);, +                logger.trace("{}: ignoring allocation, still fetching shard started state");, +                logger.trace("{}: ignoring allocation, can't be allocated on any node");, +                fetch = new InternalAsyncFetch<>(logger, "shard_store", shard.shardId(), storeAction, clusterService, allocationService);, +                logger.trace("{}: ignoring allocation, still fetching shard stores");, +        public InternalAsyncFetch(ESLogger logger, String type, ShardId shardId, List<? extends NodesOperationResponse<T>, T> action,, +            super(logger, type, shardId, action);, +            clusterService.submitStateUpdateTask("async_shard_fetch(" + type + ") " + shardId + ", reasons (" + reason + ")", Priority.HIGH, new ClusterStateUpdateTask() {, +++ b/src/main/java/org/elasticsearch/index/mapper/core/BinaryFieldMapper.java, +import org.elasticsearch.Version;, +import org.elasticsearch.common.ParseField;, +    private static final ParseField COMPRESS = new ParseField("compress").withAllDeprecated("no replacement, implemented at the codec level");, +    private static final ParseField COMPRESS_THRESHOLD = new ParseField("compress_threshold").withAllDeprecated("no replacement");, +, +            return new BinaryFieldMapper(buildNames(context), fieldType, docValues,, +                String fieldName = entry.getKey();, +                if (parserContext.indexVersionCreated().before(Version.V_2_0_0) &&, +                        (COMPRESS.match(fieldName) || COMPRESS_THRESHOLD.match(fieldName))) {, +    protected BinaryFieldMapper(Names names, FieldType fieldType, Boolean docValues,, +            if (indexCreatedBefore2x) {, +            } else {, +                return bytes;, +            }, +++ b/docs/reference/index.asciidoc, += Elasticsearch Reference, +++ b/docs/reference/mapping/types/core-types.asciidoc, +++ b/docs/reference/migration/migrate_2_0.asciidoc, +* The `binary` field does not support the `compress` and `compress_threshold` options anymore., +++ b/pom.xml, +        <lucene.snapshot.revision>1681024</lucene.snapshot.revision>, +++ b/src/main/java/org/elasticsearch/gateway/AsyncShardFetch.java, +    protected final String type;, +    protected AsyncShardFetch(ESLogger logger, String type, ShardId shardId, List<? extends NodesOperationResponse<T>, T> action) {, +        this.type = type;]