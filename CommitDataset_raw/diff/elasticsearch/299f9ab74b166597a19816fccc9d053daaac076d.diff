[+++ b/elasticsearch/src/main/java/org/elasticsearch/xpack/ml/action/OpenJobAction.java, +        PersistentTaskInProgress<?> task = MlMetadata.getJobTask(jobId, tasks);, +++ b/elasticsearch/src/main/java/org/elasticsearch/xpack/ml/action/OpenJobAction.java, +        PersistentTaskInProgress<?> task = MlMetadata.getJobTask(jobId, tasks);, +++ b/elasticsearch/src/main/java/org/elasticsearch/xpack/ml/action/StartDatafeedAction.java, +import org.apache.logging.log4j.Logger;, +import org.elasticsearch.cluster.node.DiscoveryNode;, +import org.elasticsearch.cluster.node.DiscoveryNodes;, +import org.elasticsearch.cluster.service.ClusterService;, +import org.elasticsearch.common.unit.TimeValue;, +import org.elasticsearch.xpack.ml.utils.DatafeedStateObserver;, +import org.elasticsearch.xpack.persistent.PersistentTasksInProgress.PersistentTaskInProgress;, +    public static final ParseField TIMEOUT = new ParseField("timeout");, +            PARSER.declareString((request, val) ->, +                    request.setTimeout(TimeValue.parseTimeValue(val, TIMEOUT.getPreferredName())), TIMEOUT);, +        private TimeValue timeout = TimeValue.timeValueSeconds(20);, +        public TimeValue getTimeout() {, +            return timeout;, +        }, +, +        public void setTimeout(TimeValue timeout) {, +            this.timeout = timeout;, +        }, +, +            timeout = TimeValue.timeValueMillis(in.readVLong());, +            out.writeVLong(timeout.millis());, +            builder.field(TIMEOUT.getPreferredName(), timeout.getStringRep());, +            return Objects.hash(datafeedId, startTime, endTime, timeout);, +                    Objects.equals(endTime, other.endTime) &&, +                    Objects.equals(timeout, other.timeout);, +        private final DatafeedStateObserver observer;, +        private final ClusterService clusterService;, +                               ClusterService clusterService, DatafeedJobRunner datafeedJobRunner) {, +            this.clusterService = clusterService;, +            this.observer = new DatafeedStateObserver(threadPool, clusterService);, +        }, +, +        @Override, +        protected void doExecute(Request request, ActionListener<PersistentActionResponse> listener) {, +            ClusterState state = clusterService.state();, +            StartDatafeedAction.validate(request.datafeedId, state.metaData().custom(MlMetadata.TYPE),, +                    state.custom(PersistentTasksInProgress.TYPE), true);, +            ActionListener<PersistentActionResponse> finalListener =, +                    ActionListener.wrap(response -> waitForDatafeedStarted(request, response, listener), listener::onFailure);, +            super.doExecute(request, finalListener);, +        }, +, +        void waitForDatafeedStarted(Request request,, +                                    PersistentActionResponse response,, +                                    ActionListener<PersistentActionResponse> listener) {, +            observer.waitForState(request.getDatafeedId(), request.timeout, DatafeedState.STARTED, e -> {, +                if (e != null) {, +                    listener.onFailure(e);, +                } else {, +                    listener.onResponse(response);, +                }, +            });, +        }, +, +        @Override, +        public DiscoveryNode executorNode(Request request, ClusterState clusterState) {, +            return selectNode(logger, request, clusterState);, +            StartDatafeedAction.validate(request.getDatafeedId(), mlMetadata, tasks, false);, +        protected void nodeOperation(PersistentTask persistentTask, Request request, ActionListener<TransportResponse.Empty> listener) {, +            DatafeedTask datafeedTask = (DatafeedTask) persistentTask;, +    static void validate(String datafeedId, MlMetadata mlMetadata, PersistentTasksInProgress tasks,, +                                boolean checkJobState) {, +        if (tasks == null) {, +            return;, +        }, +, +        // we only check job state when the user submits the start datafeed request,, +        // but when we persistent task framework validates the request we don't,, +        // because we don't know if the job task will be started before datafeed task,, +        // so we just wait until the job task is opened, which will happen at some point in time., +        if (checkJobState) {, +        }, +, +        DatafeedState datafeedState = MlMetadata.getDatafeedState(datafeedId, tasks);, +        if (datafeedState == DatafeedState.STARTED) {, +            throw new ElasticsearchStatusException("datafeed already started, expected datafeed state [{}], but got [{}]",, +                    RestStatus.CONFLICT, DatafeedState.STOPPED, DatafeedState.STARTED);, +        }, +, +    static DiscoveryNode selectNode(Logger logger, Request request, ClusterState clusterState) {, +        MlMetadata mlMetadata = clusterState.metaData().custom(MlMetadata.TYPE);, +        PersistentTasksInProgress tasks = clusterState.custom(PersistentTasksInProgress.TYPE);, +        DatafeedConfig datafeed = mlMetadata.getDatafeed(request.getDatafeedId());, +        DiscoveryNodes nodes = clusterState.getNodes();, +, +        JobState jobState = MlMetadata.getJobState(datafeed.getJobId(), tasks);, +        if (jobState == JobState.OPENED) {, +            PersistentTaskInProgress task = MlMetadata.getJobTask(datafeed.getJobId(), tasks);, +            return nodes.get(task.getExecutorNode());, +        } else {, +            // lets try again later when the job has been opened:, +            logger.debug("cannot start datafeeder, because job's [{}] state is [{}] while state [{}] is required",, +                    datafeed.getJobId(), jobState, JobState.OPENED);, +            return null;, +        }]