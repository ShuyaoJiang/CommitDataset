[+++ b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java, +++ b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java, +++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java, +++ b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java, +++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java, +++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySettings.java, +        logger.debug("using max_bytes_per_sec[{}], concurrent_streams [{}], file_chunk_size [{}], translog_size [{}]",, +                maxBytesPerSec, concurrentStreams);, +++ b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java, +++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java, +++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySettings.java, +        logger.debug("using max_bytes_per_sec[{}], concurrent_streams [{}], file_chunk_size [{}], translog_size [{}]",, +                maxBytesPerSec, concurrentStreams);, +++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java, +import org.elasticsearch.common.unit.ByteSizeUnit;, +import org.elasticsearch.common.unit.TimeValue;, +import java.io.BufferedOutputStream;, +    private static final int CHUNK_SIZE = new ByteSizeValue(512, ByteSizeUnit.KB).bytesAsInt();, +                final Function<StoreFileMetaData, OutputStream> outputStreamFactories = (md) -> new BufferedOutputStream(new RecoveryOutputStream(md, bytesSinceLastPause, translogView), CHUNK_SIZE);, +                .withCompress(true), +            // Check if this request is past bytes threshold, and, +            if (size >= CHUNK_SIZE) {, +        private boolean failed = false;, +            throw new UnsupportedOperationException("we can't send single bytes over the wire");, +            if (failed == false) {, +                /* since we are an outputstream a wrapper might get flushed on close after we threw an exception., +                 * that might cause another exception from the other side of the recovery since we are in a bad state, +                 * due to a corrupted file stream etc. the biggest issue is that we will turn into a loop of exceptions, +                 * and we will always suppress the original one which might cause the recovery to retry over and over again., +                 * To prevent this we try to not send chunks again after we failed once.*/, +                boolean success = false;, +                try {, +                    success = true;, +                } finally {, +                    if (success == false) {, +                        failed = true;, +                    }, +                }, +            }, +            final TransportRequestOptions chunkSendOptions = TransportRequestOptions.builder(), +                .withCompress(false), +                .withType(TransportRequestOptions.Type.RECOVERY), +                .withTimeout(recoverySettings.internalActionTimeout()), +                .build();, +                                throttleTimeInNanos), chunkSendOptions, EmptyTransportResponseHandler.INSTANCE_SAME).txGet();, +++ b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java, +++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java, +++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySettings.java, +        logger.debug("using max_bytes_per_sec[{}], concurrent_streams [{}], file_chunk_size [{}], translog_size [{}]",, +                maxBytesPerSec, concurrentStreams);, +++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java, +import org.elasticsearch.common.unit.ByteSizeUnit;, +import org.elasticsearch.common.unit.TimeValue;, +import java.io.BufferedOutputStream;, +    private static final int CHUNK_SIZE = new ByteSizeValue(512, ByteSizeUnit.KB).bytesAsInt();, +                final Function<StoreFileMetaData, OutputStream> outputStreamFactories = (md) -> new BufferedOutputStream(new RecoveryOutputStream(md, bytesSinceLastPause, translogView), CHUNK_SIZE);, +                .withCompress(true), +            // Check if this request is past bytes threshold, and, +            if (size >= CHUNK_SIZE) {, +        private boolean failed = false;, +            throw new UnsupportedOperationException("we can't send single bytes over the wire");, +            if (failed == false) {, +                /* since we are an outputstream a wrapper might get flushed on close after we threw an exception., +                 * that might cause another exception from the other side of the recovery since we are in a bad state, +                 * due to a corrupted file stream etc. the biggest issue is that we will turn into a loop of exceptions, +                 * and we will always suppress the original one which might cause the recovery to retry over and over again., +                 * To prevent this we try to not send chunks again after we failed once.*/, +                boolean success = false;, +                try {, +                    success = true;, +                } finally {, +                    if (success == false) {, +                        failed = true;, +                    }, +                }, +            }, +            final TransportRequestOptions chunkSendOptions = TransportRequestOptions.builder(), +                .withCompress(false), +                .withType(TransportRequestOptions.Type.RECOVERY), +                .withTimeout(recoverySettings.internalActionTimeout()), +                .build();, +                                throttleTimeInNanos), chunkSendOptions, EmptyTransportResponseHandler.INSTANCE_SAME).txGet();, +++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java, +, +++ b/core/src/main/java/org/elasticsearch/cluster/ClusterModule.java, +++ b/core/src/main/java/org/elasticsearch/cluster/metadata/MetaData.java, +++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySettings.java, +        logger.debug("using max_bytes_per_sec[{}], concurrent_streams [{}], file_chunk_size [{}], translog_size [{}]",, +                maxBytesPerSec, concurrentStreams);, +++ b/core/src/main/java/org/elasticsearch/indices/recovery/RecoverySourceHandler.java, +import org.elasticsearch.common.unit.ByteSizeUnit;, +import org.elasticsearch.common.unit.TimeValue;, +import java.io.BufferedOutputStream;, +    private static final int CHUNK_SIZE = new ByteSizeValue(512, ByteSizeUnit.KB).bytesAsInt();, +                final Function<StoreFileMetaData, OutputStream> outputStreamFactories = (md) -> new BufferedOutputStream(new RecoveryOutputStream(md, bytesSinceLastPause, translogView), CHUNK_SIZE);, +                .withCompress(true), +            // Check if this request is past bytes threshold, and, +            if (size >= CHUNK_SIZE) {, +        private boolean failed = false;, +            throw new UnsupportedOperationException("we can't send single bytes over the wire");]