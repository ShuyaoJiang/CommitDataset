[+++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/HistogramAggregator.java, +        // the contract of the histogram aggregation is that shards must return buckets ordered by key in ascending order, +        CollectionUtil.introSort(buckets, InternalOrder.KEY_ASC.comparator());, +++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/HistogramAggregator.java, +        // the contract of the histogram aggregation is that shards must return buckets ordered by key in ascending order, +        CollectionUtil.introSort(buckets, InternalOrder.KEY_ASC.comparator());, +++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/histogram/InternalHistogram.java, +, +import org.apache.lucene.util.PriorityQueue;, +import java.util.Iterator;, +    private static class IteratorAndCurrent<B> {, +, +        private final Iterator<B> iterator;, +        private B current;, +, +        IteratorAndCurrent(Iterator<B> iterator) {, +            this.iterator = iterator;, +            current = iterator.next();, +        }, +, +    }, +, +    private List<B> reduceBuckets(ReduceContext reduceContext) {, +        final PriorityQueue<IteratorAndCurrent<B>> pq = new PriorityQueue<IteratorAndCurrent<B>>(aggregations.size()) {, +            @Override, +            protected boolean lessThan(IteratorAndCurrent<B> a, IteratorAndCurrent<B> b) {, +                return a.current.key < b.current.key;, +            }, +        };, +            if (histogram.buckets.isEmpty() == false) {, +                pq.add(new IteratorAndCurrent<>(histogram.buckets.iterator()));, +        List<B> reducedBuckets = new ArrayList<>();, +        if (pq.size() > 0) {, +            // list of buckets coming from different shards that have the same key, +            List<B> currentBuckets = new ArrayList<>();, +            long key = pq.top().current.key;, +            do {, +                final IteratorAndCurrent<B> top = pq.top();, +, +                if (top.current.key != key) {, +                    // the key changes, reduce what we already buffered and reset the buffer for current buckets, +                    reducedBuckets.add(currentBuckets.get(0).reduce(currentBuckets, reduceContext));, +                    currentBuckets.clear();, +                    key = top.current.key;, +                }, +, +                currentBuckets.add(top.current);, +, +                if (top.iterator.hasNext()) {, +                    final B next = top.iterator.next();, +                    assert next.key > top.current.key : "shards must return data sorted by key";, +                    top.current = next;, +                    pq.updateTop();, +                } else {, +                    pq.pop();, +                }, +            } while (pq.size() > 0);, +, +            if (currentBuckets.isEmpty() == false) {, +                reducedBuckets.add(currentBuckets.get(0).reduce(currentBuckets, reduceContext));, +            }, +        }, +, +        return reducedBuckets;, +    }, +, +    private void addEmptyBuckets(List<B> list) {, +    @Override, +    public InternalAggregation reduce(ReduceContext reduceContext) {, +        List<B> reducedBuckets = reduceBuckets(reduceContext);, +, +        // adding empty buckets if needed, +        if (minDocCount == 0) {, +            addEmptyBuckets(reducedBuckets);, +        }, +, +        if (order == InternalOrder.KEY_ASC) {, +            // nothing to do, data are already sorted since shards return, +            // sorted buckets and the merge-sort performed by reduceBuckets, +            // maintains order, +        } else if (order == InternalOrder.KEY_DESC) {, +            // we just need to reverse here..., +            reducedBuckets = Lists.reverse(reducedBuckets);, +            // sorted by sub-aggregation, need to fall back to a costly n*log(n) sort]