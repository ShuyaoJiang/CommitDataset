[+++ b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java, +            throw new IOException("File [" + blobPath.toString() + "] does not exist");, +++ b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java, +            throw new IOException("File [" + blobPath.toString() + "] does not exist");, +++ b/plugins/repository-azure/src/test/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceMock.java, +            if (keyPath != null && !keyPath.isEmpty()) {, +++ b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java, +            throw new IOException("File [" + blobPath.toString() + "] does not exist");, +++ b/plugins/repository-azure/src/test/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceMock.java, +            if (keyPath != null && !keyPath.isEmpty()) {, +++ b/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/HdfsBlobContainer.java, +        if (!blobExists(blobName)) {, +            throw new IOException("Blob [" + blobName + "] does not exist");, +        }, +, +++ b/core/src/main/java/org/elasticsearch/common/blobstore/fs/FsBlobContainer.java, +            throw new IOException("File [" + blobPath.toString() + "] does not exist");, +++ b/plugins/repository-azure/src/test/java/org/elasticsearch/cloud/azure/storage/AzureStorageServiceMock.java, +            if (keyPath != null && !keyPath.isEmpty()) {, +++ b/plugins/repository-hdfs/src/main/java/org/elasticsearch/repositories/hdfs/HdfsBlobContainer.java, +        if (!blobExists(blobName)) {, +            throw new IOException("Blob [" + blobName + "] does not exist");, +        }, +, +++ b/plugins/repository-hdfs/src/test/java/org/elasticsearch/repositories/hdfs/HdfsBlobStoreContainerTests.java, +, +import org.apache.hadoop.conf.Configuration;, +import org.apache.hadoop.fs.AbstractFileSystem;, +import org.apache.hadoop.fs.UnsupportedFileSystemException;, +import javax.security.auth.Subject;, +import java.lang.reflect.Constructor;, +import java.lang.reflect.InvocationTargetException;, +import java.net.URI;, +import java.net.URISyntaxException;, +import java.security.AccessController;, +import java.security.Principal;, +import java.security.PrivilegedAction;, +import java.util.Collections;, +        return AccessController.doPrivileged(, +                new PrivilegedAction<HdfsBlobStore>() {, +                    @Override, +                    public HdfsBlobStore run() {, +                        try {, +                            FileContext fileContext = createContext(new URI("hdfs:///"));, +                            return new HdfsBlobStore(fileContext, "temp", 1024);, +                        } catch (IOException | URISyntaxException e) {, +                            throw new RuntimeException(e);, +                        }, +            }, +        });, +    }, +, +    public FileContext createContext(URI uri) {, +        // mirrors HdfsRepository.java behaviour, +        Configuration cfg = new Configuration(true);, +        cfg.setClassLoader(HdfsRepository.class.getClassLoader());, +        cfg.reloadConfiguration();, +, +        Constructor<?> ctor;, +        Subject subject;, +, +        try {, +            Class<?> clazz = Class.forName("org.apache.hadoop.security.User");, +            ctor = clazz.getConstructor(String.class);, +            ctor.setAccessible(true);, +        }  catch (ClassNotFoundException | NoSuchMethodException e) {, +            throw new RuntimeException(e);, +        }, +, +        try {, +            Principal principal = (Principal) ctor.newInstance(System.getProperty("user.name"));, +            subject = new Subject(false, Collections.singleton(principal),, +                    Collections.emptySet(), Collections.emptySet());, +        } catch (InstantiationException | IllegalAccessException | InvocationTargetException e) {, +            throw new RuntimeException(e);, +        }, +, +        // disable file system cache, +        cfg.setBoolean("fs.hdfs.impl.disable.cache", true);, +, +        // set file system to TestingFs to avoid a bunch of security, +        // checks, similar to what is done in HdfsTests.java, +        cfg.set(String.format("fs.AbstractFileSystem.%s.impl", uri.getScheme()),, +                TestingFs.class.getName());, +, +        // create the FileContext with our user, +        return Subject.doAs(subject, new PrivilegedAction<FileContext>() {, +            @Override, +            public FileContext run() {, +                try {, +                    TestingFs fs = (TestingFs) AbstractFileSystem.get(uri, cfg);, +                    return FileContext.getFileContext(fs, cfg);, +                } catch (UnsupportedFileSystemException e) {, +                    throw new RuntimeException(e);, +                }, +            }, +        });]