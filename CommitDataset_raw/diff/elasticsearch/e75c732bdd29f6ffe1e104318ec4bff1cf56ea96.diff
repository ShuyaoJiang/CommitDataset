[+++ b/src/main/java/org/elasticsearch/common/lucene/search/MatchNoDocsQuery.java, +import org.apache.lucene.index.AtomicReaderContext;, +import org.apache.lucene.util.Bits;, +        public float getValueForNormalization() throws IOException {, +        public void normalize(float norm, float topLevelBoost) {, +        public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {, +        public Explanation explain(final AtomicReaderContext context,, +    public Weight createWeight(IndexSearcher searcher) throws IOException {, +        return new MatchNoDocsWeight();, +++ b/src/main/java/org/elasticsearch/common/lucene/search/MatchNoDocsQuery.java, +import org.apache.lucene.index.AtomicReaderContext;, +import org.apache.lucene.util.Bits;, +        public float getValueForNormalization() throws IOException {, +        public void normalize(float norm, float topLevelBoost) {, +        public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {, +        public Explanation explain(final AtomicReaderContext context,, +    public Weight createWeight(IndexSearcher searcher) throws IOException {, +        return new MatchNoDocsWeight();, +++ b/src/main/java/org/elasticsearch/common/lucene/search/MultiPhrasePrefixQuery.java, +import gnu.trove.set.hash.THashSet;, +        Set<Term> terms = new THashSet<Term>();, +    private void getPrefixTerms(Set<Term> terms, final Term prefix, final IndexReader reader) throws IOException {, +        // SlowCompositeReaderWrapper could be used... but this would merge all terms from each segment into one terms, +        // instance, which is very expensive. Therefore I think it is better to iterate over each leaf individually., +                if (!StringHelper.startsWith(term, prefix.bytes())) {]