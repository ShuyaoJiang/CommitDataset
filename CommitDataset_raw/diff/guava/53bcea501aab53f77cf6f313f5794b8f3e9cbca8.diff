[+++ b/guava/src/com/google/common/collect/ComputingConcurrentHashMap.java, +    return segmentFor(hash).compute(key, hash, computingFunction);, +    V compute(K key, int hash, Function<? super K, ? extends V> computingFunction) {, +              boolean createNewEntry = true;, +                  ValueReference<K, V> valueReference = e.getValueReference();, +                  if (valueReference.isComputingReference()) {, +                    createNewEntry = false;, +                  } else {, +                    // immediately reuse invalid entries, +                    clearLiveEntry(e, hash, valueReference);, +              if (createNewEntry) {, +                computingValueReference = new ComputingValueReference<K, V>(computingFunction);, +                  e = map.newEntry(key, hash, first);, +, +                // Synchronizes on the entry to allow failing fast when a recursive computation is, +                // detected. This is not fool-proof since the entry may be copied when the segment, +                // is written to., +                if (value != null) {, +                  // putIfAbsent, +                  put(key, hash, value, true);, +                }, +    final Function<? super K, ? extends V> computingFunction;, +    public ComputingValueReference(Function<? super K, ? extends V> computingFunction) {, +      this.computingFunction = computingFunction;, +        value = computingFunction.apply(key);, +++ b/guava/src/com/google/common/collect/ComputingConcurrentHashMap.java, +    return segmentFor(hash).compute(key, hash, computingFunction);, +    V compute(K key, int hash, Function<? super K, ? extends V> computingFunction) {, +              boolean createNewEntry = true;, +                  ValueReference<K, V> valueReference = e.getValueReference();, +                  if (valueReference.isComputingReference()) {, +                    createNewEntry = false;, +                  } else {, +                    // immediately reuse invalid entries, +                    clearLiveEntry(e, hash, valueReference);, +              if (createNewEntry) {, +                computingValueReference = new ComputingValueReference<K, V>(computingFunction);, +                  e = map.newEntry(key, hash, first);, +, +                // Synchronizes on the entry to allow failing fast when a recursive computation is, +                // detected. This is not fool-proof since the entry may be copied when the segment, +                // is written to., +                if (value != null) {, +                  // putIfAbsent, +                  put(key, hash, value, true);, +                }, +    final Function<? super K, ? extends V> computingFunction;, +    public ComputingValueReference(Function<? super K, ? extends V> computingFunction) {, +      this.computingFunction = computingFunction;, +        value = computingFunction.apply(key);, +++ b/guava/src/com/google/common/collect/CustomConcurrentHashMap.java, +, +    if (cleanupExecutor != null) {, +      cleanupExecutor.execute(cleanupTask);, +    }, +    return cleanupExecutor == null;, +    segmentFor(hash).reclaimValue(entry.getKey(), hash, valueReference);, +    segmentFor(hash).reclaimKey(entry, hash);, +  final Runnable cleanupTask = new Runnable() {, +    @Override, +    public void run() {, +      // TODO(user): should we sleep between runs? use a scheduled executor? have a dirty, +      // flag to indicate when cleanup is required? enqueue one cleanup task per queue so they, +      // can wait on the queues?, +      for (Segment<K, V> segment : segments) {, +        segment.runCleanup();, +      }, +      cleanupExecutor.execute(cleanupTask);, +    }, +  };, +, +     * The number of live elements in this segment's region., +          postWriteCleanup();, +        // we may be expiring a large number of entries, so enqueue future cleanup rather than, +        // removing them immediately, +        if (!removeEntry(e, e.getHash())) {, +        if (!removeEntry(e, e.getHash())) {, +        // getFirst, but remember the index, +        AtomicReferenceArray<ReferenceEntry<K, V>> table = this.table;, +        int index = hash & (table.length() - 1);, +        ReferenceEntry<K, V> first = table.get(index);, +, +        for (ReferenceEntry<K, V> e = first; e != null; e = e.getNext()) {, +            ValueReference<K, V> valueReference = e.getValueReference();, +            V entryValue = valueReference.get();, +              removeLiveEntry(table, index, first, e, hash, valueReference);, +        // getFirst, but remember the index, +        AtomicReferenceArray<ReferenceEntry<K, V>> table = this.table;, +        int index = hash & (table.length() - 1);, +        ReferenceEntry<K, V> first = table.get(index);, +, +        for (ReferenceEntry<K, V> e = first; e != null; e = e.getNext()) {, +            ValueReference<K, V> valueReference = e.getValueReference();, +            V entryValue = valueReference.get();, +              removeLiveEntry(table, index, first, e, hash, valueReference);, +              if (valueReference.isComputingReference()) {, +              } else {, +                // immediately reuse partially collected entry, but send notifications first, +                clearLiveEntry(e, hash, valueReference); // decrements count, +              }]