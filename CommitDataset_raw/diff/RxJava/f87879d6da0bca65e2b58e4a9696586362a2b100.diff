[+++ b/src/main/java/io/reactivex/processors/MulticastProcessor.java, +/**, + * Copyright (c) 2016-present, RxJava Contributors., + *, + * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in, + * compliance with the License. You may obtain a copy of the License at, + *, + * http://www.apache.org/licenses/LICENSE-2.0, + *, + * Unless required by applicable law or agreed to in writing, software distributed under the License is, + * distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See, + * the License for the specific language governing permissions and limitations under the License., + */, +, +package io.reactivex.processors;, +, +import java.util.concurrent.atomic.*;, +, +import org.reactivestreams.*;, +, +import io.reactivex.annotations.*;, +import io.reactivex.exceptions.*;, +import io.reactivex.internal.functions.ObjectHelper;, +import io.reactivex.internal.fuseable.*;, +import io.reactivex.internal.queue.*;, +import io.reactivex.internal.subscriptions.*;, +import io.reactivex.plugins.RxJavaPlugins;, +, +/**, + * A {@link FlowableProcessor} implementation that coordinates downstream requests through, + * a front-buffer and stable-prefetching, optionally canceling the upstream if all, + * subscribers have cancelled., + * <p>, + * <img width="640" height="360" src="https://raw.github.com/wiki/ReactiveX/RxJava/images/rx-operators/MulticastProcessor.png" alt="">, + * <p>, + * This processor does not have a public constructor by design; a new empty instance of this, + * {@code MulticastProcessor} can be created via the following {@code create} methods that, + * allow configuring it:, + * <ul>, + * <li>{@link #create()}: create an empty {@code MulticastProcessor} with, + *      {@link io.reactivex.Flowable#bufferSize() Flowable.bufferSize()} prefetch amount, + *      and no reference counting behavior.</li>, + * <li>{@link #create(int)}: create an empty {@code MulticastProcessor} with, + *      the given prefetch amount and no reference counting behavior.</li>, + * <li>{@link #create(boolean)}: create an empty {@code MulticastProcessor} with, + *      {@link io.reactivex.Flowable#bufferSize() Flowable.bufferSize()} prefetch amount, + *      and no reference counting behavior.</li>, + * <li>{@link #create(int, boolean)}: create an empty {@code MulticastProcessor} with, + *      the given prefetch amount and an optional reference counting behavior.</li>, + * </ul>, + * <p>, + * When the reference counting behavior is enabled, the {@code MulticastProcessor} cancels its, + * upstream when all {@link Subscriber}s have cancelled. Late {@code Subscriber}s will then be, + * immediately completed., + * <p>, + * Because {@code MulticastProcessor} implements the {@link Subscriber} interface, calling, + * {@code onSubscribe} is mandatory (<a href="https://github.com/reactive-streams/reactive-streams-jvm#2.12">Rule 2.12</a>)., + * If {@code MulticastProcessor} should run standalone, i.e., without subscribing the {@code MulticastProcessor} to another {@link Publisher},, + * use {@link #start()} or {@link #startUnbounded()} methods to initialize the internal buffer., + * Failing to do so will lead to a {@link NullPointerException} at runtime., + * <p>, + * Use {@link #offer(Object)} to try and offer/emit items but don't fail if the, + * internal buffer is full., + * <p>, + * A {@code MulticastProcessor} is a {@link Processor} type in the Reactive Streams specification,, + * {@code null}s are not allowed (<a href="https://github.com/reactive-streams/reactive-streams-jvm#2.13">Rule 2.13</a>) as, + * parameters to {@link #onSubscribe(Subscription)}, {@link #offer(Object)}, {@link #onNext(Object)} and {@link #onError(Throwable)}., + * Such calls will result in a {@link NullPointerException} being thrown and the processor's state is not changed., + * <p>, + * Since a {@code MulticastProcessor} is a {@link io.reactivex.Flowable}, it supports backpressure., + * The backpressure from the currently subscribed {@link Subscriber}s are coordinated by emitting upstream, + * items only if all of those {@code Subscriber}s have requested at least one item. This behavior, + * is also called <em>lockstep-mode</em> because even if some {@code Subscriber}s can take any number, + * of items, other {@code Subscriber}s requesting less or infrequently will slow down the overall, + * throughput of the flow., + * <p>, + * Calling {@link #onNext(Object)}, {@link #offer(Object)}, {@link #onError(Throwable)} and {@link #onComplete()}, + * is required to be serialized (called from the same thread or called non-overlappingly from different threads, + * through external means of serialization). The {@link #toSerialized()} method available to all {@link FlowableProcessor}s, + * provides such serialization and also protects against reentrance (i.e., when a downstream {@code Subscriber}, + * consuming this processor also wants to call {@link #onNext(Object)} on this processor recursively)., + * <p>, + * This {@code MulticastProcessor} supports the standard state-peeking methods {@link #hasComplete()}, {@link #hasThrowable()},, + * {@link #getThrowable()} and {@link #hasSubscribers()}. This processor doesn't allow peeking into its buffer., + * <p>, + * When this {@code MulticastProcessor} is terminated via {@link #onError(Throwable)} or {@link #onComplete()},, + * all previously signaled but not yet consumed items will be still available to {@code Subscriber}s and the respective, + * terminal even is only emitted when all previous items have been successfully delivered to {@code Subscriber}s., + * If there are no {@code Subscriber}s, the remaining items will be buffered indefinitely., + * <p>, + * The {@code MulticastProcessor} does not support clearing its cached events (to appear empty again)., + * <dl>, + *  <dt><b>Backpressure:</b></dt>, + *  <dd>The backpressure from the currently subscribed {@code Subscriber}s are coordinated by emitting upstream, + *  items only if all of those {@code Subscriber}s have requested at least one item. This behavior, + *  is also called <em>lockstep-mode</em> because even if some {@code Subscriber}s can take any number, + *  of items, other {@code Subscriber}s requesting less or infrequently will slow down the overall, + *  throughput of the flow.</dd>, + *  <dt><b>Scheduler:</b></dt>, + *  <dd>{@code MulticastProcessor} does not operate by default on a particular {@link io.reactivex.Scheduler} and]