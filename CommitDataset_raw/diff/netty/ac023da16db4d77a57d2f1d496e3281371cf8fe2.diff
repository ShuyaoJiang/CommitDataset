[+++ b/transport-native-kqueue/src/main/c/netty_kqueue_native.c, +        if (netty_unix_util_timespec_subtract_ns(&timeoutTs,, +              netty_unix_util_timespec_elapsed_ns(&beforeTs, &nowTs))) {, +, +++ b/transport-native-kqueue/src/main/c/netty_kqueue_native.c, +        if (netty_unix_util_timespec_subtract_ns(&timeoutTs,, +              netty_unix_util_timespec_elapsed_ns(&beforeTs, &nowTs))) {, +, +++ b/transport-native-unix-common/src/main/c/netty_unix_util.c, +static const uint64_t NETTY_BILLION = 1000000000L;, +, +uint64_t netty_unix_util_timespec_elapsed_ns(const struct timespec* begin, const struct timespec* end) {, +  return NETTY_BILLION * (end->tv_sec - begin->tv_sec) + (end->tv_nsec - begin->tv_nsec);, +}, +, +jboolean netty_unix_util_timespec_subtract_ns(struct timespec* ts, uint64_t nanos) {, +  const uint64_t seconds = nanos / NETTY_BILLION;, +  nanos -= seconds * NETTY_BILLION;, +  // If there are too many nanos we steal from seconds to avoid underflow on nanos. This way we, +  // only have to worry about underflow on tv_sec., +  if (nanos > ts->tv_nsec) {, +    --(ts->tv_sec);, +    ts->tv_nsec += NETTY_BILLION;, +  }, +  const jboolean underflow = ts->tv_sec < seconds;, +  ts->tv_sec -= seconds;, +  ts->tv_nsec -= nanos;, +  return underflow;, +}, +, +++ b/transport-native-kqueue/src/main/c/netty_kqueue_native.c, +        if (netty_unix_util_timespec_subtract_ns(&timeoutTs,, +              netty_unix_util_timespec_elapsed_ns(&beforeTs, &nowTs))) {, +, +++ b/transport-native-unix-common/src/main/c/netty_unix_util.c, +static const uint64_t NETTY_BILLION = 1000000000L;, +, +uint64_t netty_unix_util_timespec_elapsed_ns(const struct timespec* begin, const struct timespec* end) {, +  return NETTY_BILLION * (end->tv_sec - begin->tv_sec) + (end->tv_nsec - begin->tv_nsec);, +}, +, +jboolean netty_unix_util_timespec_subtract_ns(struct timespec* ts, uint64_t nanos) {, +  const uint64_t seconds = nanos / NETTY_BILLION;, +  nanos -= seconds * NETTY_BILLION;, +  // If there are too many nanos we steal from seconds to avoid underflow on nanos. This way we, +  // only have to worry about underflow on tv_sec., +  if (nanos > ts->tv_nsec) {, +    --(ts->tv_sec);, +    ts->tv_nsec += NETTY_BILLION;, +  }, +  const jboolean underflow = ts->tv_sec < seconds;, +  ts->tv_sec -= seconds;, +  ts->tv_nsec -= nanos;, +  return underflow;, +}, +, +++ b/transport-native-unix-common/src/main/c/netty_unix_util.h, +#include <stdint.h>, + * Calculate the number of nano seconds elapsed between begin and end., + *, + * Returns the number of nano seconds., + */, +uint64_t netty_unix_util_timespec_elapsed_ns(const struct timespec* begin, const struct timespec* end);, +, +/**, + * Subtract <pre>nanos</pre> nano seconds from a <pre>timespec</pre>., + *, + * Returns true if there is underflow., + */, +jboolean netty_unix_util_timespec_subtract_ns(struct timespec* ts, uint64_t nanos);, +, +/**]