[+++ b/codec/src/main/java/io/netty/handler/codec/MessageToByteEncoder.java, +, +    protected boolean isPreferDirect() {, +        return preferDirect;, +    }, +++ b/codec/src/main/java/io/netty/handler/codec/MessageToByteEncoder.java, +, +    protected boolean isPreferDirect() {, +        return preferDirect;, +    }, +++ b/codec/src/main/java/io/netty/handler/codec/compression/Lz4FrameEncoder.java, +import io.netty.handler.codec.EncoderException;, +import io.netty.util.internal.ObjectUtil;, +    static final int DEFAULT_MAX_ENCODE_SIZE = Integer.MAX_VALUE;, +, +    private ByteBufChecksum checksum;, +     * Compression level of current LZ4 encoder (depends on {@link #blockSize})., +     * Inner byte buffer for outgoing data. It's capacity will be {@link #blockSize}., +     * Maximum size for any buffer to write encoded (compressed) data into., +    private final int maxEncodeSize;, +        this(factory, highCompressor, blockSize, checksum, DEFAULT_MAX_ENCODE_SIZE);, +    }, +, +        /**, +         * Creates a new customizable LZ4 encoder., +         *, +         * @param factory         user customizable {@link LZ4Factory} instance, +         *                        which may be JNI bindings to the original C implementation, a pure Java implementation, +         *                        or a Java implementation that uses the {@link sun.misc.Unsafe}, +         * @param highCompressor  if {@code true} codec will use compressor which requires more memory, +         *                        and is slower but compresses more efficiently, +         * @param blockSize       the maximum number of bytes to try to compress at once,, +         *                        must be >= 64 and <= 32 M, +         * @param checksum        the {@link Checksum} instance to use to check data for integrity, +         * @param maxEncodeSize   the maximum size for an encode (compressed) buffer, +         */, +    public Lz4FrameEncoder(LZ4Factory factory, boolean highCompressor, int blockSize,, +                           Checksum checksum, int maxEncodeSize) {, +        this.checksum = ByteBufChecksum.wrapChecksum(checksum);, +        this.maxEncodeSize = ObjectUtil.checkPositive(maxEncodeSize, "maxEncodeSize");, +    protected ByteBuf allocateBuffer(ChannelHandlerContext ctx, ByteBuf msg, boolean preferDirect) {, +        return allocateBuffer(ctx, msg, preferDirect, true);, +    }, +, +    private ByteBuf allocateBuffer(ChannelHandlerContext ctx, ByteBuf msg, boolean preferDirect,, +                                   boolean allowEmptyReturn) {, +        int targetBufSize = 0;, +        int remaining = msg.readableBytes() + buffer.readableBytes();, +, +        // quick overflow check, +        if (remaining < 0) {, +            throw new EncoderException("too much data to allocate a buffer for compression");, +        }, +, +        while (remaining > 0) {, +            int curSize = Math.min(blockSize, remaining);, +            remaining -= curSize;, +            // calculate the total compressed size of the current block (including header) and add to the total, +            targetBufSize += compressor.maxCompressedLength(curSize) + HEADER_LENGTH;, +        }, +, +        // in addition to just the raw byte count, the headers (HEADER_LENGTH) per block (configured via, +        // #blockSize) will also add to the targetBufSize, and the combination of those would never wrap around, +        // again to be >= 0, this is a good check for the overflow case., +        if (targetBufSize > maxEncodeSize || 0 > targetBufSize) {, +            throw new EncoderException(String.format("requested encode buffer size (%d bytes) exceeds the maximum " +, +                                                     "allowable size (%d bytes)", targetBufSize, maxEncodeSize));, +        }, +, +        if (allowEmptyReturn && targetBufSize < blockSize) {, +            return Unpooled.EMPTY_BUFFER;, +        }, +, +        if (preferDirect) {, +            return ctx.alloc().ioBuffer(targetBufSize, targetBufSize);, +        } else {, +            return ctx.alloc().heapBuffer(targetBufSize, targetBufSize);, +        }, +    }, +, +    /**, +     * {@inheritDoc}, +     *, +     * Encodes the input buffer into {@link #blockSize} chunks in the output buffer. Data is only compressed and, +     * written once we hit the {@link #blockSize}; else, it is copied into the backing {@link #buffer} to await, +     * more data., +     */, +    @Override, +        int length;, +        while ((length = in.readableBytes()) > 0) {, +            final int nextChunkSize = Math.min(length, buffer.writableBytes());, +            in.readBytes(buffer, nextChunkSize);, +, +            if (!buffer.isWritable()) {, +        }, +        int flushableBytes = buffer.readableBytes();, +        if (flushableBytes == 0) {, +        checksum.update(buffer, buffer.readerIndex(), flushableBytes);, +        final int bufSize = compressor.maxCompressedLength(flushableBytes) + HEADER_LENGTH;, +        out.ensureWritable(bufSize);]